/* This is a generated file! */
#![cfg_attr(rustfmt, rustfmt_skip)]
use std::sync::Arc;
use once_cell::sync::Lazy;
use sqlfluffrs_types::{Grammar, ParseMode, SimpleHint};
use sqlfluffrs_types::regex::RegexMode;

// name='AbortKeywordSegment'
pub static ABORT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ABORT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AbsKeywordSegment'
pub static ABS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ABS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AbsoluteKeywordSegment'
pub static ABSOLUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ABSOLUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AccessKeywordSegment'
pub static ACCESS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ACCESS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AccessStatementSegment'
pub static ACCESS_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// AccessStatementSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GrantKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WarehouseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WAREHOUSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntegrationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTEGRATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string(), "INTEGRATION".to_string(), "ROLE".to_string(), "USER".to_string(), "WAREHOUSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ApplyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["APPLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MaskingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MASKING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PolicyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["POLICY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["APPLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExecuteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TaskKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ManageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MANAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GrantsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANTS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MANAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MonitorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExecutionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UsageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTION".to_string(), "USAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["APPLY".to_string(), "CREATE".to_string(), "EXECUTE".to_string(), "MANAGE".to_string(), "MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MaskingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MASKING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PolicyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["POLICY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MASKING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PipeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PIPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProcedureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoutineKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StreamKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STREAM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TaskKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MaterializedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATERIALIZED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATERIALIZED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExternalKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FileKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FormatKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FORMAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string(), "FILE".to_string(), "FUNCTION".to_string(), "MATERIALIZED".to_string(), "PROCEDURE".to_string(), "ROUTINE".to_string(), "SEQUENCE".to_string(), "STAGE".to_string(), "STREAM".to_string(), "TABLE".to_string(), "TASK".to_string(), "VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string(), "FILE".to_string(), "FUNCTION".to_string(), "MASKING".to_string(), "MATERIALIZED".to_string(), "PIPE".to_string(), "PROCEDURE".to_string(), "ROUTINE".to_string(), "SCHEMA".to_string(), "SEQUENCE".to_string(), "STAGE".to_string(), "STREAM".to_string(), "TABLE".to_string(), "TASK".to_string(), "VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CatalogKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CATALOG".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CATALOG".to_string(), "SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ImportedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IMPORTED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PrivilegesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIVILEGES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IMPORTED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ApplyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["APPLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ConnectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONNECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeleteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExecuteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InsertKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ModifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MODIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MonitorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OperateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OPERATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OwnershipKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OWNERSHIP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReadKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["READ".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Reference_usageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCE_USAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReferencesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TempKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TemporaryKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMPORARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TriggerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRIGGER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TruncateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRUNCATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UpdateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UsageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Use_any_roleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE_ANY_ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WriteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PrivilegesKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIVILEGES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MANAGE".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MANAGE".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AccountKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ACCOUNT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ResourceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RESOURCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MonitorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RESOURCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WarehouseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WAREHOUSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DomainKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DOMAIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntegrationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTEGRATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LanguageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LANGUAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CatalogKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CATALOG".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TablespaceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLESPACE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TypeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TYPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ForeignKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ServerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SERVER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DataKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WrapperKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WRAPPER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATA".to_string(), "SERVER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemasKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMAS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FutureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUTURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemasKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMAS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUTURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProcedureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoutineKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StreamKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STREAM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TaskKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MaterializedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATERIALIZED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATERIALIZED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExternalKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FileKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FormatKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FORMAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string(), "FILE".to_string(), "FUNCTION".to_string(), "MATERIALIZED".to_string(), "PROCEDURE".to_string(), "ROUTINE".to_string(), "SEQUENCE".to_string(), "STAGE".to_string(), "STREAM".to_string(), "TABLE".to_string(), "TASK".to_string(), "VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TablesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StagesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STAGES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTIONS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProceduresKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoutinesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequencesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StreamsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STREAMS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TasksKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASKS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTIONS".to_string(), "PROCEDURES".to_string(), "ROUTINES".to_string(), "SEQUENCES".to_string(), "STAGES".to_string(), "STREAMS".to_string(), "TABLES".to_string(), "TASKS".to_string(), "VIEWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FutureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUTURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TablesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StagesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STAGES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTIONS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProceduresKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoutinesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequencesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StreamsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STREAMS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TasksKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASKS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTIONS".to_string(), "PROCEDURES".to_string(), "ROUTINES".to_string(), "SEQUENCES".to_string(), "STAGES".to_string(), "STREAMS".to_string(), "TABLES".to_string(), "TASKS".to_string(), "VIEWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string(), "SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUTURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "CATALOG".to_string(), "DATABASE".to_string(), "DOMAIN".to_string(), "EXTERNAL".to_string(), "FILE".to_string(), "FOREIGN".to_string(), "FUNCTION".to_string(), "FUTURE".to_string(), "INTEGRATION".to_string(), "LANGUAGE".to_string(), "MATERIALIZED".to_string(), "PROCEDURE".to_string(), "RESOURCE".to_string(), "ROLE".to_string(), "ROUTINE".to_string(), "SCHEMA".to_string(), "SEQUENCE".to_string(), "STAGE".to_string(), "STREAM".to_string(), "TABLE".to_string(), "TABLESPACE".to_string(), "TASK".to_string(), "TYPE".to_string(), "VIEW".to_string(), "WAREHOUSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FunctionParameterListGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "WildcardIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ToKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LargeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LARGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OBJECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LARGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MANAGE".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OwnershipKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OWNERSHIP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OWNERSHIP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ToKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ShareKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SHARE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string(), "ROLE".to_string(), "SHARE".to_string(), "USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RoleReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "PublicKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PUBLIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GrantKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OptionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OPTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AdminKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADMIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OptionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OPTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CopyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COPY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CurrentKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GrantsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANTS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COPY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COPY".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GrantedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANTED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Current_userKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT_USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Session_userKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SESSION_USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANTED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RevokeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REVOKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GrantKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OptionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OPTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ForKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WarehouseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WAREHOUSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntegrationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTEGRATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string(), "INTEGRATION".to_string(), "ROLE".to_string(), "USER".to_string(), "WAREHOUSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ApplyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["APPLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MaskingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MASKING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PolicyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["POLICY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["APPLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExecuteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TaskKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ManageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MANAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GrantsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANTS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MANAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MonitorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExecutionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UsageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTION".to_string(), "USAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["APPLY".to_string(), "CREATE".to_string(), "EXECUTE".to_string(), "MANAGE".to_string(), "MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MaskingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MASKING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PolicyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["POLICY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MASKING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PipeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PIPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProcedureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoutineKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StreamKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STREAM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TaskKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MaterializedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATERIALIZED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATERIALIZED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExternalKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FileKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FormatKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FORMAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string(), "FILE".to_string(), "FUNCTION".to_string(), "MATERIALIZED".to_string(), "PROCEDURE".to_string(), "ROUTINE".to_string(), "SEQUENCE".to_string(), "STAGE".to_string(), "STREAM".to_string(), "TABLE".to_string(), "TASK".to_string(), "VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string(), "FILE".to_string(), "FUNCTION".to_string(), "MASKING".to_string(), "MATERIALIZED".to_string(), "PIPE".to_string(), "PROCEDURE".to_string(), "ROUTINE".to_string(), "SCHEMA".to_string(), "SEQUENCE".to_string(), "STAGE".to_string(), "STREAM".to_string(), "TABLE".to_string(), "TASK".to_string(), "VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CatalogKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CATALOG".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CATALOG".to_string(), "SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ImportedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IMPORTED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PrivilegesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIVILEGES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IMPORTED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ApplyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["APPLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ConnectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONNECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeleteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExecuteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InsertKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ModifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MODIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MonitorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OperateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OPERATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OwnershipKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OWNERSHIP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReadKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["READ".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Reference_usageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCE_USAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReferencesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TempKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TemporaryKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMPORARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TriggerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRIGGER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TruncateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRUNCATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UpdateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UsageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Use_any_roleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE_ANY_ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WriteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PrivilegesKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIVILEGES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MANAGE".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MANAGE".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AccountKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ACCOUNT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ResourceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RESOURCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MonitorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MONITOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RESOURCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WarehouseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WAREHOUSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DomainKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DOMAIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntegrationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTEGRATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LanguageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LANGUAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CatalogKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CATALOG".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TablespaceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLESPACE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TypeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TYPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ForeignKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ServerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SERVER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DataKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WrapperKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WRAPPER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATA".to_string(), "SERVER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemasKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMAS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FutureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUTURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemasKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMAS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUTURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProcedureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoutineKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StreamKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STREAM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TaskKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MaterializedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATERIALIZED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATERIALIZED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExternalKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FileKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FormatKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FORMAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string(), "FILE".to_string(), "FUNCTION".to_string(), "MATERIALIZED".to_string(), "PROCEDURE".to_string(), "ROUTINE".to_string(), "SEQUENCE".to_string(), "STAGE".to_string(), "STREAM".to_string(), "TABLE".to_string(), "TASK".to_string(), "VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TablesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StagesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STAGES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTIONS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProceduresKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoutinesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequencesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StreamsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STREAMS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TasksKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASKS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTIONS".to_string(), "PROCEDURES".to_string(), "ROUTINES".to_string(), "SEQUENCES".to_string(), "STAGES".to_string(), "STREAMS".to_string(), "TABLES".to_string(), "TASKS".to_string(), "VIEWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FutureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUTURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TablesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StagesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STAGES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTIONS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProceduresKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoutinesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequencesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StreamsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STREAMS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TasksKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TASKS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTIONS".to_string(), "PROCEDURES".to_string(), "ROUTINES".to_string(), "SEQUENCES".to_string(), "STAGES".to_string(), "STREAMS".to_string(), "TABLES".to_string(), "TASKS".to_string(), "VIEWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string(), "SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUTURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "CATALOG".to_string(), "DATABASE".to_string(), "DOMAIN".to_string(), "EXTERNAL".to_string(), "FILE".to_string(), "FOREIGN".to_string(), "FUNCTION".to_string(), "FUTURE".to_string(), "INTEGRATION".to_string(), "LANGUAGE".to_string(), "MATERIALIZED".to_string(), "PROCEDURE".to_string(), "RESOURCE".to_string(), "ROLE".to_string(), "ROUTINE".to_string(), "SCHEMA".to_string(), "SEQUENCE".to_string(), "STAGE".to_string(), "STREAM".to_string(), "TABLE".to_string(), "TABLESPACE".to_string(), "TASK".to_string(), "TYPE".to_string(), "VIEW".to_string(), "WAREHOUSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FunctionParameterListGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "WildcardIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ToKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LargeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LARGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OBJECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LARGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "APPLY".to_string(), "CONNECT".to_string(), "CREATE".to_string(), "DELETE".to_string(), "EXECUTE".to_string(), "IMPORTED".to_string(), "INSERT".to_string(), "MANAGE".to_string(), "MODIFY".to_string(), "MONITOR".to_string(), "OPERATE".to_string(), "OWNERSHIP".to_string(), "READ".to_string(), "REFERENCES".to_string(), "REFERENCE_USAGE".to_string(), "SELECT".to_string(), "TEMP".to_string(), "TEMPORARY".to_string(), "TRIGGER".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USAGE".to_string(), "USE".to_string(), "USE_ANY_ROLE".to_string(), "WRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OwnershipKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OWNERSHIP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OWNERSHIP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ShareKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SHARE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string(), "ROLE".to_string(), "SHARE".to_string(), "USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DropBehaviorGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REVOKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANT".to_string(), "REVOKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AccessorGrammar'
pub static ACCESSOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ArrayAccessorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AccountKeywordSegment'
pub static ACCOUNT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ACCOUNT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AccountsKeywordSegment'
pub static ACCOUNTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ACCOUNTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ActionKeywordSegment'
pub static ACTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ACTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AdaKeywordSegment'
pub static ADA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ADA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AddKeywordSegment'
pub static ADD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ADD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AdminKeywordSegment'
pub static ADMIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ADMIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AfterKeywordSegment'
pub static AFTER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AFTER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AggregateKeywordSegment'
pub static AGGREGATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AGGREGATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AggregateOrderByClause'
pub static AGGREGATE_ORDER_BY_CLAUSE: Lazy<Arc<Grammar>> = Lazy::new(||
// AggregateOrderByClause
Arc::new(Grammar::Ref {
    name: "OrderByClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AliasExpressionSegment'
pub static ALIAS_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// AliasExpressionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "AsAliasOperatorSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierListSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='AliasKeywordSegment'
pub static ALIAS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ALIAS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AliasedTableReferenceGrammar'
pub static ALIASED_TABLE_REFERENCE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AliasExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='AllKeywordSegment'
pub static ALL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ALL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AllocateKeywordSegment'
pub static ALLOCATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ALLOCATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AlsoKeywordSegment'
pub static ALSO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ALSO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AlterDatabaseStatementSegment'
pub static ALTER_DATABASE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// AlterDatabaseStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AlterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string(), "SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "SetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DbpropertiesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DBPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedPropertyListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DBPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OwnerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OWNER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string(), "USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OWNER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LocationGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ManagedlocationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MANAGEDLOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MANAGEDLOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DBPROPERTIES".to_string(), "LOCATION".to_string(), "MANAGEDLOCATION".to_string(), "OWNER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AlterKeywordSegment'
pub static ALTER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ALTER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AlterSequenceOptionsSegment'
pub static ALTER_SEQUENCE_OPTIONS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// AlterSequenceOptionsSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IncrementKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INCREMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INCREMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceMinValueGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MINVALUE".to_string(), "NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceMaxValueGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAXVALUE".to_string(), "NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CacheKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NocacheKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOCACHE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string(), "NOCACHE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CycleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CYCLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NocycleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOCYCLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CYCLE".to_string(), "NOCYCLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrderNoOrderGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOORDER".to_string(), "ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string(), "CYCLE".to_string(), "INCREMENT".to_string(), "MAXVALUE".to_string(), "MINVALUE".to_string(), "NO".to_string(), "NOCACHE".to_string(), "NOCYCLE".to_string(), "NOORDER".to_string(), "ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AlterSequenceStatementSegment'
pub static ALTER_SEQUENCE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// AlterSequenceStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AlterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AlterSequenceOptionsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string(), "CYCLE".to_string(), "INCREMENT".to_string(), "MAXVALUE".to_string(), "MINVALUE".to_string(), "NO".to_string(), "NOCACHE".to_string(), "NOCYCLE".to_string(), "NOORDER".to_string(), "ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string(), "CYCLE".to_string(), "INCREMENT".to_string(), "MAXVALUE".to_string(), "MINVALUE".to_string(), "NO".to_string(), "NOCACHE".to_string(), "NOCYCLE".to_string(), "NOORDER".to_string(), "ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AlterTableDropColumnGrammar'
pub static ALTER_TABLE_DROP_COLUMN_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COLUMN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AlterTableOptionsGrammar'
pub static ALTER_TABLE_OPTIONS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ParameterNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "EqualsSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NakedIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AddKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ModifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MODIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string(), "MODIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COLUMN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnDefinitionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FirstKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIRST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AfterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AFTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AFTER".to_string(), "FIRST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AFTER".to_string(), "FIRST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "AFTER".to_string(), "FIRST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string(), "MODIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AlterTableDropColumnGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RenameKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RENAME".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ToKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string(), "TO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RENAME".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExchangeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCHANGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PartitionSpecGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCHANGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='AlterTableStatementSegment'
pub static ALTER_TABLE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// AlterTableStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AlterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AlterTableOptionsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AlterViewStatementSegment'
pub static ALTER_VIEW_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// AlterViewStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AlterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TablePropertiesGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TBLPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string(), "SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AlwaysKeywordSegment'
pub static ALWAYS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ALWAYS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AmpersandSegment'
pub static AMPERSAND_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "&",
    token_type: "ampersand",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='AnalyseKeywordSegment'
pub static ANALYSE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ANALYSE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AnalyticKeywordSegment'
pub static ANALYTIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ANALYTIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AnalyzeKeywordSegment'
pub static ANALYZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ANALYZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AndKeywordSegment'
pub static AND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AndOperatorGrammar'
pub static AND_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AND",
    token_type: "binary_operator",
    raw_class: "BinaryOperatorSegment",
    optional: false,
})
);

// name='AntiKeywordSegment'
pub static ANTI_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ANTI",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AnyKeywordSegment'
pub static ANY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ANY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Api_versionKeywordSegment'
pub static API_VERSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "API_VERSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ApplyKeywordSegment'
pub static APPLY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "APPLY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ArchiveKeywordSegment'
pub static ARCHIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ARCHIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AreKeywordSegment'
pub static ARE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ARE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ArithmeticBinaryOperatorGrammar'
pub static ARITHMETIC_BINARY_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PlusSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MinusSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DivideSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["/".to_string(), "DIV".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MultiplySegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["*".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ModuloSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["%".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BitwiseAndSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["&".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BitwiseOrSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BitwiseXorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["^".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BitwiseLShiftSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BitwiseRShiftSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), ">".to_string(), "DIV".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ArrayAccessorSegment'
pub static ARRAY_ACCESSOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ArrayAccessorSegment
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "SliceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([":".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "[",
    token_type: "start_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: "]",
    token_type: "end_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Greedy,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ArrayExpressionSegment'
pub static ARRAY_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ArrayExpressionSegment
Arc::new(Grammar::Nothing())
);

// name='ArrayKeywordSegment'
pub static ARRAY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ARRAY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ArrayLiteralSegment'
pub static ARRAY_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ArrayLiteralSegment
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BaseExpressionElementGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: true,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "[",
    token_type: "start_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: "]",
    token_type: "end_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ArrayTypeSegment'
pub static ARRAY_TYPE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ArrayTypeSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ArrayKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "<",
    token_type: "start_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ">",
    token_type: "end_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Array_aggKeywordSegment'
pub static ARRAY_AGG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ARRAY_AGG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Array_max_cardinalityKeywordSegment'
pub static ARRAY_MAX_CARDINALITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ARRAY_MAX_CARDINALITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AsAliasOperatorSegment'
pub static AS_ALIAS_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// AsAliasOperatorSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='AsKeywordSegment'
pub static AS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AscKeywordSegment'
pub static ASC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ASC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AsensitiveKeywordSegment'
pub static ASENSITIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ASENSITIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AssertionKeywordSegment'
pub static ASSERTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ASSERTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AssignmentKeywordSegment'
pub static ASSIGNMENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ASSIGNMENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AsymmetricKeywordSegment'
pub static ASYMMETRIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ASYMMETRIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AtKeywordSegment'
pub static AT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AtomicKeywordSegment'
pub static ATOMIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ATOMIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AttributeKeywordSegment'
pub static ATTRIBUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ATTRIBUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AttributesKeywordSegment'
pub static ATTRIBUTES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ATTRIBUTES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AuditKeywordSegment'
pub static AUDIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AUDIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AuthorizationKeywordSegment'
pub static AUTHORIZATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AUTHORIZATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AutoIncrementGrammar'
pub static AUTO_INCREMENT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Auto_incrementKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AUTO_INCREMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AUTO_INCREMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Auto_incrementKeywordSegment'
pub static AUTO_INCREMENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AUTO_INCREMENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AutocommitKeywordSegment'
pub static AUTOCOMMIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AUTOCOMMIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AvgKeywordSegment'
pub static AVG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AVG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Avg_row_lengthKeywordSegment'
pub static AVG_ROW_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AVG_ROW_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='AvroKeywordSegment'
pub static AVRO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "AVRO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BackQuotedIdentifierSegment'
pub static BACK_QUOTED_IDENTIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::TypedParser {
    template: "back_quote",
    token_type: "quoted_identifier",
    raw_class: "IdentifierSegment",
    optional: false,
})
);

// name='BackupKeywordSegment'
pub static BACKUP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BACKUP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BackwardKeywordSegment'
pub static BACKWARD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BACKWARD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BareFunctionSegment'
pub static BARE_FUNCTION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::MultiStringParser {
    templates: vec!["CURRENT_DATE", "CURRENT_TIME", "CURRENT_TIMESTAMP"],
    token_type: "bare_function",
    raw_class: "CodeSegment",
    optional: false,
})
);

// name='BaseExpressionElementGrammar'
pub static BASE_EXPRESSION_ELEMENT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BareFunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT_DATE".to_string(), "CURRENT_TIME".to_string(), "CURRENT_TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntervalExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "INTERVAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='BaseFileSegment'
pub static BASE_FILE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "file",
//    token_type: "BaseFileSegment",
})
);

// name='BaseSegment'
pub static BASE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "base",
//    token_type: "BaseSegment",
})
);

// name='BeforeKeywordSegment'
pub static BEFORE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BEFORE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BeginKeywordSegment'
pub static BEGIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BEGIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Begin_frameKeywordSegment'
pub static BEGIN_FRAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BEGIN_FRAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Begin_partitionKeywordSegment'
pub static BEGIN_PARTITION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BEGIN_PARTITION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BernoulliKeywordSegment'
pub static BERNOULLI_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BERNOULLI",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BetweenKeywordSegment'
pub static BETWEEN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BETWEEN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BigintKeywordSegment'
pub static BIGINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BIGINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BinaryKeywordSegment'
pub static BINARY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BINARY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BinaryOperatorGrammar'
pub static BINARY_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ArithmeticBinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), ">".to_string(), "DIV".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StringBinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BooleanBinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string(), "OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ComparisonOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "AND".to_string(), "DIV".to_string(), "IS".to_string(), "OR".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
);

// name='BinaryOperatorSegment'
pub static BINARY_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "binary_operator",
//    token_type: "BinaryOperatorSegment",
})
);

// name='BindingKeywordSegment'
pub static BINDING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BINDING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BitKeywordSegment'
pub static BIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Bit_lengthKeywordSegment'
pub static BIT_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BIT_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BitvarKeywordSegment'
pub static BITVAR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BITVAR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BitwiseAndSegment'
pub static BITWISE_AND_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// BitwiseAndSegment
Arc::new(Grammar::Ref {
    name: "AmpersandSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["&".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BitwiseLShiftSegment'
pub static BITWISE_L_SHIFT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// BitwiseLShiftSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RawLessThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RawLessThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BitwiseOrSegment'
pub static BITWISE_OR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// BitwiseOrSegment
Arc::new(Grammar::Ref {
    name: "PipeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BitwiseRShiftSegment'
pub static BITWISE_R_SHIFT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// BitwiseRShiftSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RawGreaterThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RawGreaterThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BitwiseXorSegment'
pub static BITWISE_XOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "^",
    token_type: "binary_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='BlobKeywordSegment'
pub static BLOB_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BLOB",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Block_sizeKeywordSegment'
pub static BLOCK_SIZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BLOCK_SIZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BoolKeywordSegment'
pub static BOOL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BOOL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BooleanBinaryOperatorGrammar'
pub static BOOLEAN_BINARY_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AndOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string(), "OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BooleanKeywordSegment'
pub static BOOLEAN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BOOLEAN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BooleanLiteralGrammar'
pub static BOOLEAN_LITERAL_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TrueSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FalseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FALSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FALSE".to_string(), "TRUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BothKeywordSegment'
pub static BOTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BOTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BracketedArguments'
pub static BRACKETED_ARGUMENTS: Lazy<Arc<Grammar>> = Lazy::new(||
// BracketedArguments
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: true,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BracketedColumnReferenceListGrammar'
pub static BRACKETED_COLUMN_REFERENCE_LIST_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BracketedPropertyListGrammar'
pub static BRACKETED_PROPERTY_LIST_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PropertyGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BracketedSegment'
pub static BRACKETED_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "bracketed",
//    token_type: "BracketedSegment",
})
);

// name='BracketedSetExpressionGrammar'
pub static BRACKETED_SET_EXPRESSION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UnorderedSetExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='BreadthKeywordSegment'
pub static BREADTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BREADTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BreakKeywordSegment'
pub static BREAK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BREAK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BrowseKeywordSegment'
pub static BROWSE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BROWSE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BucketKeywordSegment'
pub static BUCKET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BUCKET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BucketsKeywordSegment'
pub static BUCKETS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BUCKETS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='BulkKeywordSegment'
pub static BULK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BULK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ByKeywordSegment'
pub static BY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "BY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CTEColumnList'
pub static C_T_E_COLUMN_LIST: Lazy<Arc<Grammar>> = Lazy::new(||
// CTEColumnList
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierListSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CTEDefinitionSegment'
pub static C_T_E_DEFINITION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CTEDefinitionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "CTEColumnList",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Greedy,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='CacheKeywordSegment'
pub static CACHE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CACHE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CachedKeywordSegment'
pub static CACHED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CACHED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CallKeywordSegment'
pub static CALL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CALL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CalledKeywordSegment'
pub static CALLED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CALLED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CardinalityKeywordSegment'
pub static CARDINALITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CARDINALITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CascadeKeywordSegment'
pub static CASCADE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CASCADE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CascadedKeywordSegment'
pub static CASCADED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CASCADED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CaseExpressionSegment'
pub static CASE_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CaseExpressionSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhenClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ElseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ELSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "EndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["END".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: true,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ElseClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "EndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["END".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: true,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ELSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Ref {
    name: "EndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["END".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhenClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ElseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ELSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "EndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["END".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: true,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ElseClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "EndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["END".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: true,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ELSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Ref {
    name: "EndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["END".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ComparisonOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "AND".to_string(), "DIV".to_string(), "IS".to_string(), "OR".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CaseKeywordSegment'
pub static CASE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CASE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CastKeywordSegment'
pub static CAST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CAST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CastOperatorSegment'
pub static CAST_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "::",
    token_type: "casting_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='CatalogKeywordSegment'
pub static CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Catalog_nameKeywordSegment'
pub static CATALOG_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CATALOG_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CeilKeywordSegment'
pub static CEIL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CEIL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CeilingKeywordSegment'
pub static CEILING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CEILING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ChainKeywordSegment'
pub static CHAIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHAIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ChangeKeywordSegment'
pub static CHANGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHANGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CharCharacterSetGrammar'
pub static CHAR_CHARACTER_SET_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='CharKeywordSegment'
pub static CHAR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHAR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Char_lengthKeywordSegment'
pub static CHAR_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHAR_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CharacterKeywordSegment'
pub static CHARACTER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHARACTER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Character_lengthKeywordSegment'
pub static CHARACTER_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHARACTER_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Character_set_catalogKeywordSegment'
pub static CHARACTER_SET_CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHARACTER_SET_CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Character_set_nameKeywordSegment'
pub static CHARACTER_SET_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHARACTER_SET_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Character_set_schemaKeywordSegment'
pub static CHARACTER_SET_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHARACTER_SET_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CharacteristicsKeywordSegment'
pub static CHARACTERISTICS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHARACTERISTICS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CharactersKeywordSegment'
pub static CHARACTERS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHARACTERS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CheckKeywordSegment'
pub static CHECK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHECK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CheckedKeywordSegment'
pub static CHECKED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHECKED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CheckpointKeywordSegment'
pub static CHECKPOINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHECKPOINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ChecksumKeywordSegment'
pub static CHECKSUM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CHECKSUM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ClassKeywordSegment'
pub static CLASS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CLASS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Class_originKeywordSegment'
pub static CLASS_ORIGIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CLASS_ORIGIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ClobKeywordSegment'
pub static CLOB_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CLOB",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CloseKeywordSegment'
pub static CLOSE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CLOSE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Close_fnKeywordSegment'
pub static CLOSE_FN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CLOSE_FN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ClusterByClauseSegment'
pub static CLUSTER_BY_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ClusterByClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ClusterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "LimitKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FrameClauseUnitGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ClusterKeywordSegment'
pub static CLUSTER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CLUSTER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ClusteredKeywordSegment'
pub static CLUSTERED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CLUSTERED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ClusterstatusKeywordSegment'
pub static CLUSTERSTATUS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CLUSTERSTATUS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CoalesceKeywordSegment'
pub static COALESCE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COALESCE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CobolKeywordSegment'
pub static COBOL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COBOL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CodeSegment'
pub static CODE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "raw",
//    token_type: "CodeSegment",
})
);

// name='CollateGrammar'
pub static COLLATE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='CollateKeywordSegment'
pub static COLLATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLLATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CollationKeywordSegment'
pub static COLLATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLLATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CollationReferenceSegment'
pub static COLLATION_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CollationReferenceSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Collation_catalogKeywordSegment'
pub static COLLATION_CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLLATION_CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Collation_nameKeywordSegment'
pub static COLLATION_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLLATION_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Collation_schemaKeywordSegment'
pub static COLLATION_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLLATION_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CollectKeywordSegment'
pub static COLLECT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLLECT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CollectionKeywordSegment'
pub static COLLECTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLLECTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ColonDelimiterSegment'
pub static COLON_DELIMITER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ":",
    token_type: "colon_delimiter",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='ColonPrefixSegment'
pub static COLON_PREFIX_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ":",
    token_type: "colon_prefix",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='ColonSegment'
pub static COLON_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ":",
    token_type: "colon",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='ColumnConstraintDefaultGrammar'
pub static COLUMN_CONSTRAINT_DEFAULT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ShorthandCastSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "BareFunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT_DATE".to_string(), "CURRENT_TIME".to_string(), "CURRENT_TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ColumnConstraintSegment'
pub static COLUMN_CONSTRAINT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ColumnConstraintSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ConstraintKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRAINT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRAINT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NullKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string(), "NULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CheckKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CHECK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CHECK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DefaultKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFAULT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnConstraintDefaultGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFAULT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PrimaryKeyGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIMARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NotEnforcedGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIMARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UniqueKeyGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AutoIncrementGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AUTO_INCREMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ReferenceDefinitionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NotEnforcedGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommentClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CollateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COLLATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CollationReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COLLATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnGeneratedGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ColumnDefinitionSegment'
pub static COLUMN_DEFINITION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ColumnDefinitionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Anything)
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnConstraintSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ColumnGeneratedGrammar'
pub static COLUMN_GENERATED_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='ColumnKeywordSegment'
pub static COLUMN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLUMN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ColumnReferenceSegment'
pub static COLUMN_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ColumnReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Column_nameKeywordSegment'
pub static COLUMN_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLUMN_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ColumnsExpressionFunctionContentsSegment'
pub static COLUMNS_EXPRESSION_FUNCTION_CONTENTS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ColumnsExpressionFunctionContentsSegment
Arc::new(Grammar::Nothing())
);

// name='ColumnsExpressionFunctionNameSegment'
pub static COLUMNS_EXPRESSION_FUNCTION_NAME_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ColumnsExpressionFunctionNameSegment
Arc::new(Grammar::Ref {
    name: "ColumnsExpressionNameGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
);

// name='ColumnsExpressionGrammar'
pub static COLUMNS_EXPRESSION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='ColumnsExpressionNameGrammar'
pub static COLUMNS_EXPRESSION_NAME_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='ColumnsKeywordSegment'
pub static COLUMNS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COLUMNS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CommaSegment'
pub static COMMA_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ",",
    token_type: "comma",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='Command_functionKeywordSegment'
pub static COMMAND_FUNCTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMMAND_FUNCTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Command_function_codeKeywordSegment'
pub static COMMAND_FUNCTION_CODE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMMAND_FUNCTION_CODE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CommentClauseSegment'
pub static COMMENT_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CommentClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CommentKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CommentGrammar'
pub static COMMENT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CommentKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CommentKeywordSegment'
pub static COMMENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMMENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CommentSegment'
pub static COMMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "comment",
//    token_type: "CommentSegment",
})
);

// name='CommitKeywordSegment'
pub static COMMIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMMIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CommittedKeywordSegment'
pub static COMMITTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMMITTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CompactKeywordSegment'
pub static COMPACT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMPACT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CompactionsKeywordSegment'
pub static COMPACTIONS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMPACTIONS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ComparisonOperatorGrammar'
pub static COMPARISON_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "EqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GreaterThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LessThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GreaterThanOrEqualToSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LessThanOrEqualToSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NotEqualToSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LikeOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IsDistinctFromGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
);

// name='ComparisonOperatorSegment'
pub static COMPARISON_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "comparison_operator",
//    token_type: "ComparisonOperatorSegment",
})
);

// name='CompletionKeywordSegment'
pub static COMPLETION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMPLETION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CompositeBinaryOperatorSegment'
pub static COMPOSITE_BINARY_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "binary_operator",
//    token_type: "CompositeBinaryOperatorSegment",
})
);

// name='CompositeComparisonOperatorSegment'
pub static COMPOSITE_COMPARISON_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "comparison_operator",
//    token_type: "CompositeComparisonOperatorSegment",
})
);

// name='CompressKeywordSegment'
pub static COMPRESS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMPRESS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CompressionKeywordSegment'
pub static COMPRESSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMPRESSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ComputeKeywordSegment'
pub static COMPUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COMPUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ComputeStatsStatementSegment'
pub static COMPUTE_STATS_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ComputeStatsStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ComputeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMPUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StatsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STATS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STATS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IncrementalKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INCREMENTAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StatsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STATS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "PartitionSpecGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INCREMENTAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INCREMENTAL".to_string(), "STATS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMPUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ConcatSegment'
pub static CONCAT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ConcatSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PipeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PipeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ConcatenateKeywordSegment'
pub static CONCATENATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONCATENATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConditionKeywordSegment'
pub static CONDITION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONDITION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Condition_numberKeywordSegment'
pub static CONDITION_NUMBER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONDITION_NUMBER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConditionalCrossJoinKeywordsGrammar'
pub static CONDITIONAL_CROSS_JOIN_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Ref {
    name: "CrossKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CROSS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ConditionalJoinKeywordsGrammar'
pub static CONDITIONAL_JOIN_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "JoinTypeKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FULL".to_string(), "INNER".to_string(), "LEFT".to_string(), "RIGHT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ConditionalCrossJoinKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CROSS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NonStandardJoinTypeKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ConfKeywordSegment'
pub static CONF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConnectKeywordSegment'
pub static CONNECT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONNECT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConnectionKeywordSegment'
pub static CONNECTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONNECTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Connection_nameKeywordSegment'
pub static CONNECTION_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONNECTION_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConstraintKeywordSegment'
pub static CONSTRAINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONSTRAINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Constraint_catalogKeywordSegment'
pub static CONSTRAINT_CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONSTRAINT_CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Constraint_nameKeywordSegment'
pub static CONSTRAINT_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONSTRAINT_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Constraint_schemaKeywordSegment'
pub static CONSTRAINT_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONSTRAINT_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConstraintsKeywordSegment'
pub static CONSTRAINTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONSTRAINTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConstructorKeywordSegment'
pub static CONSTRUCTOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONSTRUCTOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ContainsKeywordSegment'
pub static CONTAINS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONTAINS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ContainstableKeywordSegment'
pub static CONTAINSTABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONTAINSTABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ContinueKeywordSegment'
pub static CONTINUE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONTINUE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConversionKeywordSegment'
pub static CONVERSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONVERSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ConvertKeywordSegment'
pub static CONVERT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CONVERT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CopyKeywordSegment'
pub static COPY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COPY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CorrKeywordSegment'
pub static CORR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CORR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CorrespondingKeywordSegment'
pub static CORRESPONDING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CORRESPONDING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CountKeywordSegment'
pub static COUNT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COUNT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Covar_popKeywordSegment'
pub static COVAR_POP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COVAR_POP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Covar_sampKeywordSegment'
pub static COVAR_SAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "COVAR_SAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CreateCastStatementSegment'
pub static CREATE_CAST_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateCastStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CastKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CAST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SpecificKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SPECIFIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RoutineKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROUTINE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProcedureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InstanceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSTANCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StaticKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STATIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ConstructorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRUCTOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRUCTOR".to_string(), "INSTANCE".to_string(), "STATIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MethodKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["METHOD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRUCTOR".to_string(), "INSTANCE".to_string(), "METHOD".to_string(), "STATIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRUCTOR".to_string(), "FUNCTION".to_string(), "INSTANCE".to_string(), "METHOD".to_string(), "PROCEDURE".to_string(), "ROUTINE".to_string(), "STATIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FunctionParameterListGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ForKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AssignmentKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ASSIGNMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateDatabaseStatementSegment'
pub static CREATE_DATABASE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateDatabaseStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string(), "SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "CommentGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LocationGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ManagedlocationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MANAGEDLOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MANAGEDLOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DbpropertiesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DBPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedPropertyListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateFunctionStatementSegment'
pub static CREATE_FUNCTION_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateFunctionStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrReplaceGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TemporaryGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMP".to_string(), "TEMPORARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FunctionParameterListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ReturnsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RETURNS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RETURNS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionDefinitionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateIndexStatementSegment'
pub static CREATE_INDEX_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateIndexStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrReplaceGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UniqueKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IndexKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INDEX".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IndexReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IndexColumnDefinitionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateKeywordSegment'
pub static CREATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CREATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CreateModelStatementSegment'
pub static CREATE_MODEL_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateModelStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrReplaceGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ModelKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MODEL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OptionsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OPTIONS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ParameterNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "EqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "[",
    token_type: "start_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: "]",
    token_type: "end_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OPTIONS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateRoleStatementSegment'
pub static CREATE_ROLE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateRoleStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateSchemaStatementSegment'
pub static CREATE_SCHEMA_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateSchemaStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateSequenceOptionsSegment'
pub static CREATE_SEQUENCE_OPTIONS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateSequenceOptionsSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IncrementKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INCREMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INCREMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StartKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["START".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["START".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceMinValueGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MINVALUE".to_string(), "NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceMaxValueGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAXVALUE".to_string(), "NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CacheKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NocacheKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOCACHE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string(), "NOCACHE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CycleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CYCLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NocycleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOCYCLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CYCLE".to_string(), "NOCYCLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrderNoOrderGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOORDER".to_string(), "ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string(), "CYCLE".to_string(), "INCREMENT".to_string(), "MAXVALUE".to_string(), "MINVALUE".to_string(), "NO".to_string(), "NOCACHE".to_string(), "NOCYCLE".to_string(), "NOORDER".to_string(), "ORDER".to_string(), "START".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateSequenceStatementSegment'
pub static CREATE_SEQUENCE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateSequenceStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateSequenceOptionsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string(), "CYCLE".to_string(), "INCREMENT".to_string(), "MAXVALUE".to_string(), "MINVALUE".to_string(), "NO".to_string(), "NOCACHE".to_string(), "NOCYCLE".to_string(), "NOORDER".to_string(), "ORDER".to_string(), "START".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHE".to_string(), "CYCLE".to_string(), "INCREMENT".to_string(), "MAXVALUE".to_string(), "MINVALUE".to_string(), "NO".to_string(), "NOCACHE".to_string(), "NOCYCLE".to_string(), "NOORDER".to_string(), "ORDER".to_string(), "START".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateTableAsSelectStatementSegment'
pub static CREATE_TABLE_AS_SELECT_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateTableAsSelectStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExternalKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PartitionedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITIONED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnDefinitionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "CommentGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITIONED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommentGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowFormatClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SerdePropertiesGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StoredAsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LocationGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CachedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PoolNameReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReplicationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REPLICATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "=KeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UncachedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNCACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHED".to_string(), "UNCACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHED".to_string(), "UNCACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TablePropertiesGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TBLPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateTableStatementSegment'
pub static CREATE_TABLE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateTableStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExternalKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXTERNAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableConstraintSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRAINT".to_string(), "FOREIGN".to_string(), "PRIMARY".to_string(), "UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnDefinitionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "CommentGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PartitionedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITIONED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnDefinitionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "CommentGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITIONED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommentGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowFormatClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SerdePropertiesGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StoredAsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LocationGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CachedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PoolNameReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReplicationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REPLICATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "=KeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UncachedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNCACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHED".to_string(), "UNCACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CACHED".to_string(), "UNCACHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TablePropertiesGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TBLPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateTriggerStatementSegment'
pub static CREATE_TRIGGER_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateTriggerStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TriggerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRIGGER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TriggerReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BeforeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BEFORE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AfterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AFTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InsteadKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSTEAD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OfKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSTEAD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AFTER".to_string(), "BEFORE".to_string(), "INSTEAD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InsertKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeleteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UpdateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OfKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "OrKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "OrKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string(), "INSERT".to_string(), "UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ReferencingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OldKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OLD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ParameterNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ParameterNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeferrableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFERRABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DeferrableKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFERRABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InitiallyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INITIALLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ImmediateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IMMEDIATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INITIALLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InitiallyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INITIALLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeferredKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFERRED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INITIALLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INITIALLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFERRABLE".to_string(), "INITIALLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFERRABLE".to_string(), "INITIALLY".to_string(), "NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ForKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "EachKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EACH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StatementKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STATEMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string(), "STATEMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFERRABLE".to_string(), "FOR".to_string(), "FROM".to_string(), "INITIALLY".to_string(), "NOT".to_string(), "REFERENCING".to_string(), "WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExecuteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ProcedureKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PROCEDURE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionNameIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["word".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionContentsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXECUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateUserStatementSegment'
pub static CREATE_USER_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateUserStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreateViewStatementSegment'
pub static CREATE_VIEW_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CreateViewStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CreateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrReplaceGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithNoSchemaBindingClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='CreatedbKeywordSegment'
pub static CREATEDB_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CREATEDB",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CreateroleKeywordSegment'
pub static CREATEROLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CREATEROLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CreateuserKeywordSegment'
pub static CREATEUSER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CREATEUSER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CrossKeywordSegment'
pub static CROSS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CROSS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CsvKeywordSegment'
pub static CSV_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CSV",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CubeFunctionNameSegment'
pub static CUBE_FUNCTION_NAME_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CubeFunctionNameSegment
Arc::new(Grammar::StringParser {
    template: "CUBE",
    token_type: "function_name_identifier",
    raw_class: "CodeSegment",
    optional: false,
})
);

// name='CubeKeywordSegment'
pub static CUBE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CUBE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CubeRollupClauseSegment'
pub static CUBE_ROLLUP_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// CubeRollupClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CubeFunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CUBE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RollupFunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLLUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CUBE".to_string(), "ROLLUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupingExpressionList",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CUBE".to_string(), "ROLLUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Cume_distKeywordSegment'
pub static CUME_DIST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CUME_DIST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CurrentKeywordSegment'
pub static CURRENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_dateKeywordSegment'
pub static CURRENT_DATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_DATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_default_transform_groupKeywordSegment'
pub static CURRENT_DEFAULT_TRANSFORM_GROUP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_DEFAULT_TRANSFORM_GROUP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_pathKeywordSegment'
pub static CURRENT_PATH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_PATH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_roleKeywordSegment'
pub static CURRENT_ROLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_ROLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_rowKeywordSegment'
pub static CURRENT_ROW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_ROW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_schemaKeywordSegment'
pub static CURRENT_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_timeKeywordSegment'
pub static CURRENT_TIME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_TIME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_timestampKeywordSegment'
pub static CURRENT_TIMESTAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_TIMESTAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_transform_group_for_typeKeywordSegment'
pub static CURRENT_TRANSFORM_GROUP_FOR_TYPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_TRANSFORM_GROUP_FOR_TYPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Current_userKeywordSegment'
pub static CURRENT_USER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURRENT_USER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CursorKeywordSegment'
pub static CURSOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURSOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Cursor_nameKeywordSegment'
pub static CURSOR_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CURSOR_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='CycleKeywordSegment'
pub static CYCLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "CYCLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DataKeywordSegment'
pub static DATA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DATA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DatabaseKeywordSegment'
pub static DATABASE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DATABASE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DatabaseReferenceSegment'
pub static DATABASE_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DatabaseReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='DatabasesKeywordSegment'
pub static DATABASES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DATABASES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DatatypeIdentifierSegment'
pub static DATATYPE_IDENTIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::RegexParser {
    template: RegexMode::new(r#"[A-Z_][A-Z0-9_]*"#),
    token_type: "data_type_identifier",
    raw_class: "CodeSegment",
    optional: false,
    anti_template: Some(RegexMode::new(r#"^(NOT)$"#)),
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::Ref {
    name: "NakedIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='DatatypeSegment'
pub static DATATYPE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DatatypeSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PrimitiveTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ArrayTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SizedArrayTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MapKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PrimitiveTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "<",
    token_type: "start_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ">",
    token_type: "end_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StructTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UniontypeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNIONTYPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "<",
    token_type: "start_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ">",
    token_type: "end_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNIONTYPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DateKeywordSegment'
pub static DATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DatePartFunctionName'
pub static DATE_PART_FUNCTION_NAME: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::MultiStringParser {
    templates: vec!["DATEADD"],
    token_type: "function_name_identifier",
    raw_class: "CodeSegment",
    optional: false,
})
);

// name='DatePartFunctionNameSegment'
pub static DATE_PART_FUNCTION_NAME_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DatePartFunctionNameSegment
Arc::new(Grammar::Ref {
    name: "DatePartFunctionName",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATEADD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DateTimeFunctionContentsSegment'
pub static DATE_TIME_FUNCTION_CONTENTS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DateTimeFunctionContentsSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatetimeUnitSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DAY".to_string(), "DAYOFYEAR".to_string(), "DAYS".to_string(), "HOUR".to_string(), "HOURS".to_string(), "MILLISECOND".to_string(), "MINUTE".to_string(), "MINUTES".to_string(), "MONTH".to_string(), "MONTHS".to_string(), "NANO".to_string(), "NANOS".to_string(), "QUARTER".to_string(), "SECOND".to_string(), "SECONDS".to_string(), "WEEK".to_string(), "WEEKDAY".to_string(), "WEEKS".to_string(), "YEAR".to_string(), "YEARS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionContentsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DateTimeLiteralGrammar'
pub static DATE_TIME_LITERAL_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TimeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIME".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TimestampKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntervalKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTERVAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string(), "INTERVAL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::TypedParser {
    template: "single_quote",
    token_type: "date_constructor_literal",
    raw_class: "LiteralSegment",
    optional: false,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string(), "INTERVAL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DatetimeKeywordSegment'
pub static DATETIME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DATETIME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DatetimeUnitSegment'
pub static DATETIME_UNIT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::MultiStringParser {
    templates: vec!["DAY", "DAYOFYEAR", "DAYS", "HOUR", "HOURS", "MILLISECOND", "MINUTE", "MINUTES", "MONTH", "MONTHS", "NANO", "NANOS", "QUARTER", "SECOND", "SECONDS", "WEEK", "WEEKDAY", "WEEKS", "YEAR", "YEARS"],
    token_type: "date_part",
    raw_class: "CodeSegment",
    optional: false,
})
);

// name='Datetime_interval_codeKeywordSegment'
pub static DATETIME_INTERVAL_CODE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DATETIME_INTERVAL_CODE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Datetime_interval_precisionKeywordSegment'
pub static DATETIME_INTERVAL_PRECISION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DATETIME_INTERVAL_PRECISION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DayKeywordSegment'
pub static DAY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Day_hourKeywordSegment'
pub static DAY_HOUR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAY_HOUR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Day_microsecondKeywordSegment'
pub static DAY_MICROSECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAY_MICROSECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Day_minuteKeywordSegment'
pub static DAY_MINUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAY_MINUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Day_secondKeywordSegment'
pub static DAY_SECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAY_SECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DayofmonthKeywordSegment'
pub static DAYOFMONTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAYOFMONTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DayofweekKeywordSegment'
pub static DAYOFWEEK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAYOFWEEK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DayofyearKeywordSegment'
pub static DAYOFYEAR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAYOFYEAR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DaysKeywordSegment'
pub static DAYS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DAYS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DbccKeywordSegment'
pub static DBCC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DBCC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DbpropertiesKeywordSegment'
pub static DBPROPERTIES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DBPROPERTIES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DeallocateKeywordSegment'
pub static DEALLOCATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEALLOCATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DecKeywordSegment'
pub static DEC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DecfloatKeywordSegment'
pub static DECFLOAT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DECFLOAT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DecimalKeywordSegment'
pub static DECIMAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DECIMAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DeclareKeywordSegment'
pub static DECLARE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DECLARE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Dedent'
pub static DEDENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Meta("dedent"))
);

// name='DefaultKeywordSegment'
pub static DEFAULT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEFAULT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DefaultValuesGrammar'
pub static DEFAULT_VALUES_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DefaultKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFAULT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ValuesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFAULT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DefaultsKeywordSegment'
pub static DEFAULTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEFAULTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DeferrableKeywordSegment'
pub static DEFERRABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEFERRABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DeferredKeywordSegment'
pub static DEFERRED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEFERRED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DefineKeywordSegment'
pub static DEFINE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEFINE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DefinedKeywordSegment'
pub static DEFINED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEFINED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DefinerKeywordSegment'
pub static DEFINER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEFINER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DegreeKeywordSegment'
pub static DEGREE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEGREE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Delay_key_writeKeywordSegment'
pub static DELAY_KEY_WRITE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DELAY_KEY_WRITE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DelayedKeywordSegment'
pub static DELAYED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DELAYED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DeleteKeywordSegment'
pub static DELETE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DELETE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DeleteStatementSegment'
pub static DELETE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DeleteStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DeleteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WhereClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DelimitedKeywordSegment'
pub static DELIMITED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DELIMITED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DelimiterGrammar'
pub static DELIMITER_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Ref {
    name: "SemicolonSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DelimiterKeywordSegment'
pub static DELIMITER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DELIMITER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DelimitersKeywordSegment'
pub static DELIMITERS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DELIMITERS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Dense_rankKeywordSegment'
pub static DENSE_RANK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DENSE_RANK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DenyKeywordSegment'
pub static DENY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DENY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DependencyKeywordSegment'
pub static DEPENDENCY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEPENDENCY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DepthKeywordSegment'
pub static DEPTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEPTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DerefKeywordSegment'
pub static DEREF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DEREF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DerivedKeywordSegment'
pub static DERIVED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DERIVED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DescKeywordSegment'
pub static DESC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DESC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DescribeKeywordSegment'
pub static DESCRIBE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DESCRIBE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DescribeStatementSegment'
pub static DESCRIBE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DescribeStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DescribeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DESCRIBE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NakedIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DESCRIBE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DescriptorKeywordSegment'
pub static DESCRIPTOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DESCRIPTOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DestroyKeywordSegment'
pub static DESTROY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DESTROY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DestructorKeywordSegment'
pub static DESTRUCTOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DESTRUCTOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DetailKeywordSegment'
pub static DETAIL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DETAIL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DeterministicKeywordSegment'
pub static DETERMINISTIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DETERMINISTIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DiagnosticsKeywordSegment'
pub static DIAGNOSTICS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DIAGNOSTICS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DictionaryKeywordSegment'
pub static DICTIONARY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DICTIONARY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DirectoriesKeywordSegment'
pub static DIRECTORIES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DIRECTORIES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DirectoryKeywordSegment'
pub static DIRECTORY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DIRECTORY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DisableKeywordSegment'
pub static DISABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DISABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DisconnectKeywordSegment'
pub static DISCONNECT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DISCONNECT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DiskKeywordSegment'
pub static DISK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DISK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DispatchKeywordSegment'
pub static DISPATCH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DISPATCH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DistinctKeywordSegment'
pub static DISTINCT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DISTINCT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DistinctrowKeywordSegment'
pub static DISTINCTROW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DISTINCTROW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DistributeByClauseSegment'
pub static DISTRIBUTE_BY_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DistributeByClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DistributeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LimitKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "HavingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QualifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["QUALIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WindowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FrameClauseUnitGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SeparatorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEPARATOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DistributeKeywordSegment'
pub static DISTRIBUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DISTRIBUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DistributedKeywordSegment'
pub static DISTRIBUTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DISTRIBUTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DivKeywordSegment'
pub static DIV_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DIV",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DivideSegment'
pub static DIVIDE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::StringParser {
    template: "DIV",
    token_type: "binary_operator",
    raw_class: "BinaryOperatorSegment",
    optional: false,
})
,
Arc::new(Grammar::StringParser {
    template: "/",
    token_type: "binary_operator",
    raw_class: "BinaryOperatorSegment",
    optional: false,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["/".to_string(), "DIV".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DoKeywordSegment'
pub static DO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DomainKeywordSegment'
pub static DOMAIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DOMAIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DotSegment'
pub static DOT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ".",
    token_type: "dot",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='DoubleKeywordSegment'
pub static DOUBLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DOUBLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DowKeywordSegment'
pub static DOW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DOW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DropBehaviorGrammar'
pub static DROP_BEHAVIOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RestrictKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CascadeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropCastStatementSegment'
pub static DROP_CAST_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropCastStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CastKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CAST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropBehaviorGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropDatabaseStatementSegment'
pub static DROP_DATABASE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropDatabaseStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATABASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DropBehaviorGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropFunctionStatementSegment'
pub static DROP_FUNCTION_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropFunctionStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FUNCTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropIndexStatementSegment'
pub static DROP_INDEX_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropIndexStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IndexKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INDEX".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IndexReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DropBehaviorGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropKeywordSegment'
pub static DROP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DROP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DropModelStatementSegment'
pub static DROP_MODEL_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropModelStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ModelKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MODEL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropRoleStatementSegment'
pub static DROP_ROLE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropRoleStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropSchemaStatementSegment'
pub static DROP_SCHEMA_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropSchemaStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DropBehaviorGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropSequenceStatementSegment'
pub static DROP_SEQUENCE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropSequenceStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SequenceReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropTableStatementSegment'
pub static DROP_TABLE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropTableStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "PurgeKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PURGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropTriggerStatementSegment'
pub static DROP_TRIGGER_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropTriggerStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TriggerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRIGGER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TriggerReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropTypeStatementSegment'
pub static DROP_TYPE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropTypeStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TypeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TYPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DropBehaviorGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropUserStatementSegment'
pub static DROP_USER_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropUserStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UserKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RoleReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DropViewStatementSegment'
pub static DROP_VIEW_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// DropViewStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DropBehaviorGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='DummyKeywordSegment'
pub static DUMMY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DUMMY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DumpKeywordSegment'
pub static DUMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DUMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='DynamicKeywordSegment'
pub static DYNAMIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DYNAMIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Dynamic_functionKeywordSegment'
pub static DYNAMIC_FUNCTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DYNAMIC_FUNCTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Dynamic_function_codeKeywordSegment'
pub static DYNAMIC_FUNCTION_CODE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "DYNAMIC_FUNCTION_CODE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EachKeywordSegment'
pub static EACH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EACH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Elem_typeKeywordSegment'
pub static ELEM_TYPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ELEM_TYPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ElementKeywordSegment'
pub static ELEMENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ELEMENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ElseClauseSegment'
pub static ELSE_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ElseClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ElseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ELSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ELSE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ElseKeywordSegment'
pub static ELSE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ELSE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ElseifKeywordSegment'
pub static ELSEIF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ELSEIF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EmptyKeywordSegment'
pub static EMPTY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EMPTY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EmptyStructLiteralBracketsSegment'
pub static EMPTY_STRUCT_LITERAL_BRACKETS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// EmptyStructLiteralBracketsSegment
Arc::new(Grammar::Bracketed {
    elements: vec![
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='EmptyStructLiteralSegment'
pub static EMPTY_STRUCT_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// EmptyStructLiteralSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StructTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "EmptyStructLiteralBracketsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='EnableKeywordSegment'
pub static ENABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ENABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EnclosedKeywordSegment'
pub static ENCLOSED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ENCLOSED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EncodingKeywordSegment'
pub static ENCODING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ENCODING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EncryptedKeywordSegment'
pub static ENCRYPTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ENCRYPTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='End-execKeywordSegment'
pub static END_EXEC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "END-EXEC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EndAngleBracketSegment'
pub static END_ANGLE_BRACKET_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ">",
    token_type: "end_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='EndBracketSegment'
pub static END_BRACKET_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='EndCurlyBracketSegment'
pub static END_CURLY_BRACKET_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "}",
    token_type: "end_curly_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='EndKeywordSegment'
pub static END_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "END",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EndSquareBracketSegment'
pub static END_SQUARE_BRACKET_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "]",
    token_type: "end_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='End_frameKeywordSegment'
pub static END_FRAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "END_FRAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='End_partitionKeywordSegment'
pub static END_PARTITION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "END_PARTITION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EnumKeywordSegment'
pub static ENUM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ENUM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EqualsKeywordSegment'
pub static EQUALS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EQUALS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EqualsSegment'
pub static EQUALS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// EqualsSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RawEqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RawEqualsSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ErrlvlKeywordSegment'
pub static ERRLVL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ERRLVL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EscapeKeywordSegment'
pub static ESCAPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ESCAPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EscapedKeywordSegment'
pub static ESCAPED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ESCAPED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='EveryKeywordSegment'
pub static EVERY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EVERY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExceptKeywordSegment'
pub static EXCEPT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXCEPT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExceptionKeywordSegment'
pub static EXCEPTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXCEPTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExchangeKeywordSegment'
pub static EXCHANGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXCHANGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExcludeKeywordSegment'
pub static EXCLUDE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXCLUDE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExcludingKeywordSegment'
pub static EXCLUDING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXCLUDING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExclusiveKeywordSegment'
pub static EXCLUSIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXCLUSIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExecKeywordSegment'
pub static EXEC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXEC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExecuteKeywordSegment'
pub static EXECUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXECUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExecutionKeywordSegment'
pub static EXECUTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXECUTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExistingKeywordSegment'
pub static EXISTING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXISTING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExistsKeywordSegment'
pub static EXISTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXISTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExitKeywordSegment'
pub static EXIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExpKeywordSegment'
pub static EXP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExplainKeywordSegment'
pub static EXPLAIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXPLAIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExplainStatementSegment'
pub static EXPLAIN_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ExplainStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExplainKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXPLAIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InsertStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UpdateStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeleteStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "DELETE".to_string(), "INSERT".to_string(), "SELECT".to_string(), "UPDATE".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXPLAIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ExportKeywordSegment'
pub static EXPORT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXPORT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExpressionKeywordSegment'
pub static EXPRESSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXPRESSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExpressionSegment'
pub static EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ExpressionSegment
Arc::new(Grammar::Ref {
    name: "Expression_A_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
);

// name='Expression_A_Grammar'
pub static EXPRESSION_A_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Tail_Recurse_Expression_A_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LikeExpressionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ILIKE".to_string(), "IREGEXP".to_string(), "LIKE".to_string(), "NOT".to_string(), "REGEXP".to_string(), "RLIKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "AND".to_string(), "DIV".to_string(), "IS".to_string(), "OR".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Tail_Recurse_Expression_A_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "AND".to_string(), "DIV".to_string(), "IS".to_string(), "OR".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string(), "NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IsClauseGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IsNullGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NotNullGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "CollateGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BetweenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BETWEEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Expression_B_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Tail_Recurse_Expression_A_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BETWEEN".to_string(), "NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PatternMatchingGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "Expression_A_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Expression_A_Unary_Operator_Grammar'
pub static EXPRESSION_A_UNARY_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SignedSegmentGrammar",
    optional: false,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QualifiedNumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TildeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["~".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NotOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PriorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "NOT".to_string(), "PRIOR".to_string(), "~".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Expression_B_Grammar'
pub static EXPRESSION_B_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Tail_Recurse_Expression_B_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ArithmeticBinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), ">".to_string(), "DIV".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StringBinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ComparisonOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "DIV".to_string(), "IS".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Tail_Recurse_Expression_B_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "DIV".to_string(), "IS".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "DIV".to_string(), "IS".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "DIV".to_string(), "IS".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Expression_B_Unary_Operator_Grammar'
pub static EXPRESSION_B_UNARY_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SignedSegmentGrammar",
    optional: false,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QualifiedNumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TildeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["~".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "~".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Expression_C_Grammar'
pub static EXPRESSION_C_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExistsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXISTS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXISTS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Expression_D_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "CaseExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TimeZoneGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ShorthandCastSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Expression_D_Grammar'
pub static EXPRESSION_D_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BareFunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT_DATE".to_string(), "CURRENT_TIME".to_string(), "CURRENT_TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "LocalAliasSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Greedy,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Expression_D_Potential_Select_Statement_Without_Brackets",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StarSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["*".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StructTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MapTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BooleanLiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FALSE".to_string(), "TRUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NullLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DateTimeLiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string(), "INTERVAL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LocalAliasSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ListComprehensionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AccessorGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Expression_D_Potential_Select_Statement_Without_Brackets'
pub static EXPRESSION_D_POTENTIAL_SELECT_STATEMENT_WITHOUT_BRACKETS: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntervalExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "INTERVAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TypedStructLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ArrayExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "OverlapsClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERLAPS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ExtendedKeywordSegment'
pub static EXTENDED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXTENDED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExtendedNaturalJoinKeywordsGrammar'
pub static EXTENDED_NATURAL_JOIN_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='ExtensionKeywordSegment'
pub static EXTENSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXTENSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExtensionReferenceSegment'
pub static EXTENSION_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ExtensionReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ExternalKeywordSegment'
pub static EXTERNAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXTERNAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ExtractKeywordSegment'
pub static EXTRACT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "EXTRACT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FalseKeywordSegment'
pub static FALSE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FALSE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FalseSegment'
pub static FALSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FALSE",
    token_type: "boolean_literal",
    raw_class: "LiteralKeywordSegment",
    optional: false,
})
);

// name='FetchClauseSegment'
pub static FETCH_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FetchClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FetchKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FETCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FirstKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIRST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NextKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NEXT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIRST".to_string(), "NEXT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OnlyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ONLY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TiesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ONLY".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FETCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FetchKeywordSegment'
pub static FETCH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FETCH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FieldsKeywordSegment'
pub static FIELDS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FIELDS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FileFormatGrammar'
pub static FILE_FORMAT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SequencefileKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEQUENCEFILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TextfileKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEXTFILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RcfileKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RCFILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrcKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ParquetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARQUET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AvroKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AVRO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "JsonfileKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["JSONFILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InputformatKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INPUTFORMAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OutputformatKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OUTPUTFORMAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INPUTFORMAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AVRO".to_string(), "INPUTFORMAT".to_string(), "JSONFILE".to_string(), "ORC".to_string(), "PARQUET".to_string(), "RCFILE".to_string(), "SEQUENCEFILE".to_string(), "TEXTFILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FileKeywordSegment'
pub static FILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FILE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FileSegment'
pub static FILE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FileSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "ALTER".to_string(), "COMPUTE".to_string(), "CREATE".to_string(), "DELETE".to_string(), "DESCRIBE".to_string(), "DROP".to_string(), "EXPLAIN".to_string(), "GRANT".to_string(), "INSERT".to_string(), "MERGE".to_string(), "MSCK".to_string(), "REVOKE".to_string(), "SELECT".to_string(), "SET".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USE".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 1,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: true,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "ALTER".to_string(), "COMPUTE".to_string(), "CREATE".to_string(), "DELETE".to_string(), "DESCRIBE".to_string(), "DROP".to_string(), "EXPLAIN".to_string(), "GRANT".to_string(), "INSERT".to_string(), "MERGE".to_string(), "MSCK".to_string(), "REVOKE".to_string(), "SELECT".to_string(), "SET".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USE".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), ";".to_string(), "ALTER".to_string(), "COMPUTE".to_string(), "CREATE".to_string(), "DELETE".to_string(), "DESCRIBE".to_string(), "DROP".to_string(), "EXPLAIN".to_string(), "GRANT".to_string(), "INSERT".to_string(), "MERGE".to_string(), "MSCK".to_string(), "REVOKE".to_string(), "SELECT".to_string(), "SET".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USE".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FileformatKeywordSegment'
pub static FILEFORMAT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FILEFORMAT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FilesKeywordSegment'
pub static FILES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FILES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FillfactorKeywordSegment'
pub static FILLFACTOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FILLFACTOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FilterClauseGrammar'
pub static FILTER_CLAUSE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FilterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhereKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FilterKeywordSegment'
pub static FILTER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FILTER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FinalKeywordSegment'
pub static FINAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FINAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Finalize_fnKeywordSegment'
pub static FINALIZE_FN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FINALIZE_FN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FirstKeywordSegment'
pub static FIRST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FIRST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Float4KeywordSegment'
pub static FLOAT4_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FLOAT4",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Float8KeywordSegment'
pub static FLOAT8_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FLOAT8",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FloatKeywordSegment'
pub static FLOAT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FLOAT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FloorKeywordSegment'
pub static FLOOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FLOOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FlushKeywordSegment'
pub static FLUSH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FLUSH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FollowingKeywordSegment'
pub static FOLLOWING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FOLLOWING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ForKeywordSegment'
pub static FOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ForceKeywordSegment'
pub static FORCE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FORCE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ForeignKeyGrammar'
pub static FOREIGN_KEY_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ForeignKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "KeyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["KEY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ForeignKeywordSegment'
pub static FOREIGN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FOREIGN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FormatKeywordSegment'
pub static FORMAT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FORMAT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FormattedKeywordSegment'
pub static FORMATTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FORMATTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FortranKeywordSegment'
pub static FORTRAN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FORTRAN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ForwardKeywordSegment'
pub static FORWARD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FORWARD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FoundKeywordSegment'
pub static FOUND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FOUND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FrameClauseSegment'
pub static FRAME_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FrameClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FrameClauseUnitGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CurrentKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntervalExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "INTERVAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UnboundedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNBOUNDED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PrecedingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRECEDING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FollowingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOLLOWING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOLLOWING".to_string(), "PRECEDING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BetweenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BETWEEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CurrentKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntervalExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "INTERVAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UnboundedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNBOUNDED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PrecedingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRECEDING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FollowingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOLLOWING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOLLOWING".to_string(), "PRECEDING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CurrentKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntervalExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "INTERVAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UnboundedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNBOUNDED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PrecedingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRECEDING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FollowingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOLLOWING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOLLOWING".to_string(), "PRECEDING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BETWEEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FrameClauseUnitGrammar'
pub static FRAME_CLAUSE_UNIT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RowsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RangeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Frame_rowKeywordSegment'
pub static FRAME_ROW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FRAME_ROW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FreeKeywordSegment'
pub static FREE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FREE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FreetextKeywordSegment'
pub static FREETEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FREETEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FreetexttableKeywordSegment'
pub static FREETEXTTABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FREETEXTTABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FreezeKeywordSegment'
pub static FREEZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FREEZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FromClauseSegment'
pub static FROM_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FromClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FromExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FromClauseTerminatorGrammar'
pub static FROM_CLAUSE_TERMINATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhereKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LimitClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ClusterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DistributeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "HavingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QualifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["QUALIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WindowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SetOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithNoSchemaBindingClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithDataClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FetchKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FETCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OffsetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OFFSET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "EXCEPT".to_string(), "FETCH".to_string(), "GROUP".to_string(), "HAVING".to_string(), "INTERSECT".to_string(), "LIMIT".to_string(), "MINUS".to_string(), "OFFSET".to_string(), "ORDER".to_string(), "QUALIFY".to_string(), "SORT".to_string(), "UNION".to_string(), "WHERE".to_string(), "WINDOW".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FromExpressionElementSegment'
pub static FROM_EXPRESSION_ELEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FromExpressionElementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PreTableFunctionKeywordsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "TemporalQuerySegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AliasExpressionSegment",
    optional: true,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FromClauseTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "EXCEPT".to_string(), "FETCH".to_string(), "GROUP".to_string(), "HAVING".to_string(), "INTERSECT".to_string(), "LIMIT".to_string(), "MINUS".to_string(), "OFFSET".to_string(), "ORDER".to_string(), "QUALIFY".to_string(), "SORT".to_string(), "UNION".to_string(), "WHERE".to_string(), "WINDOW".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SamplingExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLESAMPLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "JoinLikeClauseGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "JoinClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OffsetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OFFSET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AliasExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SamplingExpressionSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLESAMPLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LateralViewClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "PostTableExpressionGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='FromExpressionSegment'
pub static FROM_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FromExpressionSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MLTableExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ML".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromExpressionElementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FromExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "JoinClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "JoinLikeClauseGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("conditional"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MLTableExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ML".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromExpressionElementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FromExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "JoinClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "JoinLikeClauseGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("conditional"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='FromKeywordSegment'
pub static FROM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FROM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FullKeywordSegment'
pub static FULL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FULL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FulltextKeywordSegment'
pub static FULLTEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FULLTEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FunctionContentsExpressionGrammar'
pub static FUNCTION_CONTENTS_EXPRESSION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
);

// name='FunctionContentsGrammar'
pub static FUNCTION_CONTENTS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TrimParametersGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: true,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatetimeUnitSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DAY".to_string(), "DAYOFYEAR".to_string(), "DAYS".to_string(), "HOUR".to_string(), "HOURS".to_string(), "MILLISECOND".to_string(), "MINUTE".to_string(), "MINUTES".to_string(), "MONTH".to_string(), "MONTHS".to_string(), "NANO".to_string(), "NANOS".to_string(), "QUARTER".to_string(), "SECOND".to_string(), "SECONDS".to_string(), "WEEK".to_string(), "WEEKDAY".to_string(), "WEEKS".to_string(), "YEAR".to_string(), "YEARS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DistinctKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTINCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StarSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["*".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FunctionContentsExpressionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AggregateOrderByClause",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SeparatorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEPARATOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEPARATOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "IgnoreRespectNullsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IGNORE".to_string(), "RESPECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IndexColumnDefinitionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "EmptyStructLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='FunctionContentsSegment'
pub static FUNCTION_CONTENTS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FunctionContentsSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FunctionContentsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FunctionDefinitionGrammar'
pub static FUNCTION_DEFINITION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
// FunctionDefinitionGrammar
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LanguageKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LANGUAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NakedIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LANGUAGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FunctionKeywordSegment'
pub static FUNCTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FUNCTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FunctionNameIdentifierSegment'
pub static FUNCTION_NAME_IDENTIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::TypedParser {
    template: "word",
    token_type: "function_name_identifier",
    raw_class: "WordSegment",
    optional: false,
})
);

// name='FunctionNameSegment'
pub static FUNCTION_NAME_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FunctionNameSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "BracketedSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FunctionNameIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["word".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["double_quote".to_string()]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "BracketedSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["double_quote".to_string(), "word".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='FunctionParameterGrammar'
pub static FUNCTION_PARAMETER_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ParameterNameSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AnyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ANY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TypeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TYPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ANY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ANY".to_string(), "ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AnyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ANY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TypeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TYPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ANY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ANY".to_string(), "ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='FunctionParameterListGrammar'
pub static FUNCTION_PARAMETER_LIST_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
// FunctionParameterListGrammar
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FunctionParameterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: true,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='FunctionSegment'
pub static FUNCTION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// FunctionSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatePartFunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATEADD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DateTimeFunctionContentsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATEADD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATEADD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::StringParser {
    template: "ROW",
    token_type: "function_name",
    raw_class: "KeywordSegment",
    optional: false,
})
,
Arc::new(Grammar::Ref {
    name: "RowFunctionContentsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DatePartFunctionNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATEADD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ValuesClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATEADD".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FunctionContentsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "PostFunctionGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='FunctionsKeywordSegment'
pub static FUNCTIONS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FUNCTIONS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FusionKeywordSegment'
pub static FUSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FUSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='FutureKeywordSegment'
pub static FUTURE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "FUTURE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GKeywordSegment'
pub static G_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "G",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GeneralKeywordSegment'
pub static GENERAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GENERAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GeneratedKeywordSegment'
pub static GENERATED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GENERATED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GetKeywordSegment'
pub static GET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GlobOperatorSegment'
pub static GLOB_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::TypedParser {
    template: "glob_operator",
    token_type: "glob_operator",
    raw_class: "ComparisonOperatorSegment",
    optional: false,
})
);

// name='GlobalKeywordSegment'
pub static GLOBAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GLOBAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GoKeywordSegment'
pub static GO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GotoKeywordSegment'
pub static GOTO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GOTO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GrantKeywordSegment'
pub static GRANT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GRANT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GrantedKeywordSegment'
pub static GRANTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GRANTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GrantsKeywordSegment'
pub static GRANTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GRANTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GreaterThanOrEqualToSegment'
pub static GREATER_THAN_OR_EQUAL_TO_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// GreaterThanOrEqualToSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RawGreaterThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RawEqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='GreaterThanSegment'
pub static GREATER_THAN_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// GreaterThanSegment
Arc::new(Grammar::Ref {
    name: "RawGreaterThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='GreatestKeywordSegment'
pub static GREATEST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GREATEST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GroupByClauseSegment'
pub static GROUP_BY_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// GroupByClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GroupingSetsClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUPING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CubeRollupClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CUBE".to_string(), "ROLLUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "GroupByClauseTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "HAVING".to_string(), "LIMIT".to_string(), "ORDER".to_string(), "QUALIFY".to_string(), "SORT".to_string(), "WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='GroupByClauseTerminatorGrammar'
pub static GROUP_BY_CLAUSE_TERMINATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ClusterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DistributeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "ORDER".to_string(), "SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "ORDER".to_string(), "SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LimitKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "HavingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QualifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["QUALIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WindowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "HAVING".to_string(), "LIMIT".to_string(), "ORDER".to_string(), "QUALIFY".to_string(), "SORT".to_string(), "WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='GroupKeywordSegment'
pub static GROUP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GROUP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GroupingExpressionList'
pub static GROUPING_EXPRESSION_LIST: Lazy<Arc<Grammar>> = Lazy::new(||
// GroupingExpressionList
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "GroupByClauseTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "HAVING".to_string(), "LIMIT".to_string(), "ORDER".to_string(), "QUALIFY".to_string(), "SORT".to_string(), "WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='GroupingKeywordSegment'
pub static GROUPING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GROUPING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='GroupingSetsClauseSegment'
pub static GROUPING_SETS_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// GroupingSetsClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUPING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SetsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SETS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CubeRollupClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CUBE".to_string(), "ROLLUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GroupingExpressionList",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUPING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='GroupsKeywordSegment'
pub static GROUPS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "GROUPS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HandlerKeywordSegment'
pub static HANDLER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HANDLER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HashKeywordSegment'
pub static HASH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HASH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HavingClauseSegment'
pub static HAVING_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// HavingClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "HavingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='HavingClauseTerminatorGrammar'
pub static HAVING_CLAUSE_TERMINATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ClusterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DistributeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "ORDER".to_string(), "SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "ORDER".to_string(), "SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LimitKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QualifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["QUALIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WindowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "LIMIT".to_string(), "ORDER".to_string(), "QUALIFY".to_string(), "SORT".to_string(), "WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='HavingKeywordSegment'
pub static HAVING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HAVING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HeaderKeywordSegment'
pub static HEADER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HEADER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HeapKeywordSegment'
pub static HEAP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HEAP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HierarchyKeywordSegment'
pub static HIERARCHY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HIERARCHY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='High_priorityKeywordSegment'
pub static HIGH_PRIORITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HIGH_PRIORITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HoldKeywordSegment'
pub static HOLD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOLD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Hold_ddltimeKeywordSegment'
pub static HOLD_DDLTIME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOLD_DDLTIME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HoldlockKeywordSegment'
pub static HOLDLOCK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOLDLOCK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HorizontalJoinKeywordsGrammar'
pub static HORIZONTAL_JOIN_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='HostKeywordSegment'
pub static HOST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HostsKeywordSegment'
pub static HOSTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOSTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HourKeywordSegment'
pub static HOUR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOUR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Hour_microsecondKeywordSegment'
pub static HOUR_MICROSECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOUR_MICROSECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Hour_minuteKeywordSegment'
pub static HOUR_MINUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOUR_MINUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Hour_secondKeywordSegment'
pub static HOUR_SECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOUR_SECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HoursKeywordSegment'
pub static HOURS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HOURS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='HudiparquetKeywordSegment'
pub static HUDIPARQUET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "HUDIPARQUET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IcebergKeywordSegment'
pub static ICEBERG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ICEBERG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IdentifiedKeywordSegment'
pub static IDENTIFIED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IDENTIFIED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IdentifierSegment'
pub static IDENTIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "identifier",
//    token_type: "IdentifierSegment",
})
);

// name='IdentityKeywordSegment'
pub static IDENTITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IDENTITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Identity_insertKeywordSegment'
pub static IDENTITY_INSERT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IDENTITY_INSERT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IdentitycolKeywordSegment'
pub static IDENTITYCOL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IDENTITYCOL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IdxpropertiesKeywordSegment'
pub static IDXPROPERTIES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IDXPROPERTIES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IfExistsGrammar'
pub static IF_EXISTS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IfKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExistsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXISTS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='IfKeywordSegment'
pub static IF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IfNotExistsGrammar'
pub static IF_NOT_EXISTS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IfKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExistsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXISTS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='IgnoreKeywordSegment'
pub static IGNORE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IGNORE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IgnoreRespectNullsGrammar'
pub static IGNORE_RESPECT_NULLS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IgnoreKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IGNORE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RespectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RESPECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IGNORE".to_string(), "RESPECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NullsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULLS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IGNORE".to_string(), "RESPECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='IlikeKeywordSegment'
pub static ILIKE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ILIKE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ImmediateKeywordSegment'
pub static IMMEDIATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IMMEDIATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ImmutableKeywordSegment'
pub static IMMUTABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IMMUTABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ImplementationKeywordSegment'
pub static IMPLEMENTATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IMPLEMENTATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ImplicitIndent'
pub static IMPLICIT_INDENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Meta("indent"))
);

// name='ImplicitKeywordSegment'
pub static IMPLICIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IMPLICIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ImportKeywordSegment'
pub static IMPORT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IMPORT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ImportedKeywordSegment'
pub static IMPORTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IMPORTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InKeywordSegment'
pub static IN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InOperatorGrammar'
pub static IN_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Expression_A_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Greedy,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IN".to_string(), "NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='IncludeKeywordSegment'
pub static INCLUDE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INCLUDE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IncludingKeywordSegment'
pub static INCLUDING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INCLUDING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IncrementKeywordSegment'
pub static INCREMENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INCREMENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IncrementalKeywordSegment'
pub static INCREMENTAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INCREMENTAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Indent'
pub static INDENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Meta("indent"))
);

// name='IndexColumnDefinitionSegment'
pub static INDEX_COLUMN_DEFINITION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// IndexColumnDefinitionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AscKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ASC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DescKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DESC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ASC".to_string(), "DESC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='IndexKeywordSegment'
pub static INDEX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INDEX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IndexReferenceSegment'
pub static INDEX_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// IndexReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='IndexesKeywordSegment'
pub static INDEXES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INDEXES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IndicatorKeywordSegment'
pub static INDICATOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INDICATOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InfileKeywordSegment'
pub static INFILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INFILE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InfixKeywordSegment'
pub static INFIX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INFIX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InheritKeywordSegment'
pub static INHERIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INHERIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InheritsKeywordSegment'
pub static INHERITS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INHERITS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Init_fnKeywordSegment'
pub static INIT_FN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INIT_FN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InitialKeywordSegment'
pub static INITIAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INITIAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InitializeKeywordSegment'
pub static INITIALIZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INITIALIZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InitiallyKeywordSegment'
pub static INITIALLY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INITIALLY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InnerKeywordSegment'
pub static INNER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INNER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InoutKeywordSegment'
pub static INOUT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INOUT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InpathKeywordSegment'
pub static INPATH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INPATH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InputKeywordSegment'
pub static INPUT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INPUT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InputdriverKeywordSegment'
pub static INPUTDRIVER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INPUTDRIVER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InputformatKeywordSegment'
pub static INPUTFORMAT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INPUTFORMAT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InsensitiveKeywordSegment'
pub static INSENSITIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INSENSITIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InsertKeywordSegment'
pub static INSERT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INSERT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InsertStatementSegment'
pub static INSERT_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// InsertStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InsertKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OverwriteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERWRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "PartitionSpecGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ShuffleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SHUFFLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NoshuffleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOSHUFFLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOSHUFFLE".to_string(), "SHUFFLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "[",
    token_type: "start_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: "]",
    token_type: "end_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERWRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IntoKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PartitionSpecGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ShuffleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SHUFFLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NoshuffleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOSHUFFLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOSHUFFLE".to_string(), "SHUFFLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "[",
    token_type: "start_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: "]",
    token_type: "end_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ValuesClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTO".to_string(), "OVERWRITE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Insert_idKeywordSegment'
pub static INSERT_ID_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INSERT_ID",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InstanceKeywordSegment'
pub static INSTANCE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INSTANCE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InstantiableKeywordSegment'
pub static INSTANTIABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INSTANTIABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InsteadKeywordSegment'
pub static INSTEAD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INSTEAD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Int1KeywordSegment'
pub static INT1_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INT1",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Int2KeywordSegment'
pub static INT2_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INT2",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Int3KeywordSegment'
pub static INT3_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INT3",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Int4KeywordSegment'
pub static INT4_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INT4",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Int8KeywordSegment'
pub static INT8_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INT8",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntKeywordSegment'
pub static INT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntegerKeywordSegment'
pub static INTEGER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INTEGER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntegrationKeywordSegment'
pub static INTEGRATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INTEGRATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntegrationsKeywordSegment'
pub static INTEGRATIONS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INTEGRATIONS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntermediateKeywordSegment'
pub static INTERMEDIATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INTERMEDIATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntersectKeywordSegment'
pub static INTERSECT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INTERSECT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntersectionKeywordSegment'
pub static INTERSECTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INTERSECTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntervalExpressionSegment'
pub static INTERVAL_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// IntervalExpressionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IntervalKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTERVAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatetimeUnitSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DAY".to_string(), "DAYOFYEAR".to_string(), "DAYS".to_string(), "HOUR".to_string(), "HOURS".to_string(), "MILLISECOND".to_string(), "MINUTE".to_string(), "MINUTES".to_string(), "MONTH".to_string(), "MONTHS".to_string(), "NANO".to_string(), "NANOS".to_string(), "QUARTER".to_string(), "SECOND".to_string(), "SECONDS".to_string(), "WEEK".to_string(), "WEEKDAY".to_string(), "WEEKS".to_string(), "YEAR".to_string(), "YEARS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ToKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatetimeUnitSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DAY".to_string(), "DAYOFYEAR".to_string(), "DAYS".to_string(), "HOUR".to_string(), "HOURS".to_string(), "MILLISECOND".to_string(), "MINUTE".to_string(), "MINUTES".to_string(), "MONTH".to_string(), "MONTHS".to_string(), "NANO".to_string(), "NANOS".to_string(), "QUARTER".to_string(), "SECOND".to_string(), "SECONDS".to_string(), "WEEK".to_string(), "WEEKDAY".to_string(), "WEEKS".to_string(), "YEAR".to_string(), "YEARS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "INTERVAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
);

// name='IntervalKeywordSegment'
pub static INTERVAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INTERVAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IntoKeywordSegment'
pub static INTO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INTO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InvalidateKeywordSegment'
pub static INVALIDATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INVALIDATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='InvokerKeywordSegment'
pub static INVOKER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "INVOKER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IregexpKeywordSegment'
pub static IREGEXP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IREGEXP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IsClauseGrammar'
pub static IS_CLAUSE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NullLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NanLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NAN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UnknownLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "BooleanLiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FALSE".to_string(), "TRUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NormalizedGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='IsDistinctFromGrammar'
pub static IS_DISTINCT_FROM_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DistinctKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTINCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='IsKeywordSegment'
pub static IS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "IS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IsNullGrammar'
pub static IS_NULL_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='IsamKeywordSegment'
pub static ISAM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ISAM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IsnullKeywordSegment'
pub static ISNULL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ISNULL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IsolationKeywordSegment'
pub static ISOLATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ISOLATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ItemsKeywordSegment'
pub static ITEMS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ITEMS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='IterateKeywordSegment'
pub static ITERATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ITERATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='JarKeywordSegment'
pub static JAR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JAR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='JoinClauseSegment'
pub static JOIN_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// JoinClauseSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ConditionalJoinKeywordsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "JoinKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["JOIN".to_string(), "SEMI".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "FromExpressionElementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NestedJoinGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Ref {
    name: "MatchConditionSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "JoinOnConditionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "JoinUsingConditionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string(), "USING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("conditional"))
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UnconditionalJoinKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "JoinKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["JOIN".to_string(), "SEMI".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "FromExpressionElementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "MatchConditionSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExtendedNaturalJoinKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "FromExpressionElementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='JoinKeywordSegment'
pub static JOIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JOIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='JoinKeywordsGrammar'
pub static JOIN_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SemiKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEMI".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEMI".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "JoinKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["JOIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["JOIN".to_string(), "SEMI".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='JoinLikeClauseGrammar'
pub static JOIN_LIKE_CLAUSE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='JoinOnConditionSegment'
pub static JOIN_ON_CONDITION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// JoinOnConditionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("conditional"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='JoinTypeKeywordsGrammar'
pub static JOIN_TYPE_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InnerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INNER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FullKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LeftKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LEFT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RightKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RIGHT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FULL".to_string(), "LEFT".to_string(), "RIGHT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OuterKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OUTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FULL".to_string(), "LEFT".to_string(), "RIGHT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FULL".to_string(), "INNER".to_string(), "LEFT".to_string(), "RIGHT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='JoinUsingConditionGrammar'
pub static JOIN_USING_CONDITION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UsingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Greedy,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='JsonKeywordSegment'
pub static JSON_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_arrayKeywordSegment'
pub static JSON_ARRAY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_ARRAY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_arrayaggKeywordSegment'
pub static JSON_ARRAYAGG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_ARRAYAGG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_existsKeywordSegment'
pub static JSON_EXISTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_EXISTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_objectKeywordSegment'
pub static JSON_OBJECT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_OBJECT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_objectaggKeywordSegment'
pub static JSON_OBJECTAGG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_OBJECTAGG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_queryKeywordSegment'
pub static JSON_QUERY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_QUERY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_tableKeywordSegment'
pub static JSON_TABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_TABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_table_primitiveKeywordSegment'
pub static JSON_TABLE_PRIMITIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_TABLE_PRIMITIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Json_valueKeywordSegment'
pub static JSON_VALUE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSON_VALUE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='JsonfileKeywordSegment'
pub static JSONFILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "JSONFILE",
    token_type: "file_format",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='KKeywordSegment'
pub static K_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "K",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='KeyKeywordSegment'
pub static KEY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "KEY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Key_memberKeywordSegment'
pub static KEY_MEMBER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "KEY_MEMBER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Key_typeKeywordSegment'
pub static KEY_TYPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "KEY_TYPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='KeysKeywordSegment'
pub static KEYS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "KEYS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='KeywordSegment'
pub static KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "keyword",
//    token_type: "KeywordSegment",
})
);

// name='KillKeywordSegment'
pub static KILL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "KILL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='KuduKeywordSegment'
pub static KUDU_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "KUDU",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LancompilerKeywordSegment'
pub static LANCOMPILER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LANCOMPILER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LanguageKeywordSegment'
pub static LANGUAGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LANGUAGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LargeKeywordSegment'
pub static LARGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LARGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LastKeywordSegment'
pub static LAST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LAST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Last_insert_idKeywordSegment'
pub static LAST_INSERT_ID_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LAST_INSERT_ID",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LateralKeywordSegment'
pub static LATERAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LATERAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LateralViewClauseSegment'
pub static LATERAL_VIEW_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// LateralViewClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "LateralKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LATERAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ViewKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VIEW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OuterKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OUTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='LeadingKeywordSegment'
pub static LEADING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LEADING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LeastKeywordSegment'
pub static LEAST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LEAST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LeaveKeywordSegment'
pub static LEAVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LEAVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LeftKeywordSegment'
pub static LEFT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LEFT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LengthKeywordSegment'
pub static LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LessKeywordSegment'
pub static LESS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LESS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LessThanOrEqualToSegment'
pub static LESS_THAN_OR_EQUAL_TO_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// LessThanOrEqualToSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RawLessThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RawEqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='LessThanSegment'
pub static LESS_THAN_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// LessThanSegment
Arc::new(Grammar::Ref {
    name: "RawLessThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='LevelKeywordSegment'
pub static LEVEL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LEVEL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LexicalKeywordSegment'
pub static LEXICAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LEXICAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LikeExpressionGrammar'
pub static LIKE_EXPRESSION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LikeGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ILIKE".to_string(), "IREGEXP".to_string(), "LIKE".to_string(), "REGEXP".to_string(), "RLIKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ILIKE".to_string(), "IREGEXP".to_string(), "LIKE".to_string(), "NOT".to_string(), "REGEXP".to_string(), "RLIKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Expression_A_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "EscapeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ESCAPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Tail_Recurse_Expression_A_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ESCAPE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ILIKE".to_string(), "IREGEXP".to_string(), "LIKE".to_string(), "NOT".to_string(), "REGEXP".to_string(), "RLIKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='LikeGrammar'
pub static LIKE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LikeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RlikeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RLIKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IlikeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ILIKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RegexpKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REGEXP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IregexpKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IREGEXP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ILIKE".to_string(), "IREGEXP".to_string(), "LIKE".to_string(), "REGEXP".to_string(), "RLIKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='LikeKeywordSegment'
pub static LIKE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LIKE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LikeOperatorSegment'
pub static LIKE_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::TypedParser {
    template: "like_operator",
    token_type: "like_operator",
    raw_class: "ComparisonOperatorSegment",
    optional: false,
})
);

// name='Like_regexKeywordSegment'
pub static LIKE_REGEX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LIKE_REGEX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LimitClauseSegment'
pub static LIMIT_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// LimitClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LimitKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OffsetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OFFSET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OFFSET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string(), "OFFSET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='LimitKeywordSegment'
pub static LIMIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LIMIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LinenoKeywordSegment'
pub static LINENO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LINENO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LinesKeywordSegment'
pub static LINES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LINES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ListComprehensionGrammar'
pub static LIST_COMPREHENSION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='ListaggKeywordSegment'
pub static LISTAGG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LISTAGG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ListenKeywordSegment'
pub static LISTEN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LISTEN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LiteralGrammar'
pub static LITERAL_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BooleanLiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FALSE".to_string(), "TRUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QualifiedNumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NullLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DateTimeLiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string(), "INTERVAL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ArrayLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TypedArrayLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["{".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
);

// name='LiteralKeywordSegment'
pub static LITERAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "literal",
//    token_type: "LiteralKeywordSegment",
})
);

// name='LiteralSegment'
pub static LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "literal",
//    token_type: "LiteralSegment",
})
);

// name='LnKeywordSegment'
pub static LN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LoadKeywordSegment'
pub static LOAD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOAD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LocalAliasSegment'
pub static LOCAL_ALIAS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// LocalAliasSegment
Arc::new(Grammar::Nothing())
);

// name='LocalKeywordSegment'
pub static LOCAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOCAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LocaltimeKeywordSegment'
pub static LOCALTIME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOCALTIME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LocaltimestampKeywordSegment'
pub static LOCALTIMESTAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOCALTIMESTAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LocationGrammar'
pub static LOCATION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LocationKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LOCATION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='LocationKeywordSegment'
pub static LOCATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOCATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LocatorKeywordSegment'
pub static LOCATOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOCATOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LockKeywordSegment'
pub static LOCK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOCK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LocksKeywordSegment'
pub static LOCKS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOCKS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Log10KeywordSegment'
pub static LOG10_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOG10",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LogicalKeywordSegment'
pub static LOGICAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOGICAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LoginKeywordSegment'
pub static LOGIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOGIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LogsKeywordSegment'
pub static LOGS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOGS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LongKeywordSegment'
pub static LONG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LONG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LongblobKeywordSegment'
pub static LONGBLOB_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LONGBLOB",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LongtextKeywordSegment'
pub static LONGTEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LONGTEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LoopKeywordSegment'
pub static LOOP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOOP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Low_priorityKeywordSegment'
pub static LOW_PRIORITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOW_PRIORITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='LowerKeywordSegment'
pub static LOWER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "LOWER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MKeywordSegment'
pub static M_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "M",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MLTableExpressionSegment'
pub static M_L_TABLE_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MLTableExpressionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MlKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ML".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ModelKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MODEL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MODEL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ML".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MacroKeywordSegment'
pub static MACRO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MACRO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ManageKeywordSegment'
pub static MANAGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MANAGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ManagedlocationKeywordSegment'
pub static MANAGEDLOCATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MANAGEDLOCATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MapKeywordSegment'
pub static MAP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MAP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MapTypeSegment'
pub static MAP_TYPE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MapTypeSegment
Arc::new(Grammar::Nothing())
);

// name='MapjoinKeywordSegment'
pub static MAPJOIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MAPJOIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MaskingKeywordSegment'
pub static MASKING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MASKING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MatchConditionSegment'
pub static MATCH_CONDITION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MatchConditionSegment
Arc::new(Grammar::Nothing())
);

// name='MatchKeywordSegment'
pub static MATCH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MATCH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Match_numberKeywordSegment'
pub static MATCH_NUMBER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MATCH_NUMBER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Match_recognizeKeywordSegment'
pub static MATCH_RECOGNIZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MATCH_RECOGNIZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MatchedKeywordSegment'
pub static MATCHED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MATCHED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MatchesKeywordSegment'
pub static MATCHES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MATCHES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MaterializedKeywordSegment'
pub static MATERIALIZED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MATERIALIZED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MaxKeywordSegment'
pub static MAX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MAX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Max_rowsKeywordSegment'
pub static MAX_ROWS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MAX_ROWS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MaxextentsKeywordSegment'
pub static MAXEXTENTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MAXEXTENTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MaxvalueKeywordSegment'
pub static MAXVALUE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MAXVALUE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MediumblobKeywordSegment'
pub static MEDIUMBLOB_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MEDIUMBLOB",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MediumintKeywordSegment'
pub static MEDIUMINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MEDIUMINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MediumtextKeywordSegment'
pub static MEDIUMTEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MEDIUMTEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MemberKeywordSegment'
pub static MEMBER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MEMBER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MergeDeleteClauseSegment'
pub static MERGE_DELETE_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MergeDeleteClauseSegment
Arc::new(Grammar::Ref {
    name: "DeleteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MergeInsertClauseSegment'
pub static MERGE_INSERT_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MergeInsertClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "InsertKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Ref {
    name: "ValuesClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MergeIntoLiteralGrammar'
pub static MERGE_INTO_LITERAL_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MergeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MERGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntoKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MERGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MergeKeywordSegment'
pub static MERGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MERGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MergeMatchSegment'
pub static MERGE_MATCH_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MergeMatchSegment
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MergeMatchedClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MergeNotMatchedClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 1,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MergeMatchedClauseSegment'
pub static MERGE_MATCHED_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MergeMatchedClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MatchedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATCHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ThenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["THEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MergeUpdateClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MergeDeleteClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string(), "UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MergeNotMatchedClauseSegment'
pub static MERGE_NOT_MATCHED_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MergeNotMatchedClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NotKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MatchedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATCHED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ThenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["THEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "MergeInsertClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MergeStatementSegment'
pub static MERGE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MergeStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MergeIntoLiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MERGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AliasedTableReferenceGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Ref {
    name: "UsingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AliasedTableReferenceGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AliasExpressionSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Ref {
    name: "JoinOnConditionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Ref {
    name: "MergeMatchSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MERGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MergeUpdateClauseSegment'
pub static MERGE_UPDATE_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MergeUpdateClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UpdateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "SetClauseListSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Merge_fnKeywordSegment'
pub static MERGE_FN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MERGE_FN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Message_lengthKeywordSegment'
pub static MESSAGE_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MESSAGE_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Message_octet_lengthKeywordSegment'
pub static MESSAGE_OCTET_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MESSAGE_OCTET_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Message_textKeywordSegment'
pub static MESSAGE_TEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MESSAGE_TEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MetadataKeywordSegment'
pub static METADATA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "METADATA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MethodKeywordSegment'
pub static METHOD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "METHOD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MiddleintKeywordSegment'
pub static MIDDLEINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MIDDLEINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MillisecondKeywordSegment'
pub static MILLISECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MILLISECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MinKeywordSegment'
pub static MIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Min_rowsKeywordSegment'
pub static MIN_ROWS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MIN_ROWS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MinusKeywordSegment'
pub static MINUS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MINUS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MinusSegment'
pub static MINUS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "-",
    token_type: "binary_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='MinuteKeywordSegment'
pub static MINUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MINUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Minute_microsecondKeywordSegment'
pub static MINUTE_MICROSECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MINUTE_MICROSECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Minute_secondKeywordSegment'
pub static MINUTE_SECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MINUTE_SECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MinutesKeywordSegment'
pub static MINUTES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MINUTES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MinvalueKeywordSegment'
pub static MINVALUE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MINVALUE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MlKeywordSegment'
pub static ML_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ML",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MlslabelKeywordSegment'
pub static MLSLABEL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MLSLABEL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ModKeywordSegment'
pub static MOD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MOD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ModeKeywordSegment'
pub static MODE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MODE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ModelKeywordSegment'
pub static MODEL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MODEL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ModifiesKeywordSegment'
pub static MODIFIES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MODIFIES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ModifyKeywordSegment'
pub static MODIFY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MODIFY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ModuleKeywordSegment'
pub static MODULE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MODULE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ModuloSegment'
pub static MODULO_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "%",
    token_type: "binary_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='MonitorKeywordSegment'
pub static MONITOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MONITOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MonthKeywordSegment'
pub static MONTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MONTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MonthnameKeywordSegment'
pub static MONTHNAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MONTHNAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MonthsKeywordSegment'
pub static MONTHS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MONTHS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MoreKeywordSegment'
pub static MORE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MORE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MoveKeywordSegment'
pub static MOVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MOVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MsckKeywordSegment'
pub static MSCK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MSCK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MsckRepairTableStatementSegment'
pub static MSCK_REPAIR_TABLE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MsckRepairTableStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MsckKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MSCK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RepairKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REPAIR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AddKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SyncKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SYNC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string(), "DROP".to_string(), "SYNC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PartitionsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITIONS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string(), "DROP".to_string(), "SYNC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MSCK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MsckTableStatementSegment'
pub static MSCK_TABLE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// MsckTableStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MsckKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MSCK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AddKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SyncKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SYNC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string(), "DROP".to_string(), "SYNC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PartitionsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITIONS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ADD".to_string(), "DROP".to_string(), "SYNC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MSCK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='MultiplySegment'
pub static MULTIPLY_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "*",
    token_type: "binary_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='MultisetKeywordSegment'
pub static MULTISET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MULTISET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MumpsKeywordSegment'
pub static MUMPS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MUMPS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='MyisamKeywordSegment'
pub static MYISAM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "MYISAM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NakedIdentifierSegment'
pub static NAKED_IDENTIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::RegexParser {
    template: RegexMode::new(r#"[A-Z0-9_]*[A-Z][A-Z0-9_]*"#),
    token_type: "naked_identifier",
    raw_class: "IdentifierSegment",
    optional: false,
    anti_template: Some(RegexMode::new(r#"^(RUNNING|LEXICAL|ROWS|CACHE|TRANSFORM|SPECIFICTYPE|JSON_TABLE_PRIMITIVE|TRAILING|UTC_TMESTAMP|SCROLL|TRANSLATE_REGEX|TREAT|TBLPROPERTIES|TIMESTAMP|DATA|FUNCTION|SCHEMAS|CORR|SELECTIVITY|INSENSITIVE|PRECISION|OCCURRENCES_REGEX|CURSOR|CURRENT_TRANSFORM_GROUP_FOR_TYPE|STORAGEHANDLER_URI|ELSE|CUBE|EMPTY|BIGINT|ALLOCATE|CONDITION|EXISTS|END_FRAME|REGR_SLOPE|EXCEPT|USER_DEFINED_FN|OCTET_LENGTH|VALIDATE|FINALIZE_FN|UNSET|CURRENT_TIME|RWSTORAGE|FUNCTIONS|CURRENT_ROLE|RETURNS|USE|API_VERSION|METHOD|GRANT|SOME|LAST|COLLECT|SYSTEM_USER|LEFT|ROLLBACK|OMIT|ARE|SPEC|PARQUETFILE|NORMALIZE|ORDER|LIMIT|RELEASE|DOUBLE|JSON_EXISTS|OUTER|ESCAPE|DISCONNECT|DEREF|OFFSET|PER|MATCH_RECOGNIZE|JSON_TABLE|SQLEXCEPTION|COMPUTE|INTERMEDIATE|OVERLAPS|READS|DETERMINISTIC|STATIC|TRIM_ARRAY|COLUMNS|REGR_AVGX|EXCHANGE|CLASS|AS|DAYOFWEEK|TRUE|MODIFIES|LOCATION|WITH|DYNAMIC|AT|ARRAY_MAX_CARDINALITY|UPSERT|DECIMAL|TRANSLATION|AND|COVAR_SAMP|FUSION|EXPLAIN|FLOOR|CONSTRAINT|ALL|INITIAL|EQUALS|DECLARE|BOTH|SERIALIZE_FN|CURRENT_SCHEMA|LOCALTIMESTAMP|TABLESAMPLE|TO|FULL|JSON_QUERY|GROUPS|ORC|PURGE|FIRST|PREPARE_FN|DIV|MATCHES|ASC|SPECIFIC|PERCENTILE_DISC|INTERSECTION|REPLACE|EXTRACT|BOOLEAN|SET|BLOCK_SIZE|PATTERN|JSON_VALUE|COLLATE|LIKE|MERGE|HOLD|NON|CONNECT|PARTIALSCAN|USING|DEC|TINYINT|CYCLE|ARRAY|OVERLAY|BETWEEN|TEXTFILE|USER|PRECEDING|ANTI|CURRENT_ROW|PARTITIONS|ENABLE|WITHIN|DISTINCT|REGR_SYY|REF|UNIQUEJOIN|REGR_AVGY|NCHAR|NORELY|MAP|SUBSTRING_REGEX|STRUCT|END-EXEC|PREPARE|MATCH|CASCADED|TIME|COMMENT|WHENEVER|WIDTH_BUCKET|ELEMENT|LARGE|STRING|REFERENCING|POSITION|END|INOUT|BUCKETS|ATOMIC|GET|FILES|EXECUTE|RECURSIVE|IF|JSON_ARRAYAGG|NUMERIC|LOG10|MINUS|POSITION_REGEX|WHERE|GLOBAL|COMMIT|CURRENT_PATH|GROUPING|VALUE_OF|RESTRICT|DELIMITED|LOAD|FLOAT|CLOSE_FN|REGR_SXX|STATS|PERCENT|FREE|DESCRIBE|CURRENT_DEFAULT_TRANSFORM_GROUP|UNBOUNDED|SEQUENCEFILE|CURRENT_DATE|BLOB|EXTERNAL|JSON_OBJECTAGG|CASE|CHAR|OR|CURRENT_TIMESTAMP|SUBSET|IGNORE|JSONFILE|OVERWRITE|SENSITIVE|VERSIONING|SEMI|JOIN|DEFINE|TRUNCATE|SERDEPROPERTIES|SYMMETRIC|ESCAPED|VIEW|PRESERVE|NATURAL|MERGE_FN|NO|SQLSTATE|RLIKE|AGGREGATE|LEADING|NTH_VALUE|STRAIGHT_JOIN|OVER|PERCENTILE_CONT|PARQUET|OPTIMIZE|UESCAPE|NATIONAL|RELY|NULL|ALTER|DISABLE|PARTITION|NCLOB|TRIGGER|INTERVAL|UNION|UNCACHED|ARRAY_AGG|REGR_COUNT|OF|DECFLOAT|TIMEZONE_HOUR|CROSS|STORED|VIEWS|CHANGE|REFRESH|TABLES|LOCAL|LISTAGG|REGR_INTERCEPT|INPATH|UNNEST|MACRO|SYSTEM_TIME|DELETE|THEN|DATE|BY|SELECT|RCFILE|DATABASES|NOVALIDATE|PRODUCED|TERMINATED|UNKNOWN|AVRO|INIT_FN|MORE|REVOKE|CONF|REGR_SXY|DEALLOCATE|FALSE|BEGIN_PARTITION|IN|REFERENCES|KUDU|WITHOUT|HAVING|FORMATTED|MULTISET|METADATA|EACH|VARBINARY|LESS|CONTAINS|FIELDS|NULLS|SYSTEM_VERSION|IS|DEFAULT|RECOVER|REPEATABLE|WHEN|PROCEDURE|SCHEMA|PTF|TIMEZONE_MINUTE|SCOPE|ICEBERG|CONVERT|LIKE_REGEX|ASYMMETRIC|SAVEPOINT|SIMILAR|INNER|COPY|INCREMENTAL|REGR_R2|ROLLUP|EXTENDED|FILTER|REDUCE|SYNC|REPLICATION|SEEK|IMPORT|SYMBOL|CURRENT|EVERY|REGEXP|INVALIDATE|NONE|SHOW|ONE|ROW|FETCH|COLUMN|FOLLOWING|FORMAT|INSERT|ADD|HASH|FOR|CHARACTER|EXEC|IREGEXP|CREATE|SKIP|ROLES|OUT|CORRESPONDING|INTEGER|CASCADE|ILIKE|CACHED|COMPRESSION|ONLY|MATCH_NUMBER|ZORDER|LATERAL|INT|CALLED|ON|INTO|WINDOW|DATABASE|JSON_ARRAY|FILEFORMAT|PORTION|PRECEDES|MANAGEDLOCATION|NOT|FOREIGN|FRAME_ROW|CAST|START|SEARCH|SQLWARNING|GROUP|VALUES|DATETIME|END_PARTITION|INDICATOR|UPDATE|COVAR_POP|ANY|SUCCEEDS|RENAME|UPDATE_FN|VARYING|ROLE|UNIQUE|DESC|FROM|SORT|ANALYTIC|RESPECT|LINES|INTERSECT|DROP|HUDIPARQUET|BEGIN_FRAME|VARCHAR|PRIMARY|PARTITIONED|BINARY|TABLE|RIGHT|JSON_OBJECT|ASENSITIVE|CARDINALITY|SETS|ENCODING|SMALLINT|RANGE|AUTHORIZATION|REAL|CLOB|SUBMULTISET)$"#)),
})
);

// name='NameKeywordSegment'
pub static NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NamedWindowExpressionSegment'
pub static NAMED_WINDOW_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// NamedWindowExpressionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WindowSpecificationSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Greedy,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='NamedWindowSegment'
pub static NAMED_WINDOW_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// NamedWindowSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WindowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NamedWindowExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='NamesKeywordSegment'
pub static NAMES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NAMES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NanKeywordSegment'
pub static NAN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NAN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NanLiteralSegment'
pub static NAN_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NAN",
    token_type: "null_literal",
    raw_class: "LiteralKeywordSegment",
    optional: false,
})
);

// name='NationalKeywordSegment'
pub static NATIONAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NATIONAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NaturalJoinKeywordsGrammar'
pub static NATURAL_JOIN_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NaturalKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NATURAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "JoinTypeKeywordsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FULL".to_string(), "INNER".to_string(), "LEFT".to_string(), "RIGHT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NATURAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='NaturalKeywordSegment'
pub static NATURAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NATURAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NcharKeywordSegment'
pub static NCHAR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NCHAR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NclobKeywordSegment'
pub static NCLOB_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NCLOB",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NegativeSegment'
pub static NEGATIVE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "-",
    token_type: "sign_indicator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='NestedJoinGrammar'
pub static NESTED_JOIN_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='NestingKeywordSegment'
pub static NESTING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NESTING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NewKeywordSegment'
pub static NEW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NEW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NewlineSegment'
pub static NEWLINE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "newline",
//    token_type: "NewlineSegment",
})
);

// name='NextKeywordSegment'
pub static NEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NoKeywordSegment'
pub static NO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='No_dropKeywordSegment'
pub static NO_DROP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NO_DROP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='No_write_to_binlogKeywordSegment'
pub static NO_WRITE_TO_BINLOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NO_WRITE_TO_BINLOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NoauditKeywordSegment'
pub static NOAUDIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOAUDIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NocacheKeywordSegment'
pub static NOCACHE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOCACHE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NocheckKeywordSegment'
pub static NOCHECK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOCHECK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NocompressKeywordSegment'
pub static NOCOMPRESS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOCOMPRESS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NocreatedbKeywordSegment'
pub static NOCREATEDB_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOCREATEDB",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NocreateroleKeywordSegment'
pub static NOCREATEROLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOCREATEROLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NocreateuserKeywordSegment'
pub static NOCREATEUSER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOCREATEUSER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NocycleKeywordSegment'
pub static NOCYCLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOCYCLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NoinheritKeywordSegment'
pub static NOINHERIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOINHERIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NologinKeywordSegment'
pub static NOLOGIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOLOGIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NonKeywordSegment'
pub static NON_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NON",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NonSetSelectableGrammar'
pub static NON_SET_SELECTABLE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ValuesClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UnorderedSelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithCompoundStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NonSetSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedSetExpressionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='NonStandardJoinTypeKeywordsGrammar'
pub static NON_STANDARD_JOIN_TYPE_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='NonWithNonSelectableGrammar'
pub static NON_WITH_NON_SELECTABLE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UpdateStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InsertStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeleteStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MergeStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MERGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string(), "INSERT".to_string(), "MERGE".to_string(), "UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='NonWithSelectableGrammar'
pub static NON_WITH_SELECTABLE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NonSetSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='NonclusteredKeywordSegment'
pub static NONCLUSTERED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NONCLUSTERED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NoneKeywordSegment'
pub static NONE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NONE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NoorderKeywordSegment'
pub static NOORDER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOORDER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NorelyKeywordSegment'
pub static NORELY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NORELY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NormalizeKeywordSegment'
pub static NORMALIZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NORMALIZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NormalizedGrammar'
pub static NORMALIZED_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='NormalizedKeywordSegment'
pub static NORMALIZED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NORMALIZED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NoscanKeywordSegment'
pub static NOSCAN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOSCAN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NoshuffleKeywordSegment'
pub static NOSHUFFLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOSHUFFLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NosuperuserKeywordSegment'
pub static NOSUPERUSER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOSUPERUSER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NotEnforcedGrammar'
pub static NOT_ENFORCED_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='NotEqualToSegment'
pub static NOT_EQUAL_TO_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// NotEqualToSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RawNotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RawEqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RawLessThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RawGreaterThanSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([">".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='NotKeywordSegment'
pub static NOT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NotNullGrammar'
pub static NOT_NULL_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='NotOperatorGrammar'
pub static NOT_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NothingKeywordSegment'
pub static NOTHING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOTHING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NotifyKeywordSegment'
pub static NOTIFY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOTIFY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NotnullKeywordSegment'
pub static NOTNULL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOTNULL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NovalidateKeywordSegment'
pub static NOVALIDATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOVALIDATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NowaitKeywordSegment'
pub static NOWAIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NOWAIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Nth_valueKeywordSegment'
pub static NTH_VALUE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NTH_VALUE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NullKeywordSegment'
pub static NULL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NULL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NullLiteralSegment'
pub static NULL_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NULL",
    token_type: "null_literal",
    raw_class: "LiteralKeywordSegment",
    optional: false,
})
);

// name='NullableKeywordSegment'
pub static NULLABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NULLABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NullifKeywordSegment'
pub static NULLIF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NULLIF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NullsKeywordSegment'
pub static NULLS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NULLS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NumberKeywordSegment'
pub static NUMBER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NUMBER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NumericKeywordSegment'
pub static NUMERIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "NUMERIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='NumericLiteralSegment'
pub static NUMERIC_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::TypedParser {
    template: "numeric_literal",
    token_type: "numeric_literal",
    raw_class: "LiteralSegment",
    optional: false,
})
);

// name='ObjectKeywordSegment'
pub static OBJECT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OBJECT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ObjectLiteralElementSegment'
pub static OBJECT_LITERAL_ELEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ObjectLiteralElementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColonSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([":".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BaseExpressionElementGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
);

// name='ObjectLiteralSegment'
pub static OBJECT_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ObjectLiteralSegment
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ObjectLiteralElementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: true,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "{",
    token_type: "start_curly_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: "}",
    token_type: "end_curly_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["{".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ObjectReferenceDelimiterGrammar'
pub static OBJECT_REFERENCE_DELIMITER_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ObjectReferenceSegment'
pub static OBJECT_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ObjectReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ObjectReferenceTerminatorGrammar'
pub static OBJECT_REFERENCE_TERMINATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UsingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CastOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["::".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StartSquareBracketSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StartBracketSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "AND".to_string(), "DIV".to_string(), "IS".to_string(), "OR".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColonSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([":".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "JoinLikeClauseGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Token{
    token_type: "bracketed",
//    token_type: "BracketedSegment",
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ObjectsKeywordSegment'
pub static OBJECTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OBJECTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Occurrences_regexKeywordSegment'
pub static OCCURRENCES_REGEX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OCCURRENCES_REGEX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Octet_lengthKeywordSegment'
pub static OCTET_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OCTET_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OctetsKeywordSegment'
pub static OCTETS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OCTETS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OfKeywordSegment'
pub static OF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OffKeywordSegment'
pub static OFF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OFF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OfflineKeywordSegment'
pub static OFFLINE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OFFLINE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OffsetClauseSegment'
pub static OFFSET_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// OffsetClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OffsetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OFFSET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OFFSET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='OffsetKeywordSegment'
pub static OFFSET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OFFSET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OffsetsKeywordSegment'
pub static OFFSETS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OFFSETS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OidsKeywordSegment'
pub static OIDS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OIDS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OldKeywordSegment'
pub static OLD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OLD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OmitKeywordSegment'
pub static OMIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OMIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OnKeywordSegment'
pub static ON_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ON",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OneKeywordSegment'
pub static ONE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ONE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OnlineKeywordSegment'
pub static ONLINE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ONLINE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OnlyKeywordSegment'
pub static ONLY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ONLY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OpenKeywordSegment'
pub static OPEN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPEN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OpendatasourceKeywordSegment'
pub static OPENDATASOURCE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPENDATASOURCE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OpenqueryKeywordSegment'
pub static OPENQUERY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPENQUERY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OpenrowsetKeywordSegment'
pub static OPENROWSET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPENROWSET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OpenxmlKeywordSegment'
pub static OPENXML_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPENXML",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OperateKeywordSegment'
pub static OPERATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPERATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OperationKeywordSegment'
pub static OPERATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPERATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OperatorKeywordSegment'
pub static OPERATOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPERATOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OptimizeKeywordSegment'
pub static OPTIMIZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPTIMIZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OptionKeywordSegment'
pub static OPTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OptionallyKeywordSegment'
pub static OPTIONALLY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPTIONALLY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OptionsKeywordSegment'
pub static OPTIONS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OPTIONS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OrKeywordSegment'
pub static OR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OrOperatorGrammar'
pub static OR_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OR",
    token_type: "binary_operator",
    raw_class: "BinaryOperatorSegment",
    optional: false,
})
);

// name='OrReplaceGrammar'
pub static OR_REPLACE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReplaceKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REPLACE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='OrcKeywordSegment'
pub static ORC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ORC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OrderByClauseSegment'
pub static ORDER_BY_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// OrderByClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AscKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ASC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DescKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DESC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ASC".to_string(), "DESC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NullsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULLS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FirstKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIRST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LastKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LAST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIRST".to_string(), "LAST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULLS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithFillSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "LimitClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FrameClauseUnitGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='OrderByClauseTerminators'
pub static ORDER_BY_CLAUSE_TERMINATORS: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LimitClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "HavingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QualifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["QUALIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WindowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FrameClauseUnitGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SeparatorKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SEPARATOR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FetchKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FETCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FETCH".to_string(), "HAVING".to_string(), "LIMIT".to_string(), "QUALIFY".to_string(), "RANGE".to_string(), "ROWS".to_string(), "SEPARATOR".to_string(), "WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='OrderKeywordSegment'
pub static ORDER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ORDER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OrderNoOrderGrammar'
pub static ORDER_NO_ORDER_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NoorderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOORDER".to_string(), "ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='OrderingKeywordSegment'
pub static ORDERING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ORDERING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OrdinalityKeywordSegment'
pub static ORDINALITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ORDINALITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OthersKeywordSegment'
pub static OTHERS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OTHERS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OutKeywordSegment'
pub static OUT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OUT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OuterKeywordSegment'
pub static OUTER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OUTER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OutfileKeywordSegment'
pub static OUTFILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OUTFILE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OutputKeywordSegment'
pub static OUTPUT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OUTPUT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OutputdriverKeywordSegment'
pub static OUTPUTDRIVER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OUTPUTDRIVER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OutputformatKeywordSegment'
pub static OUTPUTFORMAT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OUTPUTFORMAT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OverClauseSegment'
pub static OVER_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// OverClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "IgnoreRespectNullsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IGNORE".to_string(), "RESPECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OverKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WindowSpecificationSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Greedy,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='OverKeywordSegment'
pub static OVER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OVER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OverlapsClauseSegment'
pub static OVERLAPS_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// OverlapsClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OverlapsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERLAPS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DateTimeLiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string(), "INTERVAL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DateTimeLiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string(), "INTERVAL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERLAPS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='OverlapsKeywordSegment'
pub static OVERLAPS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OVERLAPS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OverlayKeywordSegment'
pub static OVERLAY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OVERLAY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OverridingKeywordSegment'
pub static OVERRIDING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OVERRIDING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OverwriteKeywordSegment'
pub static OVERWRITE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OVERWRITE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OwnerKeywordSegment'
pub static OWNER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OWNER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='OwnershipKeywordSegment'
pub static OWNERSHIP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "OWNERSHIP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Pack_keysKeywordSegment'
pub static PACK_KEYS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PACK_KEYS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PadKeywordSegment'
pub static PAD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PAD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ParameterKeywordSegment'
pub static PARAMETER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARAMETER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ParameterNameSegment'
pub static PARAMETER_NAME_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::RegexParser {
    template: RegexMode::new(r#"\"?[A-Z][A-Z0-9_]*\"?"#),
    token_type: "parameter",
    raw_class: "CodeSegment",
    optional: false,
    anti_template: None,
})
);

// name='ParameterSegment'
pub static PARAMETER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "?",
    token_type: "parameter",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='Parameter_modeKeywordSegment'
pub static PARAMETER_MODE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARAMETER_MODE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Parameter_nameKeywordSegment'
pub static PARAMETER_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARAMETER_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Parameter_ordinal_positionKeywordSegment'
pub static PARAMETER_ORDINAL_POSITION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARAMETER_ORDINAL_POSITION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Parameter_specific_catalogKeywordSegment'
pub static PARAMETER_SPECIFIC_CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARAMETER_SPECIFIC_CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Parameter_specific_nameKeywordSegment'
pub static PARAMETER_SPECIFIC_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARAMETER_SPECIFIC_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Parameter_specific_schemaKeywordSegment'
pub static PARAMETER_SPECIFIC_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARAMETER_SPECIFIC_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ParametersKeywordSegment'
pub static PARAMETERS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARAMETERS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ParquetKeywordSegment'
pub static PARQUET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARQUET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ParquetfileKeywordSegment'
pub static PARQUETFILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARQUETFILE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PartialKeywordSegment'
pub static PARTIAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARTIAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PartialscanKeywordSegment'
pub static PARTIALSCAN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARTIALSCAN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PartitionClauseSegment'
pub static PARTITION_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// PartitionClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PartitionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='PartitionKeywordSegment'
pub static PARTITION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARTITION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PartitionSpecGrammar'
pub static PARTITION_SPEC_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PartitionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "EqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='PartitionedKeywordSegment'
pub static PARTITIONED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARTITIONED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PartitionsKeywordSegment'
pub static PARTITIONS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PARTITIONS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PascalKeywordSegment'
pub static PASCAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PASCAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PasswordKeywordSegment'
pub static PASSWORD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PASSWORD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PathKeywordSegment'
pub static PATH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PATH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PathSegment'
pub static PATH_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// PathSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SlashSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["/".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::TypedParser {
    template: "word",
    token_type: "path_segment",
    raw_class: "WordSegment",
    optional: false,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "SlashSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["/".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["word".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["/".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["/".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
);

// name='PatternKeywordSegment'
pub static PATTERN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PATTERN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PatternMatchingGrammar'
pub static PATTERN_MATCHING_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='PctfreeKeywordSegment'
pub static PCTFREE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PCTFREE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PerKeywordSegment'
pub static PER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PercentKeywordSegment'
pub static PERCENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PERCENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Percent_rankKeywordSegment'
pub static PERCENT_RANK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PERCENT_RANK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Percentile_contKeywordSegment'
pub static PERCENTILE_CONT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PERCENTILE_CONT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Percentile_discKeywordSegment'
pub static PERCENTILE_DISC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PERCENTILE_DISC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PipeKeywordSegment'
pub static PIPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PIPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PipeSegment'
pub static PIPE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "|",
    token_type: "pipe",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='PlacingKeywordSegment'
pub static PLACING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PLACING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PlanKeywordSegment'
pub static PLAN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PLAN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PliKeywordSegment'
pub static PLI_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PLI",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PlusKeywordSegment'
pub static PLUS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PLUS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PlusSegment'
pub static PLUS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "+",
    token_type: "binary_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='PolicyKeywordSegment'
pub static POLICY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "POLICY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PortionKeywordSegment'
pub static PORTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PORTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PositionKeywordSegment'
pub static POSITION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "POSITION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Position_regexKeywordSegment'
pub static POSITION_REGEX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "POSITION_REGEX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PositiveSegment'
pub static POSITIVE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "+",
    token_type: "sign_indicator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='PostFunctionGrammar'
pub static POST_FUNCTION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OverClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FilterClauseGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FILTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='PostTableExpressionGrammar'
pub static POST_TABLE_EXPRESSION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='PostfixKeywordSegment'
pub static POSTFIX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "POSTFIX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PowerKeywordSegment'
pub static POWER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "POWER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PreTableFunctionKeywordsGrammar'
pub static PRE_TABLE_FUNCTION_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='PrecedesKeywordSegment'
pub static PRECEDES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRECEDES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrecedingKeywordSegment'
pub static PRECEDING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRECEDING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrecisionKeywordSegment'
pub static PRECISION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRECISION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrefixKeywordSegment'
pub static PREFIX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PREFIX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PreorderKeywordSegment'
pub static PREORDER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PREORDER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrepareKeywordSegment'
pub static PREPARE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PREPARE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Prepare_fnKeywordSegment'
pub static PREPARE_FN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PREPARE_FN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PreparedKeywordSegment'
pub static PREPARED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PREPARED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PreserveKeywordSegment'
pub static PRESERVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRESERVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrettyKeywordSegment'
pub static PRETTY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRETTY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrimaryKeyGrammar'
pub static PRIMARY_KEY_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PrimaryKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIMARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "KeyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["KEY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIMARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='PrimaryKeywordSegment'
pub static PRIMARY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRIMARY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrimitiveTypeSegment'
pub static PRIMITIVE_TYPE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// PrimitiveTypeSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TinyintKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TINYINT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SmallintKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SMALLINT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IntegerKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTEGER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BigintKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BIGINT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BooleanKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BOOLEAN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FloatKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FLOAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DoubleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DOUBLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PrecisionKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRECISION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DOUBLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StringKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BinaryKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BINARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TimestampKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DecimalKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DECIMAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DecKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NUMERIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEC".to_string(), "DECIMAL".to_string(), "NUMERIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedArguments",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEC".to_string(), "DECIMAL".to_string(), "NUMERIC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "VarcharKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CharKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "JsonKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["JSON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='PrincipalsKeywordSegment'
pub static PRINCIPALS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRINCIPALS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrintKeywordSegment'
pub static PRINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PriorKeywordSegment'
pub static PRIOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRIOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PrivilegesKeywordSegment'
pub static PRIVILEGES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRIVILEGES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ProcKeywordSegment'
pub static PROC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PROC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ProceduralKeywordSegment'
pub static PROCEDURAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PROCEDURAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ProcedureKeywordSegment'
pub static PROCEDURE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PROCEDURE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ProceduresKeywordSegment'
pub static PROCEDURES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PROCEDURES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ProcessKeywordSegment'
pub static PROCESS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PROCESS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ProcesslistKeywordSegment'
pub static PROCESSLIST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PROCESSLIST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ProducedKeywordSegment'
pub static PRODUCED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PRODUCED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PropertyGrammar'
pub static PROPERTY_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "EqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
);

// name='ProtectionKeywordSegment'
pub static PROTECTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PROTECTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PtfKeywordSegment'
pub static PTF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PTF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PublicKeywordSegment'
pub static PUBLIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PUBLIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='PurgeKeywordSegment'
pub static PURGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "PURGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='QualifiedNumericLiteralSegment'
pub static QUALIFIED_NUMERIC_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// QualifiedNumericLiteralSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SignedSegmentGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='QualifyKeywordSegment'
pub static QUALIFY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "QUALIFY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='QuarterKeywordSegment'
pub static QUARTER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "QUARTER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='QuoteKeywordSegment'
pub static QUOTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "QUOTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='QuotedIdentifierSegment'
pub static QUOTED_IDENTIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::TypedParser {
    template: "double_quote",
    token_type: "quoted_identifier",
    raw_class: "IdentifierSegment",
    optional: false,
})
);

// name='QuotedLiteralSegment'
pub static QUOTED_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::TypedParser {
    template: "single_quote",
    token_type: "quoted_literal",
    raw_class: "LiteralSegment",
    optional: false,
})
,
Arc::new(Grammar::TypedParser {
    template: "double_quote",
    token_type: "quoted_literal",
    raw_class: "LiteralSegment",
    optional: false,
})
,
Arc::new(Grammar::TypedParser {
    template: "back_quote",
    token_type: "quoted_literal",
    raw_class: "LiteralSegment",
    optional: false,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
);

// name='Raid0KeywordSegment'
pub static RAID0_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RAID0",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RaiserrorKeywordSegment'
pub static RAISERROR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RAISERROR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RangeKeywordSegment'
pub static RANGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RANGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RankKeywordSegment'
pub static RANK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RANK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RawEqualsSegment'
pub static RAW_EQUALS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "=",
    token_type: "raw_comparison_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='RawGreaterThanSegment'
pub static RAW_GREATER_THAN_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ">",
    token_type: "raw_comparison_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='RawKeywordSegment'
pub static RAW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RAW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RawLessThanSegment'
pub static RAW_LESS_THAN_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "<",
    token_type: "raw_comparison_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='RawNotSegment'
pub static RAW_NOT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "!",
    token_type: "raw_comparison_operator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='RawSegment'
pub static RAW_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "raw",
//    token_type: "RawSegment",
})
);

// name='RcfileKeywordSegment'
pub static RCFILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RCFILE",
    token_type: "file_format",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReadKeywordSegment'
pub static READ_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "READ",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReadonlyKeywordSegment'
pub static READONLY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "READONLY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReadsKeywordSegment'
pub static READS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "READS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReadtextKeywordSegment'
pub static READTEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "READTEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RealKeywordSegment'
pub static REAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RebuildKeywordSegment'
pub static REBUILD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REBUILD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RecheckKeywordSegment'
pub static RECHECK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RECHECK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReconfigureKeywordSegment'
pub static RECONFIGURE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RECONFIGURE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RecordreaderKeywordSegment'
pub static RECORDREADER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RECORDREADER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RecordwriterKeywordSegment'
pub static RECORDWRITER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RECORDWRITER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RecoverKeywordSegment'
pub static RECOVER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RECOVER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RecursiveKeywordSegment'
pub static RECURSIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RECURSIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReduceKeywordSegment'
pub static REDUCE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REDUCE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RefKeywordSegment'
pub static REF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReferenceDefinitionGrammar'
pub static REFERENCE_DEFINITION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ReferencesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReferenceMatchGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::AnySetOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeleteKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReferentialActionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "NO".to_string(), "RESTRICT".to_string(), "SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UpdateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReferentialActionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "NO".to_string(), "RESTRICT".to_string(), "SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ReferenceMatchGrammar'
pub static REFERENCE_MATCH_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MatchKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FullKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "PartialKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTIAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SimpleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SIMPLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FULL".to_string(), "PARTIAL".to_string(), "SIMPLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MATCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Reference_usageKeywordSegment'
pub static REFERENCE_USAGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REFERENCE_USAGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReferencesKeywordSegment'
pub static REFERENCES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REFERENCES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReferencingKeywordSegment'
pub static REFERENCING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REFERENCING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReferentialActionGrammar'
pub static REFERENTIAL_ACTION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RestrictKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RESTRICT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CascadeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NullKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NoKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ActionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ACTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DefaultKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFAULT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASCADE".to_string(), "NO".to_string(), "RESTRICT".to_string(), "SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='RefreshKeywordSegment'
pub static REFRESH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REFRESH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RegexpKeywordSegment'
pub static REGEXP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGEXP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_avgxKeywordSegment'
pub static REGR_AVGX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_AVGX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_avgyKeywordSegment'
pub static REGR_AVGY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_AVGY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_countKeywordSegment'
pub static REGR_COUNT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_COUNT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_interceptKeywordSegment'
pub static REGR_INTERCEPT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_INTERCEPT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_r2KeywordSegment'
pub static REGR_R2_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_R2",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_slopeKeywordSegment'
pub static REGR_SLOPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_SLOPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_sxxKeywordSegment'
pub static REGR_SXX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_SXX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_sxyKeywordSegment'
pub static REGR_SXY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_SXY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Regr_syyKeywordSegment'
pub static REGR_SYY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REGR_SYY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReindexKeywordSegment'
pub static REINDEX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REINDEX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RelativeKeywordSegment'
pub static RELATIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RELATIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReleaseKeywordSegment'
pub static RELEASE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RELEASE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReloadKeywordSegment'
pub static RELOAD_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RELOAD",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RelyKeywordSegment'
pub static RELY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RELY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RenameKeywordSegment'
pub static RENAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RENAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RepairKeywordSegment'
pub static REPAIR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REPAIR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RepeatKeywordSegment'
pub static REPEAT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REPEAT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RepeatableKeywordSegment'
pub static REPEATABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REPEATABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReplaceKeywordSegment'
pub static REPLACE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REPLACE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReplicationKeywordSegment'
pub static REPLICATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REPLICATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RequireKeywordSegment'
pub static REQUIRE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REQUIRE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ResetKeywordSegment'
pub static RESET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RESET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ResignalKeywordSegment'
pub static RESIGNAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RESIGNAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ResourceKeywordSegment'
pub static RESOURCE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RESOURCE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RespectKeywordSegment'
pub static RESPECT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RESPECT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RestartKeywordSegment'
pub static RESTART_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RESTART",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RestoreKeywordSegment'
pub static RESTORE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RESTORE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RestrictKeywordSegment'
pub static RESTRICT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RESTRICT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ResultKeywordSegment'
pub static RESULT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RESULT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReturnKeywordSegment'
pub static RETURN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RETURN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Returned_cardinalityKeywordSegment'
pub static RETURNED_CARDINALITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RETURNED_CARDINALITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Returned_lengthKeywordSegment'
pub static RETURNED_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RETURNED_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Returned_octet_lengthKeywordSegment'
pub static RETURNED_OCTET_LENGTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RETURNED_OCTET_LENGTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Returned_sqlstateKeywordSegment'
pub static RETURNED_SQLSTATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RETURNED_SQLSTATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ReturnsKeywordSegment'
pub static RETURNS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RETURNS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RevokeKeywordSegment'
pub static REVOKE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REVOKE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RewriteKeywordSegment'
pub static REWRITE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "REWRITE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RightKeywordSegment'
pub static RIGHT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RIGHT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RlikeKeywordSegment'
pub static RLIKE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RLIKE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RoleKeywordSegment'
pub static ROLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RoleReferenceSegment'
pub static ROLE_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// RoleReferenceSegment
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
);

// name='RolesKeywordSegment'
pub static ROLES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROLES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RollbackKeywordSegment'
pub static ROLLBACK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROLLBACK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RollupFunctionNameSegment'
pub static ROLLUP_FUNCTION_NAME_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// RollupFunctionNameSegment
Arc::new(Grammar::StringParser {
    template: "ROLLUP",
    token_type: "function_name_identifier",
    raw_class: "CodeSegment",
    optional: false,
})
);

// name='RollupKeywordSegment'
pub static ROLLUP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROLLUP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RoutineKeywordSegment'
pub static ROUTINE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROUTINE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Routine_catalogKeywordSegment'
pub static ROUTINE_CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROUTINE_CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Routine_nameKeywordSegment'
pub static ROUTINE_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROUTINE_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Routine_schemaKeywordSegment'
pub static ROUTINE_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROUTINE_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RoutinesKeywordSegment'
pub static ROUTINES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROUTINES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RowFormatClauseSegment'
pub static ROW_FORMAT_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// RowFormatClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FormatKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FORMAT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DelimitedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELIMITED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FieldsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIELDS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TerminatedByGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TERMINATED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "EscapedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ESCAPED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ESCAPED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIELDS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CollectionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COLLECTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ItemsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ITEMS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TerminatedByGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TERMINATED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COLLECTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MapKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "KeysKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["KEYS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TerminatedByGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TERMINATED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LinesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LINES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TerminatedByGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TERMINATED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LINES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NullKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DefinedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFINED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELIMITED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SerdeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SERDE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SerdePropertiesGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SERDE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELIMITED".to_string(), "SERDE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='RowFunctionContentsSegment'
pub static ROW_FUNCTION_CONTENTS_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// RowFunctionContentsSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BaseExpressionElementGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='RowKeywordSegment'
pub static ROW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Row_countKeywordSegment'
pub static ROW_COUNT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROW_COUNT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Row_numberKeywordSegment'
pub static ROW_NUMBER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROW_NUMBER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RowcountKeywordSegment'
pub static ROWCOUNT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROWCOUNT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RowguidcolKeywordSegment'
pub static ROWGUIDCOL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROWGUIDCOL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RowidKeywordSegment'
pub static ROWID_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROWID",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RownumKeywordSegment'
pub static ROWNUM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROWNUM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RowsKeywordSegment'
pub static ROWS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ROWS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RuleKeywordSegment'
pub static RULE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RULE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RunningKeywordSegment'
pub static RUNNING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RUNNING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='RwstorageKeywordSegment'
pub static RWSTORAGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "RWSTORAGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SamplingExpressionSegment'
pub static SAMPLING_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SamplingExpressionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TablesampleKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLESAMPLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BucketKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BUCKET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OutKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OUT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OfKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BUCKET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PercentKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PERCENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RowsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PERCENT".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::RegexParser {
    template: RegexMode::new(r#"\d+[bBkKmMgG]"#),
    token_type: "byte_length_literal",
    raw_class: "CodeSegment",
    optional: false,
    anti_template: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AliasExpressionSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLESAMPLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SaveKeywordSegment'
pub static SAVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SAVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SavepointKeywordSegment'
pub static SAVEPOINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SAVEPOINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ScaleKeywordSegment'
pub static SCALE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCALE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SchemaKeywordSegment'
pub static SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SchemaReferenceSegment'
pub static SCHEMA_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SchemaReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Schema_nameKeywordSegment'
pub static SCHEMA_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCHEMA_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SchemasKeywordSegment'
pub static SCHEMAS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCHEMAS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ScopeKeywordSegment'
pub static SCOPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCOPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Scope_catalogKeywordSegment'
pub static SCOPE_CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCOPE_CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Scope_nameKeywordSegment'
pub static SCOPE_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCOPE_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Scope_schemaKeywordSegment'
pub static SCOPE_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCOPE_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ScrollKeywordSegment'
pub static SCROLL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SCROLL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SearchKeywordSegment'
pub static SEARCH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SEARCH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SecondKeywordSegment'
pub static SECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Second_microsecondKeywordSegment'
pub static SECOND_MICROSECOND_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SECOND_MICROSECOND",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SecondsKeywordSegment'
pub static SECONDS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SECONDS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SectionKeywordSegment'
pub static SECTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SECTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SecurityKeywordSegment'
pub static SECURITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SECURITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SeekKeywordSegment'
pub static SEEK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SEEK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SelectClauseElementSegment'
pub static SELECT_CLAUSE_ELEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SelectClauseElementSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WildcardExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BaseExpressionElementGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AliasExpressionSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='SelectClauseModifierSegment'
pub static SELECT_CLAUSE_MODIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SelectClauseModifierSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DistinctKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTINCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "DISTINCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SelectClauseSegment'
pub static SELECT_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SelectClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SelectClauseModifierSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "DISTINCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectClauseElementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: true,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "SelectClauseTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "EXCEPT".to_string(), "FETCH".to_string(), "FROM".to_string(), "INTERSECT".to_string(), "LIMIT".to_string(), "MINUS".to_string(), "ORDER".to_string(), "OVERLAPS".to_string(), "SORT".to_string(), "UNION".to_string(), "WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ClusterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DistributeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::GreedyOnceStarted,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SelectClauseTerminatorGrammar'
pub static SELECT_CLAUSE_TERMINATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FromKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WhereKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ClusterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DistributeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LimitClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OverlapsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERLAPS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SetOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FetchKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FETCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "EXCEPT".to_string(), "FETCH".to_string(), "FROM".to_string(), "INTERSECT".to_string(), "LIMIT".to_string(), "MINUS".to_string(), "ORDER".to_string(), "OVERLAPS".to_string(), "SORT".to_string(), "UNION".to_string(), "WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SelectKeywordSegment'
pub static SELECT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SELECT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SelectStatementSegment'
pub static SELECT_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SelectStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WhereClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GroupByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "HavingClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OverlapsClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERLAPS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NamedWindowSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrderByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OffsetClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OFFSET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FetchClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FETCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ClusterByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DistributeByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SortByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LimitClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NamedWindowSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "SetOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithNoSchemaBindingClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithDataClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::GreedyOnceStarted,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SelectableGrammar'
pub static SELECTABLE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithCompoundStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithCompoundStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithCompoundNonSelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithCompoundNonSelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NonWithSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SelectivityKeywordSegment'
pub static SELECTIVITY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SELECTIVITY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SelfKeywordSegment'
pub static SELF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SELF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SemiKeywordSegment'
pub static SEMI_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SEMI",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SemicolonSegment'
pub static SEMICOLON_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ";",
    token_type: "statement_terminator",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='SensitiveKeywordSegment'
pub static SENSITIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SENSITIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SeparatorKeywordSegment'
pub static SEPARATOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SEPARATOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SequenceKeywordSegment'
pub static SEQUENCE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SEQUENCE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SequenceMaxValueGrammar'
pub static SEQUENCE_MAX_VALUE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MaxvalueKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAXVALUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAXVALUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NoKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MaxvalueKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAXVALUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MAXVALUE".to_string(), "NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SequenceMinValueGrammar'
pub static SEQUENCE_MIN_VALUE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MinvalueKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MINVALUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MINVALUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NoKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MinvalueKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MINVALUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MINVALUE".to_string(), "NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SequenceReferenceSegment'
pub static SEQUENCE_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SequenceReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='SequencefileKeywordSegment'
pub static SEQUENCEFILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SEQUENCEFILE",
    token_type: "file_format",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SequencesKeywordSegment'
pub static SEQUENCES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SEQUENCES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SerdeKeywordSegment'
pub static SERDE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SERDE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SerdePropertiesGrammar'
pub static SERDE_PROPERTIES_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SerdepropertiesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SERDEPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedPropertyListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SerdepropertiesKeywordSegment'
pub static SERDEPROPERTIES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SERDEPROPERTIES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SerializableKeywordSegment'
pub static SERIALIZABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SERIALIZABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Serialize_fnKeywordSegment'
pub static SERIALIZE_FN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SERIALIZE_FN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ServerKeywordSegment'
pub static SERVER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SERVER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Server_nameKeywordSegment'
pub static SERVER_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SERVER_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SessionKeywordSegment'
pub static SESSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SESSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Session_userKeywordSegment'
pub static SESSION_USER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SESSION_USER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SetClauseListSegment'
pub static SET_CLAUSE_LIST_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SetClauseListSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SetClauseSegment'
pub static SET_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SetClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "EqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BareFunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT_DATE".to_string(), "CURRENT_TIME".to_string(), "CURRENT_TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ValuesClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DefaultKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFAULT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='SetExpressionSegment'
pub static SET_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SetExpressionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NonSetSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NonSetSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 1,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrderByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ClusterByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DistributeByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SortByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LimitClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NamedWindowSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SetKeywordSegment'
pub static SET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SetOperatorSegment'
pub static SET_OPERATOR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SetOperatorSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UnionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "IntersectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INTERSECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExceptKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MinusKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MINUS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: Some(Box::new(
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExceptKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Anything)
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SetSchemaStatementSegment'
pub static SET_SCHEMA_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SetSchemaStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "IfNotExistsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["IF".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SetStatementSegment'
pub static SET_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SetStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::StringParser {
    template: "-",
    token_type: "option_indicator",
    raw_class: "SymbolSegment",
    optional: false,
})
,
Arc::new(Grammar::StringParser {
    template: "V",
    token_type: "option",
    raw_class: "CodeSegment",
    optional: false,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ParameterNameSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ColonDelimiterSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([":".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string(), ":".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "RawEqualsSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["=".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SetofKeywordSegment'
pub static SETOF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SETOF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SetsKeywordSegment'
pub static SETS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SETS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SetuserKeywordSegment'
pub static SETUSER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SETUSER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ShareKeywordSegment'
pub static SHARE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SHARE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SharedKeywordSegment'
pub static SHARED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SHARED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SharesKeywordSegment'
pub static SHARES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SHARES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ShorthandCastSegment'
pub static SHORTHAND_CAST_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ShorthandCastSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Expression_D_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "CaseExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CASE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CastOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["::".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TimeZoneGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["::".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 1,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["::".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='ShowKeywordSegment'
pub static SHOW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SHOW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Show_databaseKeywordSegment'
pub static SHOW_DATABASE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SHOW_DATABASE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ShuffleKeywordSegment'
pub static SHUFFLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SHUFFLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ShutdownKeywordSegment'
pub static SHUTDOWN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SHUTDOWN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SignalKeywordSegment'
pub static SIGNAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SIGNAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SignedSegmentGrammar'
pub static SIGNED_SEGMENT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PositiveSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NegativeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SimilarKeywordSegment'
pub static SIMILAR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SIMILAR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SimpleKeywordSegment'
pub static SIMPLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SIMPLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SingleIdentifierGrammar'
pub static SINGLE_IDENTIFIER_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NakedIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "QuotedIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["double_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BackQuotedIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string()]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "DotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='SingleIdentifierListSegment'
pub static SINGLE_IDENTIFIER_LIST_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SingleIdentifierListSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='SingleQuotedIdentifierSegment'
pub static SINGLE_QUOTED_IDENTIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::TypedParser {
    template: "single_quote",
    token_type: "quoted_identifier",
    raw_class: "IdentifierSegment",
    optional: false,
})
);

// name='SizeKeywordSegment'
pub static SIZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SIZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SizedArrayTypeSegment'
pub static SIZED_ARRAY_TYPE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SizedArrayTypeSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ArrayTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ArrayAccessorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SkewedByClauseSegment'
pub static SKEWED_BY_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SkewedByClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SkewedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SKEWED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OnKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ON".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StoredKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DirectoriesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DIRECTORIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SKEWED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SkewedKeywordSegment'
pub static SKEWED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SKEWED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SkipKeywordSegment'
pub static SKIP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SKIP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SlashSegment'
pub static SLASH_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "/",
    token_type: "slash",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='SliceSegment'
pub static SLICE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: ":",
    token_type: "slice",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='SmallintKeywordSegment'
pub static SMALLINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SMALLINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SnapshotKeywordSegment'
pub static SNAPSHOT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SNAPSHOT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SomeKeywordSegment'
pub static SOME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SOME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SonameKeywordSegment'
pub static SONAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SONAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SortByClauseSegment'
pub static SORT_BY_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// SortByClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ColumnReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "NumericLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["numeric_literal".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AscKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ASC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DescKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DESC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ASC".to_string(), "DESC".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NullsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULLS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "FirstKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIRST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LastKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LAST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FIRST".to_string(), "LAST".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NULLS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "LimitKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FrameClauseUnitGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='SortKeywordSegment'
pub static SORT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SORT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SortedKeywordSegment'
pub static SORTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SORTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SourceKeywordSegment'
pub static SOURCE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SOURCE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SpaceKeywordSegment'
pub static SPACE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SPACE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SpatialKeywordSegment'
pub static SPATIAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SPATIAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SpecKeywordSegment'
pub static SPEC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SPEC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SpecificKeywordSegment'
pub static SPECIFIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SPECIFIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Specific_nameKeywordSegment'
pub static SPECIFIC_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SPECIFIC_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SpecifictypeKeywordSegment'
pub static SPECIFICTYPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SPECIFICTYPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SqlKeywordSegment'
pub static SQL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_big_resultKeywordSegment'
pub static SQL_BIG_RESULT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_BIG_RESULT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_big_selectsKeywordSegment'
pub static SQL_BIG_SELECTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_BIG_SELECTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_big_tablesKeywordSegment'
pub static SQL_BIG_TABLES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_BIG_TABLES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_calc_found_rowsKeywordSegment'
pub static SQL_CALC_FOUND_ROWS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_CALC_FOUND_ROWS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_log_offKeywordSegment'
pub static SQL_LOG_OFF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_LOG_OFF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_log_updateKeywordSegment'
pub static SQL_LOG_UPDATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_LOG_UPDATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_low_priority_updatesKeywordSegment'
pub static SQL_LOW_PRIORITY_UPDATES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_LOW_PRIORITY_UPDATES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_select_limitKeywordSegment'
pub static SQL_SELECT_LIMIT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_SELECT_LIMIT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_small_resultKeywordSegment'
pub static SQL_SMALL_RESULT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_SMALL_RESULT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Sql_warningsKeywordSegment'
pub static SQL_WARNINGS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQL_WARNINGS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SqlcaKeywordSegment'
pub static SQLCA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQLCA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SqlcodeKeywordSegment'
pub static SQLCODE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQLCODE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SqlerrorKeywordSegment'
pub static SQLERROR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQLERROR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SqlexceptionKeywordSegment'
pub static SQLEXCEPTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQLEXCEPTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SqlstateKeywordSegment'
pub static SQLSTATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQLSTATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SqlwarningKeywordSegment'
pub static SQLWARNING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQLWARNING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SqrtKeywordSegment'
pub static SQRT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SQRT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SslKeywordSegment'
pub static SSL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SSL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StableKeywordSegment'
pub static STABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StageKeywordSegment'
pub static STAGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STAGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StagesKeywordSegment'
pub static STAGES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STAGES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StarSegment'
pub static STAR_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "*",
    token_type: "star",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='StartAngleBracketSegment'
pub static START_ANGLE_BRACKET_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "<",
    token_type: "start_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='StartBracketSegment'
pub static START_BRACKET_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='StartCurlyBracketSegment'
pub static START_CURLY_BRACKET_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "{",
    token_type: "start_curly_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='StartKeywordSegment'
pub static START_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "START",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StartSquareBracketSegment'
pub static START_SQUARE_BRACKET_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "[",
    token_type: "start_square_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='StartingKeywordSegment'
pub static STARTING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STARTING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StartsKeywordSegment'
pub static STARTS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STARTS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StateKeywordSegment'
pub static STATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StatementKeywordSegment'
pub static STATEMENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STATEMENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StatementSegment'
pub static STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// StatementSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MergeStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MERGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InsertStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropTableStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropViewStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateUserStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropUserStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TruncateStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRUNCATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AccessStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GRANT".to_string(), "REVOKE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateTableStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateRoleStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropRoleStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AlterTableStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropSchemaStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropTypeStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateDatabaseStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropDatabaseStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateIndexStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropIndexStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateViewStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DeleteStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UpdateStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateCastStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropCastStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateFunctionStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropFunctionStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DescribeStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DESCRIBE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UseStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExplainStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXPLAIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateSequenceStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AlterSequenceStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropSequenceStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateTriggerStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DropTriggerStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DROP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AlterDatabaseStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MsckRepairTableStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MSCK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "MsckTableStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MSCK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SetStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AlterViewStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CreateTableAsSelectStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CREATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ComputeStatsStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMPUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "InsertStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["INSERT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "DelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([";".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "ALTER".to_string(), "COMPUTE".to_string(), "CREATE".to_string(), "DELETE".to_string(), "DESCRIBE".to_string(), "DROP".to_string(), "EXPLAIN".to_string(), "GRANT".to_string(), "INSERT".to_string(), "MERGE".to_string(), "MSCK".to_string(), "REVOKE".to_string(), "SELECT".to_string(), "SET".to_string(), "TRUNCATE".to_string(), "UPDATE".to_string(), "USE".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='StaticKeywordSegment'
pub static STATIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STATIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StatisticsKeywordSegment'
pub static STATISTICS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STATISTICS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StatsKeywordSegment'
pub static STATS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STATS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Stddev_popKeywordSegment'
pub static STDDEV_POP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STDDEV_POP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Stddev_sampKeywordSegment'
pub static STDDEV_SAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STDDEV_SAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StdinKeywordSegment'
pub static STDIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STDIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StdoutKeywordSegment'
pub static STDOUT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STDOUT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StorageFormatGrammar'
pub static STORAGE_FORMAT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RowFormatClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StoredAsGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string(), "STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StoredByGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string(), "STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='StorageKeywordSegment'
pub static STORAGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STORAGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Storagehandler_uriKeywordSegment'
pub static STORAGEHANDLER_URI_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STORAGEHANDLER_URI",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StoredAsGrammar'
pub static STORED_AS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StoredKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FileFormatGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AVRO".to_string(), "INPUTFORMAT".to_string(), "JSONFILE".to_string(), "ORC".to_string(), "PARQUET".to_string(), "RCFILE".to_string(), "SEQUENCEFILE".to_string(), "TEXTFILE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='StoredByGrammar'
pub static STORED_BY_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StoredKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SerdePropertiesGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STORED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='StoredKeywordSegment'
pub static STORED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STORED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Straight_joinKeywordSegment'
pub static STRAIGHT_JOIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STRAIGHT_JOIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StreamKeywordSegment'
pub static STREAM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STREAM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StreamsKeywordSegment'
pub static STREAMS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STREAMS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StreamtableKeywordSegment'
pub static STREAMTABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STREAMTABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StrictKeywordSegment'
pub static STRICT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STRICT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StringBinaryOperatorGrammar'
pub static STRING_BINARY_OPERATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ConcatSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["|".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='StringKeywordSegment'
pub static STRING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STRING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StructKeywordSegment'
pub static STRUCT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STRUCT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StructLiteralSegment'
pub static STRUCT_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// StructLiteralSegment
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BaseExpressionElementGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AliasExpressionSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='StructTypeSchemaSegment'
pub static STRUCT_TYPE_SCHEMA_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// StructTypeSchemaSegment
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ColonSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([":".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatatypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string(), "BIGINT".to_string(), "BINARY".to_string(), "BOOLEAN".to_string(), "CHAR".to_string(), "DATE".to_string(), "DEC".to_string(), "DECIMAL".to_string(), "DOUBLE".to_string(), "FLOAT".to_string(), "INT".to_string(), "INTEGER".to_string(), "JSON".to_string(), "MAP".to_string(), "NUMERIC".to_string(), "SMALLINT".to_string(), "STRING".to_string(), "STRUCT".to_string(), "TIMESTAMP".to_string(), "TINYINT".to_string(), "UNIONTYPE".to_string(), "VARCHAR".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommentGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "<",
    token_type: "start_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ">",
    token_type: "end_angle_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='StructTypeSegment'
pub static STRUCT_TYPE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// StructTypeSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StructKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StructTypeSchemaSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["<".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='StructureKeywordSegment'
pub static STRUCTURE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STRUCTURE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='StyleKeywordSegment'
pub static STYLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "STYLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Subclass_originKeywordSegment'
pub static SUBCLASS_ORIGIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUBCLASS_ORIGIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SublistKeywordSegment'
pub static SUBLIST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUBLIST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SubmultisetKeywordSegment'
pub static SUBMULTISET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUBMULTISET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SubsetKeywordSegment'
pub static SUBSET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUBSET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SubstringKeywordSegment'
pub static SUBSTRING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUBSTRING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Substring_regexKeywordSegment'
pub static SUBSTRING_REGEX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUBSTRING_REGEX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SucceedsKeywordSegment'
pub static SUCCEEDS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUCCEEDS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SuccessfulKeywordSegment'
pub static SUCCESSFUL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUCCESSFUL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SumKeywordSegment'
pub static SUM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SummaryKeywordSegment'
pub static SUMMARY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUMMARY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SuperuserKeywordSegment'
pub static SUPERUSER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SUPERUSER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SymbolKeywordSegment'
pub static SYMBOL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYMBOL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SymbolSegment'
pub static SYMBOL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "symbol",
//    token_type: "SymbolSegment",
})
);

// name='SymmetricKeywordSegment'
pub static SYMMETRIC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYMMETRIC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SyncKeywordSegment'
pub static SYNC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYNC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SynonymKeywordSegment'
pub static SYNONYM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYNONYM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SysdateKeywordSegment'
pub static SYSDATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYSDATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SysidKeywordSegment'
pub static SYSID_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYSID",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='SystemKeywordSegment'
pub static SYSTEM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYSTEM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='System_timeKeywordSegment'
pub static SYSTEM_TIME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYSTEM_TIME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='System_userKeywordSegment'
pub static SYSTEM_USER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYSTEM_USER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='System_versionKeywordSegment'
pub static SYSTEM_VERSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "SYSTEM_VERSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TableConstraintSegment'
pub static TABLE_CONSTRAINT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TableConstraintSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ConstraintKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRAINT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRAINT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UniqueKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PrimaryKeyGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIMARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DisableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NovalidateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOVALIDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RelyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RELY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NorelyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NORELY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NORELY".to_string(), "RELY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PRIMARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ForeignKeyGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedColumnReferenceListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ReferenceDefinitionGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["REFERENCES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DisableKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NovalidateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NOVALIDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FOREIGN".to_string(), "PRIMARY".to_string(), "UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CONSTRAINT".to_string(), "FOREIGN".to_string(), "PRIMARY".to_string(), "UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TableEndClauseSegment'
pub static TABLE_END_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TableEndClauseSegment
Arc::new(Grammar::Nothing())
);

// name='TableExpressionSegment'
pub static TABLE_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TableExpressionSegment
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ValuesClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BareFunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CURRENT_DATE".to_string(), "CURRENT_TIME".to_string(), "CURRENT_TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FunctionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string(), "WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "MergeStatementSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["MERGE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='TableKeywordSegment'
pub static TABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TablePropertiesGrammar'
pub static TABLE_PROPERTIES_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TblpropertiesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TBLPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedPropertyListGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TBLPROPERTIES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TableReferenceSegment'
pub static TABLE_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TableReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Table_nameKeywordSegment'
pub static TABLE_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TABLE_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TablesKeywordSegment'
pub static TABLES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TABLES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TablesampleKeywordSegment'
pub static TABLESAMPLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TABLESAMPLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TablespaceKeywordSegment'
pub static TABLESPACE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TABLESPACE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TablespaceReferenceSegment'
pub static TABLESPACE_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TablespaceReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='TagReferenceSegment'
pub static TAG_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TagReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Tail_Recurse_Expression_A_Grammar'
pub static TAIL_RECURSE_EXPRESSION_A_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Expression_A_Unary_Operator_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "NOT".to_string(), "PRIOR".to_string(), "~".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "BinaryOperatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["!".to_string(), "%".to_string(), "&".to_string(), "*".to_string(), "+".to_string(), "-".to_string(), "/".to_string(), "<".to_string(), "=".to_string(), ">".to_string(), "AND".to_string(), "DIV".to_string(), "IS".to_string(), "OR".to_string(), "^".to_string(), "|".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["like_operator".to_string()]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "NOT".to_string(), "PRIOR".to_string(), "~".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Expression_C_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Tail_Recurse_Expression_B_Grammar'
pub static TAIL_RECURSE_EXPRESSION_B_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "Expression_B_Unary_Operator_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "~".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "~".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "Expression_C_Grammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='TaskKeywordSegment'
pub static TASK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TASK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TasksKeywordSegment'
pub static TASKS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TASKS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TblpropertiesKeywordSegment'
pub static TBLPROPERTIES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TBLPROPERTIES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TempKeywordSegment'
pub static TEMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TEMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TemplateKeywordSegment'
pub static TEMPLATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TEMPLATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TemporalQuerySegment'
pub static TEMPORAL_QUERY_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TemporalQuerySegment
Arc::new(Grammar::Nothing())
);

// name='TemporaryGrammar'
pub static TEMPORARY_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TempKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TemporaryKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMPORARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMP".to_string(), "TEMPORARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TemporaryKeywordSegment'
pub static TEMPORARY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TEMPORARY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TemporaryTransientGrammar'
pub static TEMPORARY_TRANSIENT_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TransientKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRANSIENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TemporaryGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMP".to_string(), "TEMPORARY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TEMP".to_string(), "TEMPORARY".to_string(), "TRANSIENT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TerminateKeywordSegment'
pub static TERMINATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TERMINATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TerminatedByGrammar'
pub static TERMINATED_BY_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TerminatedKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TERMINATED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QuotedLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "single_quote".to_string()]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TERMINATED".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TerminatedKeywordSegment'
pub static TERMINATED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TERMINATED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TextKeywordSegment'
pub static TEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TextfileKeywordSegment'
pub static TEXTFILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TEXTFILE",
    token_type: "file_format",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TextsizeKeywordSegment'
pub static TEXTSIZE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TEXTSIZE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ThanKeywordSegment'
pub static THAN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "THAN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ThenKeywordSegment'
pub static THEN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "THEN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TiesKeywordSegment'
pub static TIES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TIES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TildeSegment'
pub static TILDE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "~",
    token_type: "tilde",
    raw_class: "SymbolSegment",
    optional: false,
})
);

// name='TimeKeywordSegment'
pub static TIME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TIME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TimeWithTZGrammar'
pub static TIME_WITH_T_Z_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TimeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIME".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TimestampKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIME".to_string(), "TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BracketedArguments",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithoutKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITHOUT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string(), "WITHOUT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TimeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIME".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ZoneKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ZONE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string(), "WITHOUT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIME".to_string(), "TIMESTAMP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TimeZoneGrammar'
pub static TIME_ZONE_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
// TimeZoneGrammar
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AtKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TimeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TIME".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ZoneKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ZONE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TimestampKeywordSegment'
pub static TIMESTAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TIMESTAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TimestamptzKeywordSegment'
pub static TIMESTAMPTZ_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TIMESTAMPTZ",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Timezone_hourKeywordSegment'
pub static TIMEZONE_HOUR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TIMEZONE_HOUR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Timezone_minuteKeywordSegment'
pub static TIMEZONE_MINUTE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TIMEZONE_MINUTE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TinyblobKeywordSegment'
pub static TINYBLOB_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TINYBLOB",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TinyintKeywordSegment'
pub static TINYINT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TINYINT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TinytextKeywordSegment'
pub static TINYTEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TINYTEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ToKeywordSegment'
pub static TO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ToastKeywordSegment'
pub static TOAST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TOAST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TopKeywordSegment'
pub static TOP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TOP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Top_level_countKeywordSegment'
pub static TOP_LEVEL_COUNT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TOP_LEVEL_COUNT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TouchKeywordSegment'
pub static TOUCH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TOUCH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TrailingKeywordSegment'
pub static TRAILING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRAILING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TranKeywordSegment'
pub static TRAN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRAN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TransactionKeywordSegment'
pub static TRANSACTION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSACTION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TransactionStatementSegment'
pub static TRANSACTION_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TransactionStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StartKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["START".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BeginKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BEGIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "CommitKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["COMMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RollbackKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROLLBACK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "EndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["END".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BEGIN".to_string(), "COMMIT".to_string(), "END".to_string(), "ROLLBACK".to_string(), "START".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TransactionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRANSACTION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WorkKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WORK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRANSACTION".to_string(), "WORK".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NameKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NAME".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NAME".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "AndKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NoKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ChainKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CHAIN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["AND".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BEGIN".to_string(), "COMMIT".to_string(), "END".to_string(), "ROLLBACK".to_string(), "START".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Transaction_activeKeywordSegment'
pub static TRANSACTION_ACTIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSACTION_ACTIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TransactionsKeywordSegment'
pub static TRANSACTIONS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSACTIONS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Transactions_committedKeywordSegment'
pub static TRANSACTIONS_COMMITTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSACTIONS_COMMITTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Transactions_rolled_backKeywordSegment'
pub static TRANSACTIONS_ROLLED_BACK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSACTIONS_ROLLED_BACK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TransformKeywordSegment'
pub static TRANSFORM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSFORM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TransformsKeywordSegment'
pub static TRANSFORMS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSFORMS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TransientKeywordSegment'
pub static TRANSIENT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSIENT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TranslateKeywordSegment'
pub static TRANSLATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSLATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Translate_regexKeywordSegment'
pub static TRANSLATE_REGEX_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSLATE_REGEX",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TranslationKeywordSegment'
pub static TRANSLATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRANSLATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TreatKeywordSegment'
pub static TREAT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TREAT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TriggerKeywordSegment'
pub static TRIGGER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRIGGER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TriggerReferenceSegment'
pub static TRIGGER_REFERENCE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TriggerReferenceSegment
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "ObjectReferenceTerminatorGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    reset_terminators: false,
    allow_gaps: false,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='Trigger_catalogKeywordSegment'
pub static TRIGGER_CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRIGGER_CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Trigger_nameKeywordSegment'
pub static TRIGGER_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRIGGER_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Trigger_schemaKeywordSegment'
pub static TRIGGER_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRIGGER_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TrimKeywordSegment'
pub static TRIM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRIM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TrimParametersGrammar'
pub static TRIM_PARAMETERS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='Trim_arrayKeywordSegment'
pub static TRIM_ARRAY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRIM_ARRAY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TrueKeywordSegment'
pub static TRUE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRUE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TrueSegment'
pub static TRUE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRUE",
    token_type: "boolean_literal",
    raw_class: "LiteralKeywordSegment",
    optional: false,
})
);

// name='TruncateKeywordSegment'
pub static TRUNCATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRUNCATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TruncateStatementSegment'
pub static TRUNCATE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TruncateStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "TruncateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRUNCATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TABLE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "PartitionSpecGrammar",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["TRUNCATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TrustedKeywordSegment'
pub static TRUSTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TRUSTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TsequalKeywordSegment'
pub static TSEQUAL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TSEQUAL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TupleSegment'
pub static TUPLE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TupleSegment
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "BaseExpressionElementGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TypeKeywordSegment'
pub static TYPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "TYPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='TypedArrayLiteralSegment'
pub static TYPED_ARRAY_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TypedArrayLiteralSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ArrayTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ArrayLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["[".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ARRAY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='TypedStructLiteralSegment'
pub static TYPED_STRUCT_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// TypedStructLiteralSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StructTypeSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "StructLiteralSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["STRUCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='UescapeKeywordSegment'
pub static UESCAPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UESCAPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UidKeywordSegment'
pub static UID_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UID",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnarchiveKeywordSegment'
pub static UNARCHIVE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNARCHIVE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnboundedKeywordSegment'
pub static UNBOUNDED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNBOUNDED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UncachedKeywordSegment'
pub static UNCACHED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNCACHED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UncommittedKeywordSegment'
pub static UNCOMMITTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNCOMMITTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnconditionalCrossJoinKeywordsGrammar'
pub static UNCONDITIONAL_CROSS_JOIN_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='UnconditionalJoinKeywordsGrammar'
pub static UNCONDITIONAL_JOIN_KEYWORDS_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NaturalJoinKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NATURAL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "UnconditionalCrossJoinKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "HorizontalJoinKeywordsGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='UnderKeywordSegment'
pub static UNDER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNDER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UndoKeywordSegment'
pub static UNDO_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNDO",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnencryptedKeywordSegment'
pub static UNENCRYPTED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNENCRYPTED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnionGrammar'
pub static UNION_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UnionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DistinctKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTINCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "AllKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ALL".to_string(), "DISTINCT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='UnionKeywordSegment'
pub static UNION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UniontypeKeywordSegment'
pub static UNIONTYPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNIONTYPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UniqueKeyGrammar'
pub static UNIQUE_KEY_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UniqueKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UNIQUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='UniqueKeywordSegment'
pub static UNIQUE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNIQUE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UniquejoinKeywordSegment'
pub static UNIQUEJOIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNIQUEJOIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnknownKeywordSegment'
pub static UNKNOWN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNKNOWN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnknownLiteralSegment'
pub static UNKNOWN_LITERAL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Nothing())
);

// name='UnlistenKeywordSegment'
pub static UNLISTEN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNLISTEN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnlockKeywordSegment'
pub static UNLOCK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNLOCK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnnamedKeywordSegment'
pub static UNNAMED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNNAMED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnnestKeywordSegment'
pub static UNNEST_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNNEST",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnorderedSelectStatementSegment'
pub static UNORDERED_SELECT_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// UnorderedSelectStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SelectClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WhereClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "GroupByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "HavingClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OverlapsClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERLAPS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NamedWindowSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "SetOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithNoSchemaBindingClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WithDataClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrderByClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LimitClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ClusterByClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DistributeByClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SortByClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::GreedyOnceStarted,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='UnorderedSetExpressionSegment'
pub static UNORDERED_SET_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// UnorderedSetExpressionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NonSetSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SetOperatorSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NonSetSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    min_times: 1,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["EXCEPT".to_string(), "INTERSECT".to_string(), "MINUS".to_string(), "UNION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='UnsetKeywordSegment'
pub static UNSET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNSET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UnsignedKeywordSegment'
pub static UNSIGNED_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNSIGNED",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UntilKeywordSegment'
pub static UNTIL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UNTIL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UpdateKeywordSegment'
pub static UPDATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UPDATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UpdateStatementSegment'
pub static UPDATE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// UpdateStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UpdateKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "TableReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "AliasExpressionSegment",
    optional: true,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::Ref {
    name: "SetKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
Arc::new(Grammar::Ref {
    name: "SetClauseListSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SET".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FromClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FROM".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WhereClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Update_fnKeywordSegment'
pub static UPDATE_FN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UPDATE_FN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UpdatetextKeywordSegment'
pub static UPDATETEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UPDATETEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UpperKeywordSegment'
pub static UPPER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UPPER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UpsertKeywordSegment'
pub static UPSERT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UPSERT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UriKeywordSegment'
pub static URI_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "URI",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UsageKeywordSegment'
pub static USAGE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USAGE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UseKeywordSegment'
pub static USE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UseStatementSegment'
pub static USE_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// UseStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "UseKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DatabaseReferenceSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["USE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='Use_any_roleKeywordSegment'
pub static USE_ANY_ROLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USE_ANY_ROLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UserKeywordSegment'
pub static USER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='User_defined_fnKeywordSegment'
pub static USER_DEFINED_FN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USER_DEFINED_FN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='User_defined_type_catalogKeywordSegment'
pub static USER_DEFINED_TYPE_CATALOG_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USER_DEFINED_TYPE_CATALOG",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='User_defined_type_codeKeywordSegment'
pub static USER_DEFINED_TYPE_CODE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USER_DEFINED_TYPE_CODE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='User_defined_type_nameKeywordSegment'
pub static USER_DEFINED_TYPE_NAME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USER_DEFINED_TYPE_NAME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='User_defined_type_schemaKeywordSegment'
pub static USER_DEFINED_TYPE_SCHEMA_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USER_DEFINED_TYPE_SCHEMA",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UsersKeywordSegment'
pub static USERS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USERS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UsingKeywordSegment'
pub static USING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "USING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UtcKeywordSegment'
pub static UTC_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UTC",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Utc_dateKeywordSegment'
pub static UTC_DATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UTC_DATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Utc_timeKeywordSegment'
pub static UTC_TIME_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UTC_TIME",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Utc_timestampKeywordSegment'
pub static UTC_TIMESTAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UTC_TIMESTAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Utc_tmestampKeywordSegment'
pub static UTC_TMESTAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UTC_TMESTAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='UtctimestampKeywordSegment'
pub static UTCTIMESTAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "UTCTIMESTAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VacuumKeywordSegment'
pub static VACUUM_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VACUUM",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ValidKeywordSegment'
pub static VALID_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VALID",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ValidateKeywordSegment'
pub static VALIDATE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VALIDATE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ValidatorKeywordSegment'
pub static VALIDATOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VALIDATOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ValueKeywordSegment'
pub static VALUE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VALUE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Value_ofKeywordSegment'
pub static VALUE_OF_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VALUE_OF",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Value_typeKeywordSegment'
pub static VALUE_TYPE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VALUE_TYPE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ValuesClauseSegment'
pub static VALUES_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// ValuesClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ValueKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ValuesKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "RowKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DefaultKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DEFAULT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "LiteralGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["+".to_string(), "-".to_string(), "ARRAY".to_string(), "DATE".to_string(), "FALSE".to_string(), "INTERVAL".to_string(), "NULL".to_string(), "TIME".to_string(), "TIMESTAMP".to_string(), "TRUE".to_string(), "[".to_string(), "{".to_string()]),
            token_types: hashbrown::HashSet::from_iter(["back_quote".to_string(), "double_quote".to_string(), "numeric_literal".to_string(), "single_quote".to_string()]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Greedy,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: false,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "ROW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='ValuesKeywordSegment'
pub static VALUES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VALUES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Var_popKeywordSegment'
pub static VAR_POP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VAR_POP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Var_sampKeywordSegment'
pub static VAR_SAMP_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VAR_SAMP",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VarbinaryKeywordSegment'
pub static VARBINARY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VARBINARY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Varchar2KeywordSegment'
pub static VARCHAR2_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VARCHAR2",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VarcharKeywordSegment'
pub static VARCHAR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VARCHAR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VarcharacterKeywordSegment'
pub static VARCHARACTER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VARCHARACTER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VariableKeywordSegment'
pub static VARIABLE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VARIABLE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VariablesKeywordSegment'
pub static VARIABLES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VARIABLES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VaryingKeywordSegment'
pub static VARYING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VARYING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VectorizationKeywordSegment'
pub static VECTORIZATION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VECTORIZATION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VerboseKeywordSegment'
pub static VERBOSE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VERBOSE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VersionKeywordSegment'
pub static VERSION_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VERSION",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VersioningKeywordSegment'
pub static VERSIONING_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VERSIONING",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ViewKeywordSegment'
pub static VIEW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VIEW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ViewsKeywordSegment'
pub static VIEWS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VIEWS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='VolatileKeywordSegment'
pub static VOLATILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "VOLATILE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WaitforKeywordSegment'
pub static WAITFOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WAITFOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WarehouseKeywordSegment'
pub static WAREHOUSE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WAREHOUSE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WarehousesKeywordSegment'
pub static WAREHOUSES_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WAREHOUSES",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WeekKeywordSegment'
pub static WEEK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WEEK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WeekdayKeywordSegment'
pub static WEEKDAY_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WEEKDAY",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WeeksKeywordSegment'
pub static WEEKS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WEEKS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WhenClauseSegment'
pub static WHEN_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WhenClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Ref {
    name: "ThenKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["THEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Meta("conditional"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHEN".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='WhenKeywordSegment'
pub static WHEN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WHEN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WheneverKeywordSegment'
pub static WHENEVER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WHENEVER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WhereClauseSegment'
pub static WHERE_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WhereClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WhereKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("indent"))
,
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Bracketed {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    bracket_pairs: (
        Box::new(
Arc::new(Grammar::StringParser {
    template: "(",
    token_type: "start_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        ),
        Box::new(
Arc::new(Grammar::StringParser {
    template: ")",
    token_type: "end_bracket",
    raw_class: "SymbolSegment",
    optional: false,
})
        )
    ),
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ExpressionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("dedent"))
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WHERE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='WhereClauseTerminatorGrammar'
pub static WHERE_CLAUSE_TERMINATOR_GRAMMAR: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "LimitClauseSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["LIMIT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "GroupKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["GROUP".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "ClusterKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "DistributeKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DISTRIBUTE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SortKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SORT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "ByKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "HavingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["HAVING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "QualifyKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["QUALIFY".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "WindowKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OverlapsKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["OVERLAPS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FetchKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["FETCH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["CLUSTER".to_string(), "DISTRIBUTE".to_string(), "FETCH".to_string(), "GROUP".to_string(), "HAVING".to_string(), "LIMIT".to_string(), "ORDER".to_string(), "OVERLAPS".to_string(), "QUALIFY".to_string(), "SORT".to_string(), "WINDOW".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='WhereKeywordSegment'
pub static WHERE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WHERE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WhileKeywordSegment'
pub static WHILE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WHILE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WhitespaceSegment'
pub static WHITESPACE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "whitespace",
//    token_type: "WhitespaceSegment",
})
);

// name='Width_bucketKeywordSegment'
pub static WIDTH_BUCKET_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WIDTH_BUCKET",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WildcardExpressionSegment'
pub static WILDCARD_EXPRESSION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WildcardExpressionSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WildcardIdentifierSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='WildcardIdentifierSegment'
pub static WILDCARD_IDENTIFIER_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WildcardIdentifierSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::AnyNumberOf {
    elements: vec![
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "ObjectReferenceDelimiterGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "StarSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["*".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DotSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([".".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["*".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
    ],
    min_times: 0,
    max_times: None,
    max_times_per_element: None,
    exclude: None,
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "StarSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["*".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: false,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='WindowKeywordSegment'
pub static WINDOW_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WINDOW",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WindowSpecificationSegment'
pub static WINDOW_SPECIFICATION_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WindowSpecificationSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "SingleIdentifierGrammar",
    optional: true,
    allow_gaps: true,
    exclude: Some(Box::new(
Arc::new(Grammar::OneOf {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "PartitionKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrderKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    exclude: None,
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string(), "PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    )),
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
Arc::new(Grammar::Ref {
    name: "PartitionClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["PARTITION".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "OrderByClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["ORDER".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "FrameClauseSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RANGE".to_string(), "ROWS".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
);

// name='WithCompoundNonSelectStatementSegment'
pub static WITH_COMPOUND_NON_SELECT_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WithCompoundNonSelectStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RecursiveKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RECURSIVE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CTEDefinitionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: true,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "SelectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Ref {
    name: "NonWithNonSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DELETE".to_string(), "INSERT".to_string(), "MERGE".to_string(), "UPDATE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='WithCompoundStatementSegment'
pub static WITH_COMPOUND_STATEMENT_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WithCompoundStatementSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "RecursiveKeywordSegment",
    optional: true,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["RECURSIVE".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Delimited {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "CTEDefinitionSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: None,
})
,
    ],
    delimiter: Box::new(
Arc::new(Grammar::Ref {
    name: "CommaSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter([",".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
    ),
    allow_trailing: true,
    optional: false,
    optional_delimiter: false,
    terminators: vec![
Arc::new(Grammar::Ref {
    name: "SelectKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SELECT".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    reset_terminators: false,
    allow_gaps: true,
    min_delimiters: 0,
    parse_mode: ParseMode::Strict,
    simple_hint: None,
})
,
Arc::new(Grammar::Meta("conditional"))
,
Arc::new(Grammar::Ref {
    name: "NonWithSelectableGrammar",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["(".to_string(), "SELECT".to_string(), "VALUE".to_string(), "VALUES".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='WithDataClauseSegment'
pub static WITH_DATA_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WithDataClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "NoKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: true,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "DataKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["DATA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='WithFillSegment'
pub static WITH_FILL_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WithFillSegment
Arc::new(Grammar::Nothing())
);

// name='WithKeywordSegment'
pub static WITH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WITH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WithNoSchemaBindingClauseSegment'
pub static WITH_NO_SCHEMA_BINDING_CLAUSE_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
// WithNoSchemaBindingClauseSegment
Arc::new(Grammar::Sequence {
    elements: vec![
Arc::new(Grammar::Ref {
    name: "WithKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "NoKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["NO".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "SchemaKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["SCHEMA".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
Arc::new(Grammar::Ref {
    name: "BindingKeywordSegment",
    optional: false,
    allow_gaps: true,
    exclude: None,
    terminators: vec![
    ],
    reset_terminators: false,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["BINDING".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
,
    ],
    optional: false,
    terminators: vec![
    ],
    reset_terminators: false,
    allow_gaps: true,
    parse_mode: ParseMode::Strict,
    simple_hint: Some(SimpleHint {
            raw_values: hashbrown::HashSet::from_iter(["WITH".to_string()]),
            token_types: hashbrown::HashSet::from_iter([]),
        }),
})
);

// name='WithinKeywordSegment'
pub static WITHIN_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WITHIN",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WithoutKeywordSegment'
pub static WITHOUT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WITHOUT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WordSegment'
pub static WORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::Token{
    token_type: "word",
//    token_type: "WordSegment",
})
);

// name='WorkKeywordSegment'
pub static WORK_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WORK",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WrapperKeywordSegment'
pub static WRAPPER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WRAPPER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WriteKeywordSegment'
pub static WRITE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WRITE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='WritetextKeywordSegment'
pub static WRITETEXT_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "WRITETEXT",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='X509KeywordSegment'
pub static X509_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "X509",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='XmlKeywordSegment'
pub static XML_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "XML",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='XorKeywordSegment'
pub static XOR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "XOR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='YamlKeywordSegment'
pub static YAML_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "YAML",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='YearKeywordSegment'
pub static YEAR_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "YEAR",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='Year_monthKeywordSegment'
pub static YEAR_MONTH_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "YEAR_MONTH",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='YearsKeywordSegment'
pub static YEARS_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "YEARS",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ZerofillKeywordSegment'
pub static ZEROFILL_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ZEROFILL",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ZoneKeywordSegment'
pub static ZONE_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ZONE",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

// name='ZorderKeywordSegment'
pub static ZORDER_KEYWORD_SEGMENT: Lazy<Arc<Grammar>> = Lazy::new(||
Arc::new(Grammar::StringParser {
    template: "ZORDER",
    token_type: "keyword",
    raw_class: "KeywordSegment",
    optional: false,
})
);

pub fn get_impala_segment_grammar(name: &str) -> Option<Arc<Grammar>> {
    match name {
            "AbortKeywordSegment" => Some(ABORT_KEYWORD_SEGMENT.clone()),
            "AbsKeywordSegment" => Some(ABS_KEYWORD_SEGMENT.clone()),
            "AbsoluteKeywordSegment" => Some(ABSOLUTE_KEYWORD_SEGMENT.clone()),
            "AccessKeywordSegment" => Some(ACCESS_KEYWORD_SEGMENT.clone()),
            "AccessStatementSegment" => Some(ACCESS_STATEMENT_SEGMENT.clone()),
            "AccessorGrammar" => Some(ACCESSOR_GRAMMAR.clone()),
            "AccountKeywordSegment" => Some(ACCOUNT_KEYWORD_SEGMENT.clone()),
            "AccountsKeywordSegment" => Some(ACCOUNTS_KEYWORD_SEGMENT.clone()),
            "ActionKeywordSegment" => Some(ACTION_KEYWORD_SEGMENT.clone()),
            "AdaKeywordSegment" => Some(ADA_KEYWORD_SEGMENT.clone()),
            "AddKeywordSegment" => Some(ADD_KEYWORD_SEGMENT.clone()),
            "AdminKeywordSegment" => Some(ADMIN_KEYWORD_SEGMENT.clone()),
            "AfterKeywordSegment" => Some(AFTER_KEYWORD_SEGMENT.clone()),
            "AggregateKeywordSegment" => Some(AGGREGATE_KEYWORD_SEGMENT.clone()),
            "AggregateOrderByClause" => Some(AGGREGATE_ORDER_BY_CLAUSE.clone()),
            "AliasExpressionSegment" => Some(ALIAS_EXPRESSION_SEGMENT.clone()),
            "AliasKeywordSegment" => Some(ALIAS_KEYWORD_SEGMENT.clone()),
            "AliasedTableReferenceGrammar" => Some(ALIASED_TABLE_REFERENCE_GRAMMAR.clone()),
            "AllKeywordSegment" => Some(ALL_KEYWORD_SEGMENT.clone()),
            "AllocateKeywordSegment" => Some(ALLOCATE_KEYWORD_SEGMENT.clone()),
            "AlsoKeywordSegment" => Some(ALSO_KEYWORD_SEGMENT.clone()),
            "AlterDatabaseStatementSegment" => Some(ALTER_DATABASE_STATEMENT_SEGMENT.clone()),
            "AlterKeywordSegment" => Some(ALTER_KEYWORD_SEGMENT.clone()),
            "AlterSequenceOptionsSegment" => Some(ALTER_SEQUENCE_OPTIONS_SEGMENT.clone()),
            "AlterSequenceStatementSegment" => Some(ALTER_SEQUENCE_STATEMENT_SEGMENT.clone()),
            "AlterTableDropColumnGrammar" => Some(ALTER_TABLE_DROP_COLUMN_GRAMMAR.clone()),
            "AlterTableOptionsGrammar" => Some(ALTER_TABLE_OPTIONS_GRAMMAR.clone()),
            "AlterTableStatementSegment" => Some(ALTER_TABLE_STATEMENT_SEGMENT.clone()),
            "AlterViewStatementSegment" => Some(ALTER_VIEW_STATEMENT_SEGMENT.clone()),
            "AlwaysKeywordSegment" => Some(ALWAYS_KEYWORD_SEGMENT.clone()),
            "AmpersandSegment" => Some(AMPERSAND_SEGMENT.clone()),
            "AnalyseKeywordSegment" => Some(ANALYSE_KEYWORD_SEGMENT.clone()),
            "AnalyticKeywordSegment" => Some(ANALYTIC_KEYWORD_SEGMENT.clone()),
            "AnalyzeKeywordSegment" => Some(ANALYZE_KEYWORD_SEGMENT.clone()),
            "AndKeywordSegment" => Some(AND_KEYWORD_SEGMENT.clone()),
            "AndOperatorGrammar" => Some(AND_OPERATOR_GRAMMAR.clone()),
            "AntiKeywordSegment" => Some(ANTI_KEYWORD_SEGMENT.clone()),
            "AnyKeywordSegment" => Some(ANY_KEYWORD_SEGMENT.clone()),
            "Api_versionKeywordSegment" => Some(API_VERSION_KEYWORD_SEGMENT.clone()),
            "ApplyKeywordSegment" => Some(APPLY_KEYWORD_SEGMENT.clone()),
            "ArchiveKeywordSegment" => Some(ARCHIVE_KEYWORD_SEGMENT.clone()),
            "AreKeywordSegment" => Some(ARE_KEYWORD_SEGMENT.clone()),
            "ArithmeticBinaryOperatorGrammar" => Some(ARITHMETIC_BINARY_OPERATOR_GRAMMAR.clone()),
            "ArrayAccessorSegment" => Some(ARRAY_ACCESSOR_SEGMENT.clone()),
            "ArrayExpressionSegment" => Some(ARRAY_EXPRESSION_SEGMENT.clone()),
            "ArrayKeywordSegment" => Some(ARRAY_KEYWORD_SEGMENT.clone()),
            "ArrayLiteralSegment" => Some(ARRAY_LITERAL_SEGMENT.clone()),
            "ArrayTypeSegment" => Some(ARRAY_TYPE_SEGMENT.clone()),
            "Array_aggKeywordSegment" => Some(ARRAY_AGG_KEYWORD_SEGMENT.clone()),
            "Array_max_cardinalityKeywordSegment" => Some(ARRAY_MAX_CARDINALITY_KEYWORD_SEGMENT.clone()),
            "AsAliasOperatorSegment" => Some(AS_ALIAS_OPERATOR_SEGMENT.clone()),
            "AsKeywordSegment" => Some(AS_KEYWORD_SEGMENT.clone()),
            "AscKeywordSegment" => Some(ASC_KEYWORD_SEGMENT.clone()),
            "AsensitiveKeywordSegment" => Some(ASENSITIVE_KEYWORD_SEGMENT.clone()),
            "AssertionKeywordSegment" => Some(ASSERTION_KEYWORD_SEGMENT.clone()),
            "AssignmentKeywordSegment" => Some(ASSIGNMENT_KEYWORD_SEGMENT.clone()),
            "AsymmetricKeywordSegment" => Some(ASYMMETRIC_KEYWORD_SEGMENT.clone()),
            "AtKeywordSegment" => Some(AT_KEYWORD_SEGMENT.clone()),
            "AtomicKeywordSegment" => Some(ATOMIC_KEYWORD_SEGMENT.clone()),
            "AttributeKeywordSegment" => Some(ATTRIBUTE_KEYWORD_SEGMENT.clone()),
            "AttributesKeywordSegment" => Some(ATTRIBUTES_KEYWORD_SEGMENT.clone()),
            "AuditKeywordSegment" => Some(AUDIT_KEYWORD_SEGMENT.clone()),
            "AuthorizationKeywordSegment" => Some(AUTHORIZATION_KEYWORD_SEGMENT.clone()),
            "AutoIncrementGrammar" => Some(AUTO_INCREMENT_GRAMMAR.clone()),
            "Auto_incrementKeywordSegment" => Some(AUTO_INCREMENT_KEYWORD_SEGMENT.clone()),
            "AutocommitKeywordSegment" => Some(AUTOCOMMIT_KEYWORD_SEGMENT.clone()),
            "AvgKeywordSegment" => Some(AVG_KEYWORD_SEGMENT.clone()),
            "Avg_row_lengthKeywordSegment" => Some(AVG_ROW_LENGTH_KEYWORD_SEGMENT.clone()),
            "AvroKeywordSegment" => Some(AVRO_KEYWORD_SEGMENT.clone()),
            "BackQuotedIdentifierSegment" => Some(BACK_QUOTED_IDENTIFIER_SEGMENT.clone()),
            "BackupKeywordSegment" => Some(BACKUP_KEYWORD_SEGMENT.clone()),
            "BackwardKeywordSegment" => Some(BACKWARD_KEYWORD_SEGMENT.clone()),
            "BareFunctionSegment" => Some(BARE_FUNCTION_SEGMENT.clone()),
            "BaseExpressionElementGrammar" => Some(BASE_EXPRESSION_ELEMENT_GRAMMAR.clone()),
            "BaseFileSegment" => Some(BASE_FILE_SEGMENT.clone()),
            "BaseSegment" => Some(BASE_SEGMENT.clone()),
            "BeforeKeywordSegment" => Some(BEFORE_KEYWORD_SEGMENT.clone()),
            "BeginKeywordSegment" => Some(BEGIN_KEYWORD_SEGMENT.clone()),
            "Begin_frameKeywordSegment" => Some(BEGIN_FRAME_KEYWORD_SEGMENT.clone()),
            "Begin_partitionKeywordSegment" => Some(BEGIN_PARTITION_KEYWORD_SEGMENT.clone()),
            "BernoulliKeywordSegment" => Some(BERNOULLI_KEYWORD_SEGMENT.clone()),
            "BetweenKeywordSegment" => Some(BETWEEN_KEYWORD_SEGMENT.clone()),
            "BigintKeywordSegment" => Some(BIGINT_KEYWORD_SEGMENT.clone()),
            "BinaryKeywordSegment" => Some(BINARY_KEYWORD_SEGMENT.clone()),
            "BinaryOperatorGrammar" => Some(BINARY_OPERATOR_GRAMMAR.clone()),
            "BinaryOperatorSegment" => Some(BINARY_OPERATOR_SEGMENT.clone()),
            "BindingKeywordSegment" => Some(BINDING_KEYWORD_SEGMENT.clone()),
            "BitKeywordSegment" => Some(BIT_KEYWORD_SEGMENT.clone()),
            "Bit_lengthKeywordSegment" => Some(BIT_LENGTH_KEYWORD_SEGMENT.clone()),
            "BitvarKeywordSegment" => Some(BITVAR_KEYWORD_SEGMENT.clone()),
            "BitwiseAndSegment" => Some(BITWISE_AND_SEGMENT.clone()),
            "BitwiseLShiftSegment" => Some(BITWISE_L_SHIFT_SEGMENT.clone()),
            "BitwiseOrSegment" => Some(BITWISE_OR_SEGMENT.clone()),
            "BitwiseRShiftSegment" => Some(BITWISE_R_SHIFT_SEGMENT.clone()),
            "BitwiseXorSegment" => Some(BITWISE_XOR_SEGMENT.clone()),
            "BlobKeywordSegment" => Some(BLOB_KEYWORD_SEGMENT.clone()),
            "Block_sizeKeywordSegment" => Some(BLOCK_SIZE_KEYWORD_SEGMENT.clone()),
            "BoolKeywordSegment" => Some(BOOL_KEYWORD_SEGMENT.clone()),
            "BooleanBinaryOperatorGrammar" => Some(BOOLEAN_BINARY_OPERATOR_GRAMMAR.clone()),
            "BooleanKeywordSegment" => Some(BOOLEAN_KEYWORD_SEGMENT.clone()),
            "BooleanLiteralGrammar" => Some(BOOLEAN_LITERAL_GRAMMAR.clone()),
            "BothKeywordSegment" => Some(BOTH_KEYWORD_SEGMENT.clone()),
            "BracketedArguments" => Some(BRACKETED_ARGUMENTS.clone()),
            "BracketedColumnReferenceListGrammar" => Some(BRACKETED_COLUMN_REFERENCE_LIST_GRAMMAR.clone()),
            "BracketedPropertyListGrammar" => Some(BRACKETED_PROPERTY_LIST_GRAMMAR.clone()),
            "BracketedSegment" => Some(BRACKETED_SEGMENT.clone()),
            "BracketedSetExpressionGrammar" => Some(BRACKETED_SET_EXPRESSION_GRAMMAR.clone()),
            "BreadthKeywordSegment" => Some(BREADTH_KEYWORD_SEGMENT.clone()),
            "BreakKeywordSegment" => Some(BREAK_KEYWORD_SEGMENT.clone()),
            "BrowseKeywordSegment" => Some(BROWSE_KEYWORD_SEGMENT.clone()),
            "BucketKeywordSegment" => Some(BUCKET_KEYWORD_SEGMENT.clone()),
            "BucketsKeywordSegment" => Some(BUCKETS_KEYWORD_SEGMENT.clone()),
            "BulkKeywordSegment" => Some(BULK_KEYWORD_SEGMENT.clone()),
            "ByKeywordSegment" => Some(BY_KEYWORD_SEGMENT.clone()),
            "CTEColumnList" => Some(C_T_E_COLUMN_LIST.clone()),
            "CTEDefinitionSegment" => Some(C_T_E_DEFINITION_SEGMENT.clone()),
            "CacheKeywordSegment" => Some(CACHE_KEYWORD_SEGMENT.clone()),
            "CachedKeywordSegment" => Some(CACHED_KEYWORD_SEGMENT.clone()),
            "CallKeywordSegment" => Some(CALL_KEYWORD_SEGMENT.clone()),
            "CalledKeywordSegment" => Some(CALLED_KEYWORD_SEGMENT.clone()),
            "CardinalityKeywordSegment" => Some(CARDINALITY_KEYWORD_SEGMENT.clone()),
            "CascadeKeywordSegment" => Some(CASCADE_KEYWORD_SEGMENT.clone()),
            "CascadedKeywordSegment" => Some(CASCADED_KEYWORD_SEGMENT.clone()),
            "CaseExpressionSegment" => Some(CASE_EXPRESSION_SEGMENT.clone()),
            "CaseKeywordSegment" => Some(CASE_KEYWORD_SEGMENT.clone()),
            "CastKeywordSegment" => Some(CAST_KEYWORD_SEGMENT.clone()),
            "CastOperatorSegment" => Some(CAST_OPERATOR_SEGMENT.clone()),
            "CatalogKeywordSegment" => Some(CATALOG_KEYWORD_SEGMENT.clone()),
            "Catalog_nameKeywordSegment" => Some(CATALOG_NAME_KEYWORD_SEGMENT.clone()),
            "CeilKeywordSegment" => Some(CEIL_KEYWORD_SEGMENT.clone()),
            "CeilingKeywordSegment" => Some(CEILING_KEYWORD_SEGMENT.clone()),
            "ChainKeywordSegment" => Some(CHAIN_KEYWORD_SEGMENT.clone()),
            "ChangeKeywordSegment" => Some(CHANGE_KEYWORD_SEGMENT.clone()),
            "CharCharacterSetGrammar" => Some(CHAR_CHARACTER_SET_GRAMMAR.clone()),
            "CharKeywordSegment" => Some(CHAR_KEYWORD_SEGMENT.clone()),
            "Char_lengthKeywordSegment" => Some(CHAR_LENGTH_KEYWORD_SEGMENT.clone()),
            "CharacterKeywordSegment" => Some(CHARACTER_KEYWORD_SEGMENT.clone()),
            "Character_lengthKeywordSegment" => Some(CHARACTER_LENGTH_KEYWORD_SEGMENT.clone()),
            "Character_set_catalogKeywordSegment" => Some(CHARACTER_SET_CATALOG_KEYWORD_SEGMENT.clone()),
            "Character_set_nameKeywordSegment" => Some(CHARACTER_SET_NAME_KEYWORD_SEGMENT.clone()),
            "Character_set_schemaKeywordSegment" => Some(CHARACTER_SET_SCHEMA_KEYWORD_SEGMENT.clone()),
            "CharacteristicsKeywordSegment" => Some(CHARACTERISTICS_KEYWORD_SEGMENT.clone()),
            "CharactersKeywordSegment" => Some(CHARACTERS_KEYWORD_SEGMENT.clone()),
            "CheckKeywordSegment" => Some(CHECK_KEYWORD_SEGMENT.clone()),
            "CheckedKeywordSegment" => Some(CHECKED_KEYWORD_SEGMENT.clone()),
            "CheckpointKeywordSegment" => Some(CHECKPOINT_KEYWORD_SEGMENT.clone()),
            "ChecksumKeywordSegment" => Some(CHECKSUM_KEYWORD_SEGMENT.clone()),
            "ClassKeywordSegment" => Some(CLASS_KEYWORD_SEGMENT.clone()),
            "Class_originKeywordSegment" => Some(CLASS_ORIGIN_KEYWORD_SEGMENT.clone()),
            "ClobKeywordSegment" => Some(CLOB_KEYWORD_SEGMENT.clone()),
            "CloseKeywordSegment" => Some(CLOSE_KEYWORD_SEGMENT.clone()),
            "Close_fnKeywordSegment" => Some(CLOSE_FN_KEYWORD_SEGMENT.clone()),
            "ClusterByClauseSegment" => Some(CLUSTER_BY_CLAUSE_SEGMENT.clone()),
            "ClusterKeywordSegment" => Some(CLUSTER_KEYWORD_SEGMENT.clone()),
            "ClusteredKeywordSegment" => Some(CLUSTERED_KEYWORD_SEGMENT.clone()),
            "ClusterstatusKeywordSegment" => Some(CLUSTERSTATUS_KEYWORD_SEGMENT.clone()),
            "CoalesceKeywordSegment" => Some(COALESCE_KEYWORD_SEGMENT.clone()),
            "CobolKeywordSegment" => Some(COBOL_KEYWORD_SEGMENT.clone()),
            "CodeSegment" => Some(CODE_SEGMENT.clone()),
            "CollateGrammar" => Some(COLLATE_GRAMMAR.clone()),
            "CollateKeywordSegment" => Some(COLLATE_KEYWORD_SEGMENT.clone()),
            "CollationKeywordSegment" => Some(COLLATION_KEYWORD_SEGMENT.clone()),
            "CollationReferenceSegment" => Some(COLLATION_REFERENCE_SEGMENT.clone()),
            "Collation_catalogKeywordSegment" => Some(COLLATION_CATALOG_KEYWORD_SEGMENT.clone()),
            "Collation_nameKeywordSegment" => Some(COLLATION_NAME_KEYWORD_SEGMENT.clone()),
            "Collation_schemaKeywordSegment" => Some(COLLATION_SCHEMA_KEYWORD_SEGMENT.clone()),
            "CollectKeywordSegment" => Some(COLLECT_KEYWORD_SEGMENT.clone()),
            "CollectionKeywordSegment" => Some(COLLECTION_KEYWORD_SEGMENT.clone()),
            "ColonDelimiterSegment" => Some(COLON_DELIMITER_SEGMENT.clone()),
            "ColonPrefixSegment" => Some(COLON_PREFIX_SEGMENT.clone()),
            "ColonSegment" => Some(COLON_SEGMENT.clone()),
            "ColumnConstraintDefaultGrammar" => Some(COLUMN_CONSTRAINT_DEFAULT_GRAMMAR.clone()),
            "ColumnConstraintSegment" => Some(COLUMN_CONSTRAINT_SEGMENT.clone()),
            "ColumnDefinitionSegment" => Some(COLUMN_DEFINITION_SEGMENT.clone()),
            "ColumnGeneratedGrammar" => Some(COLUMN_GENERATED_GRAMMAR.clone()),
            "ColumnKeywordSegment" => Some(COLUMN_KEYWORD_SEGMENT.clone()),
            "ColumnReferenceSegment" => Some(COLUMN_REFERENCE_SEGMENT.clone()),
            "Column_nameKeywordSegment" => Some(COLUMN_NAME_KEYWORD_SEGMENT.clone()),
            "ColumnsExpressionFunctionContentsSegment" => Some(COLUMNS_EXPRESSION_FUNCTION_CONTENTS_SEGMENT.clone()),
            "ColumnsExpressionFunctionNameSegment" => Some(COLUMNS_EXPRESSION_FUNCTION_NAME_SEGMENT.clone()),
            "ColumnsExpressionGrammar" => Some(COLUMNS_EXPRESSION_GRAMMAR.clone()),
            "ColumnsExpressionNameGrammar" => Some(COLUMNS_EXPRESSION_NAME_GRAMMAR.clone()),
            "ColumnsKeywordSegment" => Some(COLUMNS_KEYWORD_SEGMENT.clone()),
            "CommaSegment" => Some(COMMA_SEGMENT.clone()),
            "Command_functionKeywordSegment" => Some(COMMAND_FUNCTION_KEYWORD_SEGMENT.clone()),
            "Command_function_codeKeywordSegment" => Some(COMMAND_FUNCTION_CODE_KEYWORD_SEGMENT.clone()),
            "CommentClauseSegment" => Some(COMMENT_CLAUSE_SEGMENT.clone()),
            "CommentGrammar" => Some(COMMENT_GRAMMAR.clone()),
            "CommentKeywordSegment" => Some(COMMENT_KEYWORD_SEGMENT.clone()),
            "CommentSegment" => Some(COMMENT_SEGMENT.clone()),
            "CommitKeywordSegment" => Some(COMMIT_KEYWORD_SEGMENT.clone()),
            "CommittedKeywordSegment" => Some(COMMITTED_KEYWORD_SEGMENT.clone()),
            "CompactKeywordSegment" => Some(COMPACT_KEYWORD_SEGMENT.clone()),
            "CompactionsKeywordSegment" => Some(COMPACTIONS_KEYWORD_SEGMENT.clone()),
            "ComparisonOperatorGrammar" => Some(COMPARISON_OPERATOR_GRAMMAR.clone()),
            "ComparisonOperatorSegment" => Some(COMPARISON_OPERATOR_SEGMENT.clone()),
            "CompletionKeywordSegment" => Some(COMPLETION_KEYWORD_SEGMENT.clone()),
            "CompositeBinaryOperatorSegment" => Some(COMPOSITE_BINARY_OPERATOR_SEGMENT.clone()),
            "CompositeComparisonOperatorSegment" => Some(COMPOSITE_COMPARISON_OPERATOR_SEGMENT.clone()),
            "CompressKeywordSegment" => Some(COMPRESS_KEYWORD_SEGMENT.clone()),
            "CompressionKeywordSegment" => Some(COMPRESSION_KEYWORD_SEGMENT.clone()),
            "ComputeKeywordSegment" => Some(COMPUTE_KEYWORD_SEGMENT.clone()),
            "ComputeStatsStatementSegment" => Some(COMPUTE_STATS_STATEMENT_SEGMENT.clone()),
            "ConcatSegment" => Some(CONCAT_SEGMENT.clone()),
            "ConcatenateKeywordSegment" => Some(CONCATENATE_KEYWORD_SEGMENT.clone()),
            "ConditionKeywordSegment" => Some(CONDITION_KEYWORD_SEGMENT.clone()),
            "Condition_numberKeywordSegment" => Some(CONDITION_NUMBER_KEYWORD_SEGMENT.clone()),
            "ConditionalCrossJoinKeywordsGrammar" => Some(CONDITIONAL_CROSS_JOIN_KEYWORDS_GRAMMAR.clone()),
            "ConditionalJoinKeywordsGrammar" => Some(CONDITIONAL_JOIN_KEYWORDS_GRAMMAR.clone()),
            "ConfKeywordSegment" => Some(CONF_KEYWORD_SEGMENT.clone()),
            "ConnectKeywordSegment" => Some(CONNECT_KEYWORD_SEGMENT.clone()),
            "ConnectionKeywordSegment" => Some(CONNECTION_KEYWORD_SEGMENT.clone()),
            "Connection_nameKeywordSegment" => Some(CONNECTION_NAME_KEYWORD_SEGMENT.clone()),
            "ConstraintKeywordSegment" => Some(CONSTRAINT_KEYWORD_SEGMENT.clone()),
            "Constraint_catalogKeywordSegment" => Some(CONSTRAINT_CATALOG_KEYWORD_SEGMENT.clone()),
            "Constraint_nameKeywordSegment" => Some(CONSTRAINT_NAME_KEYWORD_SEGMENT.clone()),
            "Constraint_schemaKeywordSegment" => Some(CONSTRAINT_SCHEMA_KEYWORD_SEGMENT.clone()),
            "ConstraintsKeywordSegment" => Some(CONSTRAINTS_KEYWORD_SEGMENT.clone()),
            "ConstructorKeywordSegment" => Some(CONSTRUCTOR_KEYWORD_SEGMENT.clone()),
            "ContainsKeywordSegment" => Some(CONTAINS_KEYWORD_SEGMENT.clone()),
            "ContainstableKeywordSegment" => Some(CONTAINSTABLE_KEYWORD_SEGMENT.clone()),
            "ContinueKeywordSegment" => Some(CONTINUE_KEYWORD_SEGMENT.clone()),
            "ConversionKeywordSegment" => Some(CONVERSION_KEYWORD_SEGMENT.clone()),
            "ConvertKeywordSegment" => Some(CONVERT_KEYWORD_SEGMENT.clone()),
            "CopyKeywordSegment" => Some(COPY_KEYWORD_SEGMENT.clone()),
            "CorrKeywordSegment" => Some(CORR_KEYWORD_SEGMENT.clone()),
            "CorrespondingKeywordSegment" => Some(CORRESPONDING_KEYWORD_SEGMENT.clone()),
            "CountKeywordSegment" => Some(COUNT_KEYWORD_SEGMENT.clone()),
            "Covar_popKeywordSegment" => Some(COVAR_POP_KEYWORD_SEGMENT.clone()),
            "Covar_sampKeywordSegment" => Some(COVAR_SAMP_KEYWORD_SEGMENT.clone()),
            "CreateCastStatementSegment" => Some(CREATE_CAST_STATEMENT_SEGMENT.clone()),
            "CreateDatabaseStatementSegment" => Some(CREATE_DATABASE_STATEMENT_SEGMENT.clone()),
            "CreateFunctionStatementSegment" => Some(CREATE_FUNCTION_STATEMENT_SEGMENT.clone()),
            "CreateIndexStatementSegment" => Some(CREATE_INDEX_STATEMENT_SEGMENT.clone()),
            "CreateKeywordSegment" => Some(CREATE_KEYWORD_SEGMENT.clone()),
            "CreateModelStatementSegment" => Some(CREATE_MODEL_STATEMENT_SEGMENT.clone()),
            "CreateRoleStatementSegment" => Some(CREATE_ROLE_STATEMENT_SEGMENT.clone()),
            "CreateSchemaStatementSegment" => Some(CREATE_SCHEMA_STATEMENT_SEGMENT.clone()),
            "CreateSequenceOptionsSegment" => Some(CREATE_SEQUENCE_OPTIONS_SEGMENT.clone()),
            "CreateSequenceStatementSegment" => Some(CREATE_SEQUENCE_STATEMENT_SEGMENT.clone()),
            "CreateTableAsSelectStatementSegment" => Some(CREATE_TABLE_AS_SELECT_STATEMENT_SEGMENT.clone()),
            "CreateTableStatementSegment" => Some(CREATE_TABLE_STATEMENT_SEGMENT.clone()),
            "CreateTriggerStatementSegment" => Some(CREATE_TRIGGER_STATEMENT_SEGMENT.clone()),
            "CreateUserStatementSegment" => Some(CREATE_USER_STATEMENT_SEGMENT.clone()),
            "CreateViewStatementSegment" => Some(CREATE_VIEW_STATEMENT_SEGMENT.clone()),
            "CreatedbKeywordSegment" => Some(CREATEDB_KEYWORD_SEGMENT.clone()),
            "CreateroleKeywordSegment" => Some(CREATEROLE_KEYWORD_SEGMENT.clone()),
            "CreateuserKeywordSegment" => Some(CREATEUSER_KEYWORD_SEGMENT.clone()),
            "CrossKeywordSegment" => Some(CROSS_KEYWORD_SEGMENT.clone()),
            "CsvKeywordSegment" => Some(CSV_KEYWORD_SEGMENT.clone()),
            "CubeFunctionNameSegment" => Some(CUBE_FUNCTION_NAME_SEGMENT.clone()),
            "CubeKeywordSegment" => Some(CUBE_KEYWORD_SEGMENT.clone()),
            "CubeRollupClauseSegment" => Some(CUBE_ROLLUP_CLAUSE_SEGMENT.clone()),
            "Cume_distKeywordSegment" => Some(CUME_DIST_KEYWORD_SEGMENT.clone()),
            "CurrentKeywordSegment" => Some(CURRENT_KEYWORD_SEGMENT.clone()),
            "Current_dateKeywordSegment" => Some(CURRENT_DATE_KEYWORD_SEGMENT.clone()),
            "Current_default_transform_groupKeywordSegment" => Some(CURRENT_DEFAULT_TRANSFORM_GROUP_KEYWORD_SEGMENT.clone()),
            "Current_pathKeywordSegment" => Some(CURRENT_PATH_KEYWORD_SEGMENT.clone()),
            "Current_roleKeywordSegment" => Some(CURRENT_ROLE_KEYWORD_SEGMENT.clone()),
            "Current_rowKeywordSegment" => Some(CURRENT_ROW_KEYWORD_SEGMENT.clone()),
            "Current_schemaKeywordSegment" => Some(CURRENT_SCHEMA_KEYWORD_SEGMENT.clone()),
            "Current_timeKeywordSegment" => Some(CURRENT_TIME_KEYWORD_SEGMENT.clone()),
            "Current_timestampKeywordSegment" => Some(CURRENT_TIMESTAMP_KEYWORD_SEGMENT.clone()),
            "Current_transform_group_for_typeKeywordSegment" => Some(CURRENT_TRANSFORM_GROUP_FOR_TYPE_KEYWORD_SEGMENT.clone()),
            "Current_userKeywordSegment" => Some(CURRENT_USER_KEYWORD_SEGMENT.clone()),
            "CursorKeywordSegment" => Some(CURSOR_KEYWORD_SEGMENT.clone()),
            "Cursor_nameKeywordSegment" => Some(CURSOR_NAME_KEYWORD_SEGMENT.clone()),
            "CycleKeywordSegment" => Some(CYCLE_KEYWORD_SEGMENT.clone()),
            "DataKeywordSegment" => Some(DATA_KEYWORD_SEGMENT.clone()),
            "DatabaseKeywordSegment" => Some(DATABASE_KEYWORD_SEGMENT.clone()),
            "DatabaseReferenceSegment" => Some(DATABASE_REFERENCE_SEGMENT.clone()),
            "DatabasesKeywordSegment" => Some(DATABASES_KEYWORD_SEGMENT.clone()),
            "DatatypeIdentifierSegment" => Some(DATATYPE_IDENTIFIER_SEGMENT.clone()),
            "DatatypeSegment" => Some(DATATYPE_SEGMENT.clone()),
            "DateKeywordSegment" => Some(DATE_KEYWORD_SEGMENT.clone()),
            "DatePartFunctionName" => Some(DATE_PART_FUNCTION_NAME.clone()),
            "DatePartFunctionNameSegment" => Some(DATE_PART_FUNCTION_NAME_SEGMENT.clone()),
            "DateTimeFunctionContentsSegment" => Some(DATE_TIME_FUNCTION_CONTENTS_SEGMENT.clone()),
            "DateTimeLiteralGrammar" => Some(DATE_TIME_LITERAL_GRAMMAR.clone()),
            "DatetimeKeywordSegment" => Some(DATETIME_KEYWORD_SEGMENT.clone()),
            "DatetimeUnitSegment" => Some(DATETIME_UNIT_SEGMENT.clone()),
            "Datetime_interval_codeKeywordSegment" => Some(DATETIME_INTERVAL_CODE_KEYWORD_SEGMENT.clone()),
            "Datetime_interval_precisionKeywordSegment" => Some(DATETIME_INTERVAL_PRECISION_KEYWORD_SEGMENT.clone()),
            "DayKeywordSegment" => Some(DAY_KEYWORD_SEGMENT.clone()),
            "Day_hourKeywordSegment" => Some(DAY_HOUR_KEYWORD_SEGMENT.clone()),
            "Day_microsecondKeywordSegment" => Some(DAY_MICROSECOND_KEYWORD_SEGMENT.clone()),
            "Day_minuteKeywordSegment" => Some(DAY_MINUTE_KEYWORD_SEGMENT.clone()),
            "Day_secondKeywordSegment" => Some(DAY_SECOND_KEYWORD_SEGMENT.clone()),
            "DayofmonthKeywordSegment" => Some(DAYOFMONTH_KEYWORD_SEGMENT.clone()),
            "DayofweekKeywordSegment" => Some(DAYOFWEEK_KEYWORD_SEGMENT.clone()),
            "DayofyearKeywordSegment" => Some(DAYOFYEAR_KEYWORD_SEGMENT.clone()),
            "DaysKeywordSegment" => Some(DAYS_KEYWORD_SEGMENT.clone()),
            "DbccKeywordSegment" => Some(DBCC_KEYWORD_SEGMENT.clone()),
            "DbpropertiesKeywordSegment" => Some(DBPROPERTIES_KEYWORD_SEGMENT.clone()),
            "DeallocateKeywordSegment" => Some(DEALLOCATE_KEYWORD_SEGMENT.clone()),
            "DecKeywordSegment" => Some(DEC_KEYWORD_SEGMENT.clone()),
            "DecfloatKeywordSegment" => Some(DECFLOAT_KEYWORD_SEGMENT.clone()),
            "DecimalKeywordSegment" => Some(DECIMAL_KEYWORD_SEGMENT.clone()),
            "DeclareKeywordSegment" => Some(DECLARE_KEYWORD_SEGMENT.clone()),
            "Dedent" => Some(DEDENT.clone()),
            "DefaultKeywordSegment" => Some(DEFAULT_KEYWORD_SEGMENT.clone()),
            "DefaultValuesGrammar" => Some(DEFAULT_VALUES_GRAMMAR.clone()),
            "DefaultsKeywordSegment" => Some(DEFAULTS_KEYWORD_SEGMENT.clone()),
            "DeferrableKeywordSegment" => Some(DEFERRABLE_KEYWORD_SEGMENT.clone()),
            "DeferredKeywordSegment" => Some(DEFERRED_KEYWORD_SEGMENT.clone()),
            "DefineKeywordSegment" => Some(DEFINE_KEYWORD_SEGMENT.clone()),
            "DefinedKeywordSegment" => Some(DEFINED_KEYWORD_SEGMENT.clone()),
            "DefinerKeywordSegment" => Some(DEFINER_KEYWORD_SEGMENT.clone()),
            "DegreeKeywordSegment" => Some(DEGREE_KEYWORD_SEGMENT.clone()),
            "Delay_key_writeKeywordSegment" => Some(DELAY_KEY_WRITE_KEYWORD_SEGMENT.clone()),
            "DelayedKeywordSegment" => Some(DELAYED_KEYWORD_SEGMENT.clone()),
            "DeleteKeywordSegment" => Some(DELETE_KEYWORD_SEGMENT.clone()),
            "DeleteStatementSegment" => Some(DELETE_STATEMENT_SEGMENT.clone()),
            "DelimitedKeywordSegment" => Some(DELIMITED_KEYWORD_SEGMENT.clone()),
            "DelimiterGrammar" => Some(DELIMITER_GRAMMAR.clone()),
            "DelimiterKeywordSegment" => Some(DELIMITER_KEYWORD_SEGMENT.clone()),
            "DelimitersKeywordSegment" => Some(DELIMITERS_KEYWORD_SEGMENT.clone()),
            "Dense_rankKeywordSegment" => Some(DENSE_RANK_KEYWORD_SEGMENT.clone()),
            "DenyKeywordSegment" => Some(DENY_KEYWORD_SEGMENT.clone()),
            "DependencyKeywordSegment" => Some(DEPENDENCY_KEYWORD_SEGMENT.clone()),
            "DepthKeywordSegment" => Some(DEPTH_KEYWORD_SEGMENT.clone()),
            "DerefKeywordSegment" => Some(DEREF_KEYWORD_SEGMENT.clone()),
            "DerivedKeywordSegment" => Some(DERIVED_KEYWORD_SEGMENT.clone()),
            "DescKeywordSegment" => Some(DESC_KEYWORD_SEGMENT.clone()),
            "DescribeKeywordSegment" => Some(DESCRIBE_KEYWORD_SEGMENT.clone()),
            "DescribeStatementSegment" => Some(DESCRIBE_STATEMENT_SEGMENT.clone()),
            "DescriptorKeywordSegment" => Some(DESCRIPTOR_KEYWORD_SEGMENT.clone()),
            "DestroyKeywordSegment" => Some(DESTROY_KEYWORD_SEGMENT.clone()),
            "DestructorKeywordSegment" => Some(DESTRUCTOR_KEYWORD_SEGMENT.clone()),
            "DetailKeywordSegment" => Some(DETAIL_KEYWORD_SEGMENT.clone()),
            "DeterministicKeywordSegment" => Some(DETERMINISTIC_KEYWORD_SEGMENT.clone()),
            "DiagnosticsKeywordSegment" => Some(DIAGNOSTICS_KEYWORD_SEGMENT.clone()),
            "DictionaryKeywordSegment" => Some(DICTIONARY_KEYWORD_SEGMENT.clone()),
            "DirectoriesKeywordSegment" => Some(DIRECTORIES_KEYWORD_SEGMENT.clone()),
            "DirectoryKeywordSegment" => Some(DIRECTORY_KEYWORD_SEGMENT.clone()),
            "DisableKeywordSegment" => Some(DISABLE_KEYWORD_SEGMENT.clone()),
            "DisconnectKeywordSegment" => Some(DISCONNECT_KEYWORD_SEGMENT.clone()),
            "DiskKeywordSegment" => Some(DISK_KEYWORD_SEGMENT.clone()),
            "DispatchKeywordSegment" => Some(DISPATCH_KEYWORD_SEGMENT.clone()),
            "DistinctKeywordSegment" => Some(DISTINCT_KEYWORD_SEGMENT.clone()),
            "DistinctrowKeywordSegment" => Some(DISTINCTROW_KEYWORD_SEGMENT.clone()),
            "DistributeByClauseSegment" => Some(DISTRIBUTE_BY_CLAUSE_SEGMENT.clone()),
            "DistributeKeywordSegment" => Some(DISTRIBUTE_KEYWORD_SEGMENT.clone()),
            "DistributedKeywordSegment" => Some(DISTRIBUTED_KEYWORD_SEGMENT.clone()),
            "DivKeywordSegment" => Some(DIV_KEYWORD_SEGMENT.clone()),
            "DivideSegment" => Some(DIVIDE_SEGMENT.clone()),
            "DoKeywordSegment" => Some(DO_KEYWORD_SEGMENT.clone()),
            "DomainKeywordSegment" => Some(DOMAIN_KEYWORD_SEGMENT.clone()),
            "DotSegment" => Some(DOT_SEGMENT.clone()),
            "DoubleKeywordSegment" => Some(DOUBLE_KEYWORD_SEGMENT.clone()),
            "DowKeywordSegment" => Some(DOW_KEYWORD_SEGMENT.clone()),
            "DropBehaviorGrammar" => Some(DROP_BEHAVIOR_GRAMMAR.clone()),
            "DropCastStatementSegment" => Some(DROP_CAST_STATEMENT_SEGMENT.clone()),
            "DropDatabaseStatementSegment" => Some(DROP_DATABASE_STATEMENT_SEGMENT.clone()),
            "DropFunctionStatementSegment" => Some(DROP_FUNCTION_STATEMENT_SEGMENT.clone()),
            "DropIndexStatementSegment" => Some(DROP_INDEX_STATEMENT_SEGMENT.clone()),
            "DropKeywordSegment" => Some(DROP_KEYWORD_SEGMENT.clone()),
            "DropModelStatementSegment" => Some(DROP_MODEL_STATEMENT_SEGMENT.clone()),
            "DropRoleStatementSegment" => Some(DROP_ROLE_STATEMENT_SEGMENT.clone()),
            "DropSchemaStatementSegment" => Some(DROP_SCHEMA_STATEMENT_SEGMENT.clone()),
            "DropSequenceStatementSegment" => Some(DROP_SEQUENCE_STATEMENT_SEGMENT.clone()),
            "DropTableStatementSegment" => Some(DROP_TABLE_STATEMENT_SEGMENT.clone()),
            "DropTriggerStatementSegment" => Some(DROP_TRIGGER_STATEMENT_SEGMENT.clone()),
            "DropTypeStatementSegment" => Some(DROP_TYPE_STATEMENT_SEGMENT.clone()),
            "DropUserStatementSegment" => Some(DROP_USER_STATEMENT_SEGMENT.clone()),
            "DropViewStatementSegment" => Some(DROP_VIEW_STATEMENT_SEGMENT.clone()),
            "DummyKeywordSegment" => Some(DUMMY_KEYWORD_SEGMENT.clone()),
            "DumpKeywordSegment" => Some(DUMP_KEYWORD_SEGMENT.clone()),
            "DynamicKeywordSegment" => Some(DYNAMIC_KEYWORD_SEGMENT.clone()),
            "Dynamic_functionKeywordSegment" => Some(DYNAMIC_FUNCTION_KEYWORD_SEGMENT.clone()),
            "Dynamic_function_codeKeywordSegment" => Some(DYNAMIC_FUNCTION_CODE_KEYWORD_SEGMENT.clone()),
            "EachKeywordSegment" => Some(EACH_KEYWORD_SEGMENT.clone()),
            "Elem_typeKeywordSegment" => Some(ELEM_TYPE_KEYWORD_SEGMENT.clone()),
            "ElementKeywordSegment" => Some(ELEMENT_KEYWORD_SEGMENT.clone()),
            "ElseClauseSegment" => Some(ELSE_CLAUSE_SEGMENT.clone()),
            "ElseKeywordSegment" => Some(ELSE_KEYWORD_SEGMENT.clone()),
            "ElseifKeywordSegment" => Some(ELSEIF_KEYWORD_SEGMENT.clone()),
            "EmptyKeywordSegment" => Some(EMPTY_KEYWORD_SEGMENT.clone()),
            "EmptyStructLiteralBracketsSegment" => Some(EMPTY_STRUCT_LITERAL_BRACKETS_SEGMENT.clone()),
            "EmptyStructLiteralSegment" => Some(EMPTY_STRUCT_LITERAL_SEGMENT.clone()),
            "EnableKeywordSegment" => Some(ENABLE_KEYWORD_SEGMENT.clone()),
            "EnclosedKeywordSegment" => Some(ENCLOSED_KEYWORD_SEGMENT.clone()),
            "EncodingKeywordSegment" => Some(ENCODING_KEYWORD_SEGMENT.clone()),
            "EncryptedKeywordSegment" => Some(ENCRYPTED_KEYWORD_SEGMENT.clone()),
            "End-execKeywordSegment" => Some(END_EXEC_KEYWORD_SEGMENT.clone()),
            "EndAngleBracketSegment" => Some(END_ANGLE_BRACKET_SEGMENT.clone()),
            "EndBracketSegment" => Some(END_BRACKET_SEGMENT.clone()),
            "EndCurlyBracketSegment" => Some(END_CURLY_BRACKET_SEGMENT.clone()),
            "EndKeywordSegment" => Some(END_KEYWORD_SEGMENT.clone()),
            "EndSquareBracketSegment" => Some(END_SQUARE_BRACKET_SEGMENT.clone()),
            "End_frameKeywordSegment" => Some(END_FRAME_KEYWORD_SEGMENT.clone()),
            "End_partitionKeywordSegment" => Some(END_PARTITION_KEYWORD_SEGMENT.clone()),
            "EnumKeywordSegment" => Some(ENUM_KEYWORD_SEGMENT.clone()),
            "EqualsKeywordSegment" => Some(EQUALS_KEYWORD_SEGMENT.clone()),
            "EqualsSegment" => Some(EQUALS_SEGMENT.clone()),
            "ErrlvlKeywordSegment" => Some(ERRLVL_KEYWORD_SEGMENT.clone()),
            "EscapeKeywordSegment" => Some(ESCAPE_KEYWORD_SEGMENT.clone()),
            "EscapedKeywordSegment" => Some(ESCAPED_KEYWORD_SEGMENT.clone()),
            "EveryKeywordSegment" => Some(EVERY_KEYWORD_SEGMENT.clone()),
            "ExceptKeywordSegment" => Some(EXCEPT_KEYWORD_SEGMENT.clone()),
            "ExceptionKeywordSegment" => Some(EXCEPTION_KEYWORD_SEGMENT.clone()),
            "ExchangeKeywordSegment" => Some(EXCHANGE_KEYWORD_SEGMENT.clone()),
            "ExcludeKeywordSegment" => Some(EXCLUDE_KEYWORD_SEGMENT.clone()),
            "ExcludingKeywordSegment" => Some(EXCLUDING_KEYWORD_SEGMENT.clone()),
            "ExclusiveKeywordSegment" => Some(EXCLUSIVE_KEYWORD_SEGMENT.clone()),
            "ExecKeywordSegment" => Some(EXEC_KEYWORD_SEGMENT.clone()),
            "ExecuteKeywordSegment" => Some(EXECUTE_KEYWORD_SEGMENT.clone()),
            "ExecutionKeywordSegment" => Some(EXECUTION_KEYWORD_SEGMENT.clone()),
            "ExistingKeywordSegment" => Some(EXISTING_KEYWORD_SEGMENT.clone()),
            "ExistsKeywordSegment" => Some(EXISTS_KEYWORD_SEGMENT.clone()),
            "ExitKeywordSegment" => Some(EXIT_KEYWORD_SEGMENT.clone()),
            "ExpKeywordSegment" => Some(EXP_KEYWORD_SEGMENT.clone()),
            "ExplainKeywordSegment" => Some(EXPLAIN_KEYWORD_SEGMENT.clone()),
            "ExplainStatementSegment" => Some(EXPLAIN_STATEMENT_SEGMENT.clone()),
            "ExportKeywordSegment" => Some(EXPORT_KEYWORD_SEGMENT.clone()),
            "ExpressionKeywordSegment" => Some(EXPRESSION_KEYWORD_SEGMENT.clone()),
            "ExpressionSegment" => Some(EXPRESSION_SEGMENT.clone()),
            "Expression_A_Grammar" => Some(EXPRESSION_A_GRAMMAR.clone()),
            "Expression_A_Unary_Operator_Grammar" => Some(EXPRESSION_A_UNARY_OPERATOR_GRAMMAR.clone()),
            "Expression_B_Grammar" => Some(EXPRESSION_B_GRAMMAR.clone()),
            "Expression_B_Unary_Operator_Grammar" => Some(EXPRESSION_B_UNARY_OPERATOR_GRAMMAR.clone()),
            "Expression_C_Grammar" => Some(EXPRESSION_C_GRAMMAR.clone()),
            "Expression_D_Grammar" => Some(EXPRESSION_D_GRAMMAR.clone()),
            "Expression_D_Potential_Select_Statement_Without_Brackets" => Some(EXPRESSION_D_POTENTIAL_SELECT_STATEMENT_WITHOUT_BRACKETS.clone()),
            "ExtendedKeywordSegment" => Some(EXTENDED_KEYWORD_SEGMENT.clone()),
            "ExtendedNaturalJoinKeywordsGrammar" => Some(EXTENDED_NATURAL_JOIN_KEYWORDS_GRAMMAR.clone()),
            "ExtensionKeywordSegment" => Some(EXTENSION_KEYWORD_SEGMENT.clone()),
            "ExtensionReferenceSegment" => Some(EXTENSION_REFERENCE_SEGMENT.clone()),
            "ExternalKeywordSegment" => Some(EXTERNAL_KEYWORD_SEGMENT.clone()),
            "ExtractKeywordSegment" => Some(EXTRACT_KEYWORD_SEGMENT.clone()),
            "FalseKeywordSegment" => Some(FALSE_KEYWORD_SEGMENT.clone()),
            "FalseSegment" => Some(FALSE_SEGMENT.clone()),
            "FetchClauseSegment" => Some(FETCH_CLAUSE_SEGMENT.clone()),
            "FetchKeywordSegment" => Some(FETCH_KEYWORD_SEGMENT.clone()),
            "FieldsKeywordSegment" => Some(FIELDS_KEYWORD_SEGMENT.clone()),
            "FileFormatGrammar" => Some(FILE_FORMAT_GRAMMAR.clone()),
            "FileKeywordSegment" => Some(FILE_KEYWORD_SEGMENT.clone()),
            "FileSegment" => Some(FILE_SEGMENT.clone()),
            "FileformatKeywordSegment" => Some(FILEFORMAT_KEYWORD_SEGMENT.clone()),
            "FilesKeywordSegment" => Some(FILES_KEYWORD_SEGMENT.clone()),
            "FillfactorKeywordSegment" => Some(FILLFACTOR_KEYWORD_SEGMENT.clone()),
            "FilterClauseGrammar" => Some(FILTER_CLAUSE_GRAMMAR.clone()),
            "FilterKeywordSegment" => Some(FILTER_KEYWORD_SEGMENT.clone()),
            "FinalKeywordSegment" => Some(FINAL_KEYWORD_SEGMENT.clone()),
            "Finalize_fnKeywordSegment" => Some(FINALIZE_FN_KEYWORD_SEGMENT.clone()),
            "FirstKeywordSegment" => Some(FIRST_KEYWORD_SEGMENT.clone()),
            "Float4KeywordSegment" => Some(FLOAT4_KEYWORD_SEGMENT.clone()),
            "Float8KeywordSegment" => Some(FLOAT8_KEYWORD_SEGMENT.clone()),
            "FloatKeywordSegment" => Some(FLOAT_KEYWORD_SEGMENT.clone()),
            "FloorKeywordSegment" => Some(FLOOR_KEYWORD_SEGMENT.clone()),
            "FlushKeywordSegment" => Some(FLUSH_KEYWORD_SEGMENT.clone()),
            "FollowingKeywordSegment" => Some(FOLLOWING_KEYWORD_SEGMENT.clone()),
            "ForKeywordSegment" => Some(FOR_KEYWORD_SEGMENT.clone()),
            "ForceKeywordSegment" => Some(FORCE_KEYWORD_SEGMENT.clone()),
            "ForeignKeyGrammar" => Some(FOREIGN_KEY_GRAMMAR.clone()),
            "ForeignKeywordSegment" => Some(FOREIGN_KEYWORD_SEGMENT.clone()),
            "FormatKeywordSegment" => Some(FORMAT_KEYWORD_SEGMENT.clone()),
            "FormattedKeywordSegment" => Some(FORMATTED_KEYWORD_SEGMENT.clone()),
            "FortranKeywordSegment" => Some(FORTRAN_KEYWORD_SEGMENT.clone()),
            "ForwardKeywordSegment" => Some(FORWARD_KEYWORD_SEGMENT.clone()),
            "FoundKeywordSegment" => Some(FOUND_KEYWORD_SEGMENT.clone()),
            "FrameClauseSegment" => Some(FRAME_CLAUSE_SEGMENT.clone()),
            "FrameClauseUnitGrammar" => Some(FRAME_CLAUSE_UNIT_GRAMMAR.clone()),
            "Frame_rowKeywordSegment" => Some(FRAME_ROW_KEYWORD_SEGMENT.clone()),
            "FreeKeywordSegment" => Some(FREE_KEYWORD_SEGMENT.clone()),
            "FreetextKeywordSegment" => Some(FREETEXT_KEYWORD_SEGMENT.clone()),
            "FreetexttableKeywordSegment" => Some(FREETEXTTABLE_KEYWORD_SEGMENT.clone()),
            "FreezeKeywordSegment" => Some(FREEZE_KEYWORD_SEGMENT.clone()),
            "FromClauseSegment" => Some(FROM_CLAUSE_SEGMENT.clone()),
            "FromClauseTerminatorGrammar" => Some(FROM_CLAUSE_TERMINATOR_GRAMMAR.clone()),
            "FromExpressionElementSegment" => Some(FROM_EXPRESSION_ELEMENT_SEGMENT.clone()),
            "FromExpressionSegment" => Some(FROM_EXPRESSION_SEGMENT.clone()),
            "FromKeywordSegment" => Some(FROM_KEYWORD_SEGMENT.clone()),
            "FullKeywordSegment" => Some(FULL_KEYWORD_SEGMENT.clone()),
            "FulltextKeywordSegment" => Some(FULLTEXT_KEYWORD_SEGMENT.clone()),
            "FunctionContentsExpressionGrammar" => Some(FUNCTION_CONTENTS_EXPRESSION_GRAMMAR.clone()),
            "FunctionContentsGrammar" => Some(FUNCTION_CONTENTS_GRAMMAR.clone()),
            "FunctionContentsSegment" => Some(FUNCTION_CONTENTS_SEGMENT.clone()),
            "FunctionDefinitionGrammar" => Some(FUNCTION_DEFINITION_GRAMMAR.clone()),
            "FunctionKeywordSegment" => Some(FUNCTION_KEYWORD_SEGMENT.clone()),
            "FunctionNameIdentifierSegment" => Some(FUNCTION_NAME_IDENTIFIER_SEGMENT.clone()),
            "FunctionNameSegment" => Some(FUNCTION_NAME_SEGMENT.clone()),
            "FunctionParameterGrammar" => Some(FUNCTION_PARAMETER_GRAMMAR.clone()),
            "FunctionParameterListGrammar" => Some(FUNCTION_PARAMETER_LIST_GRAMMAR.clone()),
            "FunctionSegment" => Some(FUNCTION_SEGMENT.clone()),
            "FunctionsKeywordSegment" => Some(FUNCTIONS_KEYWORD_SEGMENT.clone()),
            "FusionKeywordSegment" => Some(FUSION_KEYWORD_SEGMENT.clone()),
            "FutureKeywordSegment" => Some(FUTURE_KEYWORD_SEGMENT.clone()),
            "GKeywordSegment" => Some(G_KEYWORD_SEGMENT.clone()),
            "GeneralKeywordSegment" => Some(GENERAL_KEYWORD_SEGMENT.clone()),
            "GeneratedKeywordSegment" => Some(GENERATED_KEYWORD_SEGMENT.clone()),
            "GetKeywordSegment" => Some(GET_KEYWORD_SEGMENT.clone()),
            "GlobOperatorSegment" => Some(GLOB_OPERATOR_SEGMENT.clone()),
            "GlobalKeywordSegment" => Some(GLOBAL_KEYWORD_SEGMENT.clone()),
            "GoKeywordSegment" => Some(GO_KEYWORD_SEGMENT.clone()),
            "GotoKeywordSegment" => Some(GOTO_KEYWORD_SEGMENT.clone()),
            "GrantKeywordSegment" => Some(GRANT_KEYWORD_SEGMENT.clone()),
            "GrantedKeywordSegment" => Some(GRANTED_KEYWORD_SEGMENT.clone()),
            "GrantsKeywordSegment" => Some(GRANTS_KEYWORD_SEGMENT.clone()),
            "GreaterThanOrEqualToSegment" => Some(GREATER_THAN_OR_EQUAL_TO_SEGMENT.clone()),
            "GreaterThanSegment" => Some(GREATER_THAN_SEGMENT.clone()),
            "GreatestKeywordSegment" => Some(GREATEST_KEYWORD_SEGMENT.clone()),
            "GroupByClauseSegment" => Some(GROUP_BY_CLAUSE_SEGMENT.clone()),
            "GroupByClauseTerminatorGrammar" => Some(GROUP_BY_CLAUSE_TERMINATOR_GRAMMAR.clone()),
            "GroupKeywordSegment" => Some(GROUP_KEYWORD_SEGMENT.clone()),
            "GroupingExpressionList" => Some(GROUPING_EXPRESSION_LIST.clone()),
            "GroupingKeywordSegment" => Some(GROUPING_KEYWORD_SEGMENT.clone()),
            "GroupingSetsClauseSegment" => Some(GROUPING_SETS_CLAUSE_SEGMENT.clone()),
            "GroupsKeywordSegment" => Some(GROUPS_KEYWORD_SEGMENT.clone()),
            "HandlerKeywordSegment" => Some(HANDLER_KEYWORD_SEGMENT.clone()),
            "HashKeywordSegment" => Some(HASH_KEYWORD_SEGMENT.clone()),
            "HavingClauseSegment" => Some(HAVING_CLAUSE_SEGMENT.clone()),
            "HavingClauseTerminatorGrammar" => Some(HAVING_CLAUSE_TERMINATOR_GRAMMAR.clone()),
            "HavingKeywordSegment" => Some(HAVING_KEYWORD_SEGMENT.clone()),
            "HeaderKeywordSegment" => Some(HEADER_KEYWORD_SEGMENT.clone()),
            "HeapKeywordSegment" => Some(HEAP_KEYWORD_SEGMENT.clone()),
            "HierarchyKeywordSegment" => Some(HIERARCHY_KEYWORD_SEGMENT.clone()),
            "High_priorityKeywordSegment" => Some(HIGH_PRIORITY_KEYWORD_SEGMENT.clone()),
            "HoldKeywordSegment" => Some(HOLD_KEYWORD_SEGMENT.clone()),
            "Hold_ddltimeKeywordSegment" => Some(HOLD_DDLTIME_KEYWORD_SEGMENT.clone()),
            "HoldlockKeywordSegment" => Some(HOLDLOCK_KEYWORD_SEGMENT.clone()),
            "HorizontalJoinKeywordsGrammar" => Some(HORIZONTAL_JOIN_KEYWORDS_GRAMMAR.clone()),
            "HostKeywordSegment" => Some(HOST_KEYWORD_SEGMENT.clone()),
            "HostsKeywordSegment" => Some(HOSTS_KEYWORD_SEGMENT.clone()),
            "HourKeywordSegment" => Some(HOUR_KEYWORD_SEGMENT.clone()),
            "Hour_microsecondKeywordSegment" => Some(HOUR_MICROSECOND_KEYWORD_SEGMENT.clone()),
            "Hour_minuteKeywordSegment" => Some(HOUR_MINUTE_KEYWORD_SEGMENT.clone()),
            "Hour_secondKeywordSegment" => Some(HOUR_SECOND_KEYWORD_SEGMENT.clone()),
            "HoursKeywordSegment" => Some(HOURS_KEYWORD_SEGMENT.clone()),
            "HudiparquetKeywordSegment" => Some(HUDIPARQUET_KEYWORD_SEGMENT.clone()),
            "IcebergKeywordSegment" => Some(ICEBERG_KEYWORD_SEGMENT.clone()),
            "IdentifiedKeywordSegment" => Some(IDENTIFIED_KEYWORD_SEGMENT.clone()),
            "IdentifierSegment" => Some(IDENTIFIER_SEGMENT.clone()),
            "IdentityKeywordSegment" => Some(IDENTITY_KEYWORD_SEGMENT.clone()),
            "Identity_insertKeywordSegment" => Some(IDENTITY_INSERT_KEYWORD_SEGMENT.clone()),
            "IdentitycolKeywordSegment" => Some(IDENTITYCOL_KEYWORD_SEGMENT.clone()),
            "IdxpropertiesKeywordSegment" => Some(IDXPROPERTIES_KEYWORD_SEGMENT.clone()),
            "IfExistsGrammar" => Some(IF_EXISTS_GRAMMAR.clone()),
            "IfKeywordSegment" => Some(IF_KEYWORD_SEGMENT.clone()),
            "IfNotExistsGrammar" => Some(IF_NOT_EXISTS_GRAMMAR.clone()),
            "IgnoreKeywordSegment" => Some(IGNORE_KEYWORD_SEGMENT.clone()),
            "IgnoreRespectNullsGrammar" => Some(IGNORE_RESPECT_NULLS_GRAMMAR.clone()),
            "IlikeKeywordSegment" => Some(ILIKE_KEYWORD_SEGMENT.clone()),
            "ImmediateKeywordSegment" => Some(IMMEDIATE_KEYWORD_SEGMENT.clone()),
            "ImmutableKeywordSegment" => Some(IMMUTABLE_KEYWORD_SEGMENT.clone()),
            "ImplementationKeywordSegment" => Some(IMPLEMENTATION_KEYWORD_SEGMENT.clone()),
            "ImplicitIndent" => Some(IMPLICIT_INDENT.clone()),
            "ImplicitKeywordSegment" => Some(IMPLICIT_KEYWORD_SEGMENT.clone()),
            "ImportKeywordSegment" => Some(IMPORT_KEYWORD_SEGMENT.clone()),
            "ImportedKeywordSegment" => Some(IMPORTED_KEYWORD_SEGMENT.clone()),
            "InKeywordSegment" => Some(IN_KEYWORD_SEGMENT.clone()),
            "InOperatorGrammar" => Some(IN_OPERATOR_GRAMMAR.clone()),
            "IncludeKeywordSegment" => Some(INCLUDE_KEYWORD_SEGMENT.clone()),
            "IncludingKeywordSegment" => Some(INCLUDING_KEYWORD_SEGMENT.clone()),
            "IncrementKeywordSegment" => Some(INCREMENT_KEYWORD_SEGMENT.clone()),
            "IncrementalKeywordSegment" => Some(INCREMENTAL_KEYWORD_SEGMENT.clone()),
            "Indent" => Some(INDENT.clone()),
            "IndexColumnDefinitionSegment" => Some(INDEX_COLUMN_DEFINITION_SEGMENT.clone()),
            "IndexKeywordSegment" => Some(INDEX_KEYWORD_SEGMENT.clone()),
            "IndexReferenceSegment" => Some(INDEX_REFERENCE_SEGMENT.clone()),
            "IndexesKeywordSegment" => Some(INDEXES_KEYWORD_SEGMENT.clone()),
            "IndicatorKeywordSegment" => Some(INDICATOR_KEYWORD_SEGMENT.clone()),
            "InfileKeywordSegment" => Some(INFILE_KEYWORD_SEGMENT.clone()),
            "InfixKeywordSegment" => Some(INFIX_KEYWORD_SEGMENT.clone()),
            "InheritKeywordSegment" => Some(INHERIT_KEYWORD_SEGMENT.clone()),
            "InheritsKeywordSegment" => Some(INHERITS_KEYWORD_SEGMENT.clone()),
            "Init_fnKeywordSegment" => Some(INIT_FN_KEYWORD_SEGMENT.clone()),
            "InitialKeywordSegment" => Some(INITIAL_KEYWORD_SEGMENT.clone()),
            "InitializeKeywordSegment" => Some(INITIALIZE_KEYWORD_SEGMENT.clone()),
            "InitiallyKeywordSegment" => Some(INITIALLY_KEYWORD_SEGMENT.clone()),
            "InnerKeywordSegment" => Some(INNER_KEYWORD_SEGMENT.clone()),
            "InoutKeywordSegment" => Some(INOUT_KEYWORD_SEGMENT.clone()),
            "InpathKeywordSegment" => Some(INPATH_KEYWORD_SEGMENT.clone()),
            "InputKeywordSegment" => Some(INPUT_KEYWORD_SEGMENT.clone()),
            "InputdriverKeywordSegment" => Some(INPUTDRIVER_KEYWORD_SEGMENT.clone()),
            "InputformatKeywordSegment" => Some(INPUTFORMAT_KEYWORD_SEGMENT.clone()),
            "InsensitiveKeywordSegment" => Some(INSENSITIVE_KEYWORD_SEGMENT.clone()),
            "InsertKeywordSegment" => Some(INSERT_KEYWORD_SEGMENT.clone()),
            "InsertStatementSegment" => Some(INSERT_STATEMENT_SEGMENT.clone()),
            "Insert_idKeywordSegment" => Some(INSERT_ID_KEYWORD_SEGMENT.clone()),
            "InstanceKeywordSegment" => Some(INSTANCE_KEYWORD_SEGMENT.clone()),
            "InstantiableKeywordSegment" => Some(INSTANTIABLE_KEYWORD_SEGMENT.clone()),
            "InsteadKeywordSegment" => Some(INSTEAD_KEYWORD_SEGMENT.clone()),
            "Int1KeywordSegment" => Some(INT1_KEYWORD_SEGMENT.clone()),
            "Int2KeywordSegment" => Some(INT2_KEYWORD_SEGMENT.clone()),
            "Int3KeywordSegment" => Some(INT3_KEYWORD_SEGMENT.clone()),
            "Int4KeywordSegment" => Some(INT4_KEYWORD_SEGMENT.clone()),
            "Int8KeywordSegment" => Some(INT8_KEYWORD_SEGMENT.clone()),
            "IntKeywordSegment" => Some(INT_KEYWORD_SEGMENT.clone()),
            "IntegerKeywordSegment" => Some(INTEGER_KEYWORD_SEGMENT.clone()),
            "IntegrationKeywordSegment" => Some(INTEGRATION_KEYWORD_SEGMENT.clone()),
            "IntegrationsKeywordSegment" => Some(INTEGRATIONS_KEYWORD_SEGMENT.clone()),
            "IntermediateKeywordSegment" => Some(INTERMEDIATE_KEYWORD_SEGMENT.clone()),
            "IntersectKeywordSegment" => Some(INTERSECT_KEYWORD_SEGMENT.clone()),
            "IntersectionKeywordSegment" => Some(INTERSECTION_KEYWORD_SEGMENT.clone()),
            "IntervalExpressionSegment" => Some(INTERVAL_EXPRESSION_SEGMENT.clone()),
            "IntervalKeywordSegment" => Some(INTERVAL_KEYWORD_SEGMENT.clone()),
            "IntoKeywordSegment" => Some(INTO_KEYWORD_SEGMENT.clone()),
            "InvalidateKeywordSegment" => Some(INVALIDATE_KEYWORD_SEGMENT.clone()),
            "InvokerKeywordSegment" => Some(INVOKER_KEYWORD_SEGMENT.clone()),
            "IregexpKeywordSegment" => Some(IREGEXP_KEYWORD_SEGMENT.clone()),
            "IsClauseGrammar" => Some(IS_CLAUSE_GRAMMAR.clone()),
            "IsDistinctFromGrammar" => Some(IS_DISTINCT_FROM_GRAMMAR.clone()),
            "IsKeywordSegment" => Some(IS_KEYWORD_SEGMENT.clone()),
            "IsNullGrammar" => Some(IS_NULL_GRAMMAR.clone()),
            "IsamKeywordSegment" => Some(ISAM_KEYWORD_SEGMENT.clone()),
            "IsnullKeywordSegment" => Some(ISNULL_KEYWORD_SEGMENT.clone()),
            "IsolationKeywordSegment" => Some(ISOLATION_KEYWORD_SEGMENT.clone()),
            "ItemsKeywordSegment" => Some(ITEMS_KEYWORD_SEGMENT.clone()),
            "IterateKeywordSegment" => Some(ITERATE_KEYWORD_SEGMENT.clone()),
            "JarKeywordSegment" => Some(JAR_KEYWORD_SEGMENT.clone()),
            "JoinClauseSegment" => Some(JOIN_CLAUSE_SEGMENT.clone()),
            "JoinKeywordSegment" => Some(JOIN_KEYWORD_SEGMENT.clone()),
            "JoinKeywordsGrammar" => Some(JOIN_KEYWORDS_GRAMMAR.clone()),
            "JoinLikeClauseGrammar" => Some(JOIN_LIKE_CLAUSE_GRAMMAR.clone()),
            "JoinOnConditionSegment" => Some(JOIN_ON_CONDITION_SEGMENT.clone()),
            "JoinTypeKeywordsGrammar" => Some(JOIN_TYPE_KEYWORDS_GRAMMAR.clone()),
            "JoinUsingConditionGrammar" => Some(JOIN_USING_CONDITION_GRAMMAR.clone()),
            "JsonKeywordSegment" => Some(JSON_KEYWORD_SEGMENT.clone()),
            "Json_arrayKeywordSegment" => Some(JSON_ARRAY_KEYWORD_SEGMENT.clone()),
            "Json_arrayaggKeywordSegment" => Some(JSON_ARRAYAGG_KEYWORD_SEGMENT.clone()),
            "Json_existsKeywordSegment" => Some(JSON_EXISTS_KEYWORD_SEGMENT.clone()),
            "Json_objectKeywordSegment" => Some(JSON_OBJECT_KEYWORD_SEGMENT.clone()),
            "Json_objectaggKeywordSegment" => Some(JSON_OBJECTAGG_KEYWORD_SEGMENT.clone()),
            "Json_queryKeywordSegment" => Some(JSON_QUERY_KEYWORD_SEGMENT.clone()),
            "Json_tableKeywordSegment" => Some(JSON_TABLE_KEYWORD_SEGMENT.clone()),
            "Json_table_primitiveKeywordSegment" => Some(JSON_TABLE_PRIMITIVE_KEYWORD_SEGMENT.clone()),
            "Json_valueKeywordSegment" => Some(JSON_VALUE_KEYWORD_SEGMENT.clone()),
            "JsonfileKeywordSegment" => Some(JSONFILE_KEYWORD_SEGMENT.clone()),
            "KKeywordSegment" => Some(K_KEYWORD_SEGMENT.clone()),
            "KeyKeywordSegment" => Some(KEY_KEYWORD_SEGMENT.clone()),
            "Key_memberKeywordSegment" => Some(KEY_MEMBER_KEYWORD_SEGMENT.clone()),
            "Key_typeKeywordSegment" => Some(KEY_TYPE_KEYWORD_SEGMENT.clone()),
            "KeysKeywordSegment" => Some(KEYS_KEYWORD_SEGMENT.clone()),
            "KeywordSegment" => Some(KEYWORD_SEGMENT.clone()),
            "KillKeywordSegment" => Some(KILL_KEYWORD_SEGMENT.clone()),
            "KuduKeywordSegment" => Some(KUDU_KEYWORD_SEGMENT.clone()),
            "LancompilerKeywordSegment" => Some(LANCOMPILER_KEYWORD_SEGMENT.clone()),
            "LanguageKeywordSegment" => Some(LANGUAGE_KEYWORD_SEGMENT.clone()),
            "LargeKeywordSegment" => Some(LARGE_KEYWORD_SEGMENT.clone()),
            "LastKeywordSegment" => Some(LAST_KEYWORD_SEGMENT.clone()),
            "Last_insert_idKeywordSegment" => Some(LAST_INSERT_ID_KEYWORD_SEGMENT.clone()),
            "LateralKeywordSegment" => Some(LATERAL_KEYWORD_SEGMENT.clone()),
            "LateralViewClauseSegment" => Some(LATERAL_VIEW_CLAUSE_SEGMENT.clone()),
            "LeadingKeywordSegment" => Some(LEADING_KEYWORD_SEGMENT.clone()),
            "LeastKeywordSegment" => Some(LEAST_KEYWORD_SEGMENT.clone()),
            "LeaveKeywordSegment" => Some(LEAVE_KEYWORD_SEGMENT.clone()),
            "LeftKeywordSegment" => Some(LEFT_KEYWORD_SEGMENT.clone()),
            "LengthKeywordSegment" => Some(LENGTH_KEYWORD_SEGMENT.clone()),
            "LessKeywordSegment" => Some(LESS_KEYWORD_SEGMENT.clone()),
            "LessThanOrEqualToSegment" => Some(LESS_THAN_OR_EQUAL_TO_SEGMENT.clone()),
            "LessThanSegment" => Some(LESS_THAN_SEGMENT.clone()),
            "LevelKeywordSegment" => Some(LEVEL_KEYWORD_SEGMENT.clone()),
            "LexicalKeywordSegment" => Some(LEXICAL_KEYWORD_SEGMENT.clone()),
            "LikeExpressionGrammar" => Some(LIKE_EXPRESSION_GRAMMAR.clone()),
            "LikeGrammar" => Some(LIKE_GRAMMAR.clone()),
            "LikeKeywordSegment" => Some(LIKE_KEYWORD_SEGMENT.clone()),
            "LikeOperatorSegment" => Some(LIKE_OPERATOR_SEGMENT.clone()),
            "Like_regexKeywordSegment" => Some(LIKE_REGEX_KEYWORD_SEGMENT.clone()),
            "LimitClauseSegment" => Some(LIMIT_CLAUSE_SEGMENT.clone()),
            "LimitKeywordSegment" => Some(LIMIT_KEYWORD_SEGMENT.clone()),
            "LinenoKeywordSegment" => Some(LINENO_KEYWORD_SEGMENT.clone()),
            "LinesKeywordSegment" => Some(LINES_KEYWORD_SEGMENT.clone()),
            "ListComprehensionGrammar" => Some(LIST_COMPREHENSION_GRAMMAR.clone()),
            "ListaggKeywordSegment" => Some(LISTAGG_KEYWORD_SEGMENT.clone()),
            "ListenKeywordSegment" => Some(LISTEN_KEYWORD_SEGMENT.clone()),
            "LiteralGrammar" => Some(LITERAL_GRAMMAR.clone()),
            "LiteralKeywordSegment" => Some(LITERAL_KEYWORD_SEGMENT.clone()),
            "LiteralSegment" => Some(LITERAL_SEGMENT.clone()),
            "LnKeywordSegment" => Some(LN_KEYWORD_SEGMENT.clone()),
            "LoadKeywordSegment" => Some(LOAD_KEYWORD_SEGMENT.clone()),
            "LocalAliasSegment" => Some(LOCAL_ALIAS_SEGMENT.clone()),
            "LocalKeywordSegment" => Some(LOCAL_KEYWORD_SEGMENT.clone()),
            "LocaltimeKeywordSegment" => Some(LOCALTIME_KEYWORD_SEGMENT.clone()),
            "LocaltimestampKeywordSegment" => Some(LOCALTIMESTAMP_KEYWORD_SEGMENT.clone()),
            "LocationGrammar" => Some(LOCATION_GRAMMAR.clone()),
            "LocationKeywordSegment" => Some(LOCATION_KEYWORD_SEGMENT.clone()),
            "LocatorKeywordSegment" => Some(LOCATOR_KEYWORD_SEGMENT.clone()),
            "LockKeywordSegment" => Some(LOCK_KEYWORD_SEGMENT.clone()),
            "LocksKeywordSegment" => Some(LOCKS_KEYWORD_SEGMENT.clone()),
            "Log10KeywordSegment" => Some(LOG10_KEYWORD_SEGMENT.clone()),
            "LogicalKeywordSegment" => Some(LOGICAL_KEYWORD_SEGMENT.clone()),
            "LoginKeywordSegment" => Some(LOGIN_KEYWORD_SEGMENT.clone()),
            "LogsKeywordSegment" => Some(LOGS_KEYWORD_SEGMENT.clone()),
            "LongKeywordSegment" => Some(LONG_KEYWORD_SEGMENT.clone()),
            "LongblobKeywordSegment" => Some(LONGBLOB_KEYWORD_SEGMENT.clone()),
            "LongtextKeywordSegment" => Some(LONGTEXT_KEYWORD_SEGMENT.clone()),
            "LoopKeywordSegment" => Some(LOOP_KEYWORD_SEGMENT.clone()),
            "Low_priorityKeywordSegment" => Some(LOW_PRIORITY_KEYWORD_SEGMENT.clone()),
            "LowerKeywordSegment" => Some(LOWER_KEYWORD_SEGMENT.clone()),
            "MKeywordSegment" => Some(M_KEYWORD_SEGMENT.clone()),
            "MLTableExpressionSegment" => Some(M_L_TABLE_EXPRESSION_SEGMENT.clone()),
            "MacroKeywordSegment" => Some(MACRO_KEYWORD_SEGMENT.clone()),
            "ManageKeywordSegment" => Some(MANAGE_KEYWORD_SEGMENT.clone()),
            "ManagedlocationKeywordSegment" => Some(MANAGEDLOCATION_KEYWORD_SEGMENT.clone()),
            "MapKeywordSegment" => Some(MAP_KEYWORD_SEGMENT.clone()),
            "MapTypeSegment" => Some(MAP_TYPE_SEGMENT.clone()),
            "MapjoinKeywordSegment" => Some(MAPJOIN_KEYWORD_SEGMENT.clone()),
            "MaskingKeywordSegment" => Some(MASKING_KEYWORD_SEGMENT.clone()),
            "MatchConditionSegment" => Some(MATCH_CONDITION_SEGMENT.clone()),
            "MatchKeywordSegment" => Some(MATCH_KEYWORD_SEGMENT.clone()),
            "Match_numberKeywordSegment" => Some(MATCH_NUMBER_KEYWORD_SEGMENT.clone()),
            "Match_recognizeKeywordSegment" => Some(MATCH_RECOGNIZE_KEYWORD_SEGMENT.clone()),
            "MatchedKeywordSegment" => Some(MATCHED_KEYWORD_SEGMENT.clone()),
            "MatchesKeywordSegment" => Some(MATCHES_KEYWORD_SEGMENT.clone()),
            "MaterializedKeywordSegment" => Some(MATERIALIZED_KEYWORD_SEGMENT.clone()),
            "MaxKeywordSegment" => Some(MAX_KEYWORD_SEGMENT.clone()),
            "Max_rowsKeywordSegment" => Some(MAX_ROWS_KEYWORD_SEGMENT.clone()),
            "MaxextentsKeywordSegment" => Some(MAXEXTENTS_KEYWORD_SEGMENT.clone()),
            "MaxvalueKeywordSegment" => Some(MAXVALUE_KEYWORD_SEGMENT.clone()),
            "MediumblobKeywordSegment" => Some(MEDIUMBLOB_KEYWORD_SEGMENT.clone()),
            "MediumintKeywordSegment" => Some(MEDIUMINT_KEYWORD_SEGMENT.clone()),
            "MediumtextKeywordSegment" => Some(MEDIUMTEXT_KEYWORD_SEGMENT.clone()),
            "MemberKeywordSegment" => Some(MEMBER_KEYWORD_SEGMENT.clone()),
            "MergeDeleteClauseSegment" => Some(MERGE_DELETE_CLAUSE_SEGMENT.clone()),
            "MergeInsertClauseSegment" => Some(MERGE_INSERT_CLAUSE_SEGMENT.clone()),
            "MergeIntoLiteralGrammar" => Some(MERGE_INTO_LITERAL_GRAMMAR.clone()),
            "MergeKeywordSegment" => Some(MERGE_KEYWORD_SEGMENT.clone()),
            "MergeMatchSegment" => Some(MERGE_MATCH_SEGMENT.clone()),
            "MergeMatchedClauseSegment" => Some(MERGE_MATCHED_CLAUSE_SEGMENT.clone()),
            "MergeNotMatchedClauseSegment" => Some(MERGE_NOT_MATCHED_CLAUSE_SEGMENT.clone()),
            "MergeStatementSegment" => Some(MERGE_STATEMENT_SEGMENT.clone()),
            "MergeUpdateClauseSegment" => Some(MERGE_UPDATE_CLAUSE_SEGMENT.clone()),
            "Merge_fnKeywordSegment" => Some(MERGE_FN_KEYWORD_SEGMENT.clone()),
            "Message_lengthKeywordSegment" => Some(MESSAGE_LENGTH_KEYWORD_SEGMENT.clone()),
            "Message_octet_lengthKeywordSegment" => Some(MESSAGE_OCTET_LENGTH_KEYWORD_SEGMENT.clone()),
            "Message_textKeywordSegment" => Some(MESSAGE_TEXT_KEYWORD_SEGMENT.clone()),
            "MetadataKeywordSegment" => Some(METADATA_KEYWORD_SEGMENT.clone()),
            "MethodKeywordSegment" => Some(METHOD_KEYWORD_SEGMENT.clone()),
            "MiddleintKeywordSegment" => Some(MIDDLEINT_KEYWORD_SEGMENT.clone()),
            "MillisecondKeywordSegment" => Some(MILLISECOND_KEYWORD_SEGMENT.clone()),
            "MinKeywordSegment" => Some(MIN_KEYWORD_SEGMENT.clone()),
            "Min_rowsKeywordSegment" => Some(MIN_ROWS_KEYWORD_SEGMENT.clone()),
            "MinusKeywordSegment" => Some(MINUS_KEYWORD_SEGMENT.clone()),
            "MinusSegment" => Some(MINUS_SEGMENT.clone()),
            "MinuteKeywordSegment" => Some(MINUTE_KEYWORD_SEGMENT.clone()),
            "Minute_microsecondKeywordSegment" => Some(MINUTE_MICROSECOND_KEYWORD_SEGMENT.clone()),
            "Minute_secondKeywordSegment" => Some(MINUTE_SECOND_KEYWORD_SEGMENT.clone()),
            "MinutesKeywordSegment" => Some(MINUTES_KEYWORD_SEGMENT.clone()),
            "MinvalueKeywordSegment" => Some(MINVALUE_KEYWORD_SEGMENT.clone()),
            "MlKeywordSegment" => Some(ML_KEYWORD_SEGMENT.clone()),
            "MlslabelKeywordSegment" => Some(MLSLABEL_KEYWORD_SEGMENT.clone()),
            "ModKeywordSegment" => Some(MOD_KEYWORD_SEGMENT.clone()),
            "ModeKeywordSegment" => Some(MODE_KEYWORD_SEGMENT.clone()),
            "ModelKeywordSegment" => Some(MODEL_KEYWORD_SEGMENT.clone()),
            "ModifiesKeywordSegment" => Some(MODIFIES_KEYWORD_SEGMENT.clone()),
            "ModifyKeywordSegment" => Some(MODIFY_KEYWORD_SEGMENT.clone()),
            "ModuleKeywordSegment" => Some(MODULE_KEYWORD_SEGMENT.clone()),
            "ModuloSegment" => Some(MODULO_SEGMENT.clone()),
            "MonitorKeywordSegment" => Some(MONITOR_KEYWORD_SEGMENT.clone()),
            "MonthKeywordSegment" => Some(MONTH_KEYWORD_SEGMENT.clone()),
            "MonthnameKeywordSegment" => Some(MONTHNAME_KEYWORD_SEGMENT.clone()),
            "MonthsKeywordSegment" => Some(MONTHS_KEYWORD_SEGMENT.clone()),
            "MoreKeywordSegment" => Some(MORE_KEYWORD_SEGMENT.clone()),
            "MoveKeywordSegment" => Some(MOVE_KEYWORD_SEGMENT.clone()),
            "MsckKeywordSegment" => Some(MSCK_KEYWORD_SEGMENT.clone()),
            "MsckRepairTableStatementSegment" => Some(MSCK_REPAIR_TABLE_STATEMENT_SEGMENT.clone()),
            "MsckTableStatementSegment" => Some(MSCK_TABLE_STATEMENT_SEGMENT.clone()),
            "MultiplySegment" => Some(MULTIPLY_SEGMENT.clone()),
            "MultisetKeywordSegment" => Some(MULTISET_KEYWORD_SEGMENT.clone()),
            "MumpsKeywordSegment" => Some(MUMPS_KEYWORD_SEGMENT.clone()),
            "MyisamKeywordSegment" => Some(MYISAM_KEYWORD_SEGMENT.clone()),
            "NakedIdentifierSegment" => Some(NAKED_IDENTIFIER_SEGMENT.clone()),
            "NameKeywordSegment" => Some(NAME_KEYWORD_SEGMENT.clone()),
            "NamedWindowExpressionSegment" => Some(NAMED_WINDOW_EXPRESSION_SEGMENT.clone()),
            "NamedWindowSegment" => Some(NAMED_WINDOW_SEGMENT.clone()),
            "NamesKeywordSegment" => Some(NAMES_KEYWORD_SEGMENT.clone()),
            "NanKeywordSegment" => Some(NAN_KEYWORD_SEGMENT.clone()),
            "NanLiteralSegment" => Some(NAN_LITERAL_SEGMENT.clone()),
            "NationalKeywordSegment" => Some(NATIONAL_KEYWORD_SEGMENT.clone()),
            "NaturalJoinKeywordsGrammar" => Some(NATURAL_JOIN_KEYWORDS_GRAMMAR.clone()),
            "NaturalKeywordSegment" => Some(NATURAL_KEYWORD_SEGMENT.clone()),
            "NcharKeywordSegment" => Some(NCHAR_KEYWORD_SEGMENT.clone()),
            "NclobKeywordSegment" => Some(NCLOB_KEYWORD_SEGMENT.clone()),
            "NegativeSegment" => Some(NEGATIVE_SEGMENT.clone()),
            "NestedJoinGrammar" => Some(NESTED_JOIN_GRAMMAR.clone()),
            "NestingKeywordSegment" => Some(NESTING_KEYWORD_SEGMENT.clone()),
            "NewKeywordSegment" => Some(NEW_KEYWORD_SEGMENT.clone()),
            "NewlineSegment" => Some(NEWLINE_SEGMENT.clone()),
            "NextKeywordSegment" => Some(NEXT_KEYWORD_SEGMENT.clone()),
            "NoKeywordSegment" => Some(NO_KEYWORD_SEGMENT.clone()),
            "No_dropKeywordSegment" => Some(NO_DROP_KEYWORD_SEGMENT.clone()),
            "No_write_to_binlogKeywordSegment" => Some(NO_WRITE_TO_BINLOG_KEYWORD_SEGMENT.clone()),
            "NoauditKeywordSegment" => Some(NOAUDIT_KEYWORD_SEGMENT.clone()),
            "NocacheKeywordSegment" => Some(NOCACHE_KEYWORD_SEGMENT.clone()),
            "NocheckKeywordSegment" => Some(NOCHECK_KEYWORD_SEGMENT.clone()),
            "NocompressKeywordSegment" => Some(NOCOMPRESS_KEYWORD_SEGMENT.clone()),
            "NocreatedbKeywordSegment" => Some(NOCREATEDB_KEYWORD_SEGMENT.clone()),
            "NocreateroleKeywordSegment" => Some(NOCREATEROLE_KEYWORD_SEGMENT.clone()),
            "NocreateuserKeywordSegment" => Some(NOCREATEUSER_KEYWORD_SEGMENT.clone()),
            "NocycleKeywordSegment" => Some(NOCYCLE_KEYWORD_SEGMENT.clone()),
            "NoinheritKeywordSegment" => Some(NOINHERIT_KEYWORD_SEGMENT.clone()),
            "NologinKeywordSegment" => Some(NOLOGIN_KEYWORD_SEGMENT.clone()),
            "NonKeywordSegment" => Some(NON_KEYWORD_SEGMENT.clone()),
            "NonSetSelectableGrammar" => Some(NON_SET_SELECTABLE_GRAMMAR.clone()),
            "NonStandardJoinTypeKeywordsGrammar" => Some(NON_STANDARD_JOIN_TYPE_KEYWORDS_GRAMMAR.clone()),
            "NonWithNonSelectableGrammar" => Some(NON_WITH_NON_SELECTABLE_GRAMMAR.clone()),
            "NonWithSelectableGrammar" => Some(NON_WITH_SELECTABLE_GRAMMAR.clone()),
            "NonclusteredKeywordSegment" => Some(NONCLUSTERED_KEYWORD_SEGMENT.clone()),
            "NoneKeywordSegment" => Some(NONE_KEYWORD_SEGMENT.clone()),
            "NoorderKeywordSegment" => Some(NOORDER_KEYWORD_SEGMENT.clone()),
            "NorelyKeywordSegment" => Some(NORELY_KEYWORD_SEGMENT.clone()),
            "NormalizeKeywordSegment" => Some(NORMALIZE_KEYWORD_SEGMENT.clone()),
            "NormalizedGrammar" => Some(NORMALIZED_GRAMMAR.clone()),
            "NormalizedKeywordSegment" => Some(NORMALIZED_KEYWORD_SEGMENT.clone()),
            "NoscanKeywordSegment" => Some(NOSCAN_KEYWORD_SEGMENT.clone()),
            "NoshuffleKeywordSegment" => Some(NOSHUFFLE_KEYWORD_SEGMENT.clone()),
            "NosuperuserKeywordSegment" => Some(NOSUPERUSER_KEYWORD_SEGMENT.clone()),
            "NotEnforcedGrammar" => Some(NOT_ENFORCED_GRAMMAR.clone()),
            "NotEqualToSegment" => Some(NOT_EQUAL_TO_SEGMENT.clone()),
            "NotKeywordSegment" => Some(NOT_KEYWORD_SEGMENT.clone()),
            "NotNullGrammar" => Some(NOT_NULL_GRAMMAR.clone()),
            "NotOperatorGrammar" => Some(NOT_OPERATOR_GRAMMAR.clone()),
            "NothingKeywordSegment" => Some(NOTHING_KEYWORD_SEGMENT.clone()),
            "NotifyKeywordSegment" => Some(NOTIFY_KEYWORD_SEGMENT.clone()),
            "NotnullKeywordSegment" => Some(NOTNULL_KEYWORD_SEGMENT.clone()),
            "NovalidateKeywordSegment" => Some(NOVALIDATE_KEYWORD_SEGMENT.clone()),
            "NowaitKeywordSegment" => Some(NOWAIT_KEYWORD_SEGMENT.clone()),
            "Nth_valueKeywordSegment" => Some(NTH_VALUE_KEYWORD_SEGMENT.clone()),
            "NullKeywordSegment" => Some(NULL_KEYWORD_SEGMENT.clone()),
            "NullLiteralSegment" => Some(NULL_LITERAL_SEGMENT.clone()),
            "NullableKeywordSegment" => Some(NULLABLE_KEYWORD_SEGMENT.clone()),
            "NullifKeywordSegment" => Some(NULLIF_KEYWORD_SEGMENT.clone()),
            "NullsKeywordSegment" => Some(NULLS_KEYWORD_SEGMENT.clone()),
            "NumberKeywordSegment" => Some(NUMBER_KEYWORD_SEGMENT.clone()),
            "NumericKeywordSegment" => Some(NUMERIC_KEYWORD_SEGMENT.clone()),
            "NumericLiteralSegment" => Some(NUMERIC_LITERAL_SEGMENT.clone()),
            "ObjectKeywordSegment" => Some(OBJECT_KEYWORD_SEGMENT.clone()),
            "ObjectLiteralElementSegment" => Some(OBJECT_LITERAL_ELEMENT_SEGMENT.clone()),
            "ObjectLiteralSegment" => Some(OBJECT_LITERAL_SEGMENT.clone()),
            "ObjectReferenceDelimiterGrammar" => Some(OBJECT_REFERENCE_DELIMITER_GRAMMAR.clone()),
            "ObjectReferenceSegment" => Some(OBJECT_REFERENCE_SEGMENT.clone()),
            "ObjectReferenceTerminatorGrammar" => Some(OBJECT_REFERENCE_TERMINATOR_GRAMMAR.clone()),
            "ObjectsKeywordSegment" => Some(OBJECTS_KEYWORD_SEGMENT.clone()),
            "Occurrences_regexKeywordSegment" => Some(OCCURRENCES_REGEX_KEYWORD_SEGMENT.clone()),
            "Octet_lengthKeywordSegment" => Some(OCTET_LENGTH_KEYWORD_SEGMENT.clone()),
            "OctetsKeywordSegment" => Some(OCTETS_KEYWORD_SEGMENT.clone()),
            "OfKeywordSegment" => Some(OF_KEYWORD_SEGMENT.clone()),
            "OffKeywordSegment" => Some(OFF_KEYWORD_SEGMENT.clone()),
            "OfflineKeywordSegment" => Some(OFFLINE_KEYWORD_SEGMENT.clone()),
            "OffsetClauseSegment" => Some(OFFSET_CLAUSE_SEGMENT.clone()),
            "OffsetKeywordSegment" => Some(OFFSET_KEYWORD_SEGMENT.clone()),
            "OffsetsKeywordSegment" => Some(OFFSETS_KEYWORD_SEGMENT.clone()),
            "OidsKeywordSegment" => Some(OIDS_KEYWORD_SEGMENT.clone()),
            "OldKeywordSegment" => Some(OLD_KEYWORD_SEGMENT.clone()),
            "OmitKeywordSegment" => Some(OMIT_KEYWORD_SEGMENT.clone()),
            "OnKeywordSegment" => Some(ON_KEYWORD_SEGMENT.clone()),
            "OneKeywordSegment" => Some(ONE_KEYWORD_SEGMENT.clone()),
            "OnlineKeywordSegment" => Some(ONLINE_KEYWORD_SEGMENT.clone()),
            "OnlyKeywordSegment" => Some(ONLY_KEYWORD_SEGMENT.clone()),
            "OpenKeywordSegment" => Some(OPEN_KEYWORD_SEGMENT.clone()),
            "OpendatasourceKeywordSegment" => Some(OPENDATASOURCE_KEYWORD_SEGMENT.clone()),
            "OpenqueryKeywordSegment" => Some(OPENQUERY_KEYWORD_SEGMENT.clone()),
            "OpenrowsetKeywordSegment" => Some(OPENROWSET_KEYWORD_SEGMENT.clone()),
            "OpenxmlKeywordSegment" => Some(OPENXML_KEYWORD_SEGMENT.clone()),
            "OperateKeywordSegment" => Some(OPERATE_KEYWORD_SEGMENT.clone()),
            "OperationKeywordSegment" => Some(OPERATION_KEYWORD_SEGMENT.clone()),
            "OperatorKeywordSegment" => Some(OPERATOR_KEYWORD_SEGMENT.clone()),
            "OptimizeKeywordSegment" => Some(OPTIMIZE_KEYWORD_SEGMENT.clone()),
            "OptionKeywordSegment" => Some(OPTION_KEYWORD_SEGMENT.clone()),
            "OptionallyKeywordSegment" => Some(OPTIONALLY_KEYWORD_SEGMENT.clone()),
            "OptionsKeywordSegment" => Some(OPTIONS_KEYWORD_SEGMENT.clone()),
            "OrKeywordSegment" => Some(OR_KEYWORD_SEGMENT.clone()),
            "OrOperatorGrammar" => Some(OR_OPERATOR_GRAMMAR.clone()),
            "OrReplaceGrammar" => Some(OR_REPLACE_GRAMMAR.clone()),
            "OrcKeywordSegment" => Some(ORC_KEYWORD_SEGMENT.clone()),
            "OrderByClauseSegment" => Some(ORDER_BY_CLAUSE_SEGMENT.clone()),
            "OrderByClauseTerminators" => Some(ORDER_BY_CLAUSE_TERMINATORS.clone()),
            "OrderKeywordSegment" => Some(ORDER_KEYWORD_SEGMENT.clone()),
            "OrderNoOrderGrammar" => Some(ORDER_NO_ORDER_GRAMMAR.clone()),
            "OrderingKeywordSegment" => Some(ORDERING_KEYWORD_SEGMENT.clone()),
            "OrdinalityKeywordSegment" => Some(ORDINALITY_KEYWORD_SEGMENT.clone()),
            "OthersKeywordSegment" => Some(OTHERS_KEYWORD_SEGMENT.clone()),
            "OutKeywordSegment" => Some(OUT_KEYWORD_SEGMENT.clone()),
            "OuterKeywordSegment" => Some(OUTER_KEYWORD_SEGMENT.clone()),
            "OutfileKeywordSegment" => Some(OUTFILE_KEYWORD_SEGMENT.clone()),
            "OutputKeywordSegment" => Some(OUTPUT_KEYWORD_SEGMENT.clone()),
            "OutputdriverKeywordSegment" => Some(OUTPUTDRIVER_KEYWORD_SEGMENT.clone()),
            "OutputformatKeywordSegment" => Some(OUTPUTFORMAT_KEYWORD_SEGMENT.clone()),
            "OverClauseSegment" => Some(OVER_CLAUSE_SEGMENT.clone()),
            "OverKeywordSegment" => Some(OVER_KEYWORD_SEGMENT.clone()),
            "OverlapsClauseSegment" => Some(OVERLAPS_CLAUSE_SEGMENT.clone()),
            "OverlapsKeywordSegment" => Some(OVERLAPS_KEYWORD_SEGMENT.clone()),
            "OverlayKeywordSegment" => Some(OVERLAY_KEYWORD_SEGMENT.clone()),
            "OverridingKeywordSegment" => Some(OVERRIDING_KEYWORD_SEGMENT.clone()),
            "OverwriteKeywordSegment" => Some(OVERWRITE_KEYWORD_SEGMENT.clone()),
            "OwnerKeywordSegment" => Some(OWNER_KEYWORD_SEGMENT.clone()),
            "OwnershipKeywordSegment" => Some(OWNERSHIP_KEYWORD_SEGMENT.clone()),
            "Pack_keysKeywordSegment" => Some(PACK_KEYS_KEYWORD_SEGMENT.clone()),
            "PadKeywordSegment" => Some(PAD_KEYWORD_SEGMENT.clone()),
            "ParameterKeywordSegment" => Some(PARAMETER_KEYWORD_SEGMENT.clone()),
            "ParameterNameSegment" => Some(PARAMETER_NAME_SEGMENT.clone()),
            "ParameterSegment" => Some(PARAMETER_SEGMENT.clone()),
            "Parameter_modeKeywordSegment" => Some(PARAMETER_MODE_KEYWORD_SEGMENT.clone()),
            "Parameter_nameKeywordSegment" => Some(PARAMETER_NAME_KEYWORD_SEGMENT.clone()),
            "Parameter_ordinal_positionKeywordSegment" => Some(PARAMETER_ORDINAL_POSITION_KEYWORD_SEGMENT.clone()),
            "Parameter_specific_catalogKeywordSegment" => Some(PARAMETER_SPECIFIC_CATALOG_KEYWORD_SEGMENT.clone()),
            "Parameter_specific_nameKeywordSegment" => Some(PARAMETER_SPECIFIC_NAME_KEYWORD_SEGMENT.clone()),
            "Parameter_specific_schemaKeywordSegment" => Some(PARAMETER_SPECIFIC_SCHEMA_KEYWORD_SEGMENT.clone()),
            "ParametersKeywordSegment" => Some(PARAMETERS_KEYWORD_SEGMENT.clone()),
            "ParquetKeywordSegment" => Some(PARQUET_KEYWORD_SEGMENT.clone()),
            "ParquetfileKeywordSegment" => Some(PARQUETFILE_KEYWORD_SEGMENT.clone()),
            "PartialKeywordSegment" => Some(PARTIAL_KEYWORD_SEGMENT.clone()),
            "PartialscanKeywordSegment" => Some(PARTIALSCAN_KEYWORD_SEGMENT.clone()),
            "PartitionClauseSegment" => Some(PARTITION_CLAUSE_SEGMENT.clone()),
            "PartitionKeywordSegment" => Some(PARTITION_KEYWORD_SEGMENT.clone()),
            "PartitionSpecGrammar" => Some(PARTITION_SPEC_GRAMMAR.clone()),
            "PartitionedKeywordSegment" => Some(PARTITIONED_KEYWORD_SEGMENT.clone()),
            "PartitionsKeywordSegment" => Some(PARTITIONS_KEYWORD_SEGMENT.clone()),
            "PascalKeywordSegment" => Some(PASCAL_KEYWORD_SEGMENT.clone()),
            "PasswordKeywordSegment" => Some(PASSWORD_KEYWORD_SEGMENT.clone()),
            "PathKeywordSegment" => Some(PATH_KEYWORD_SEGMENT.clone()),
            "PathSegment" => Some(PATH_SEGMENT.clone()),
            "PatternKeywordSegment" => Some(PATTERN_KEYWORD_SEGMENT.clone()),
            "PatternMatchingGrammar" => Some(PATTERN_MATCHING_GRAMMAR.clone()),
            "PctfreeKeywordSegment" => Some(PCTFREE_KEYWORD_SEGMENT.clone()),
            "PerKeywordSegment" => Some(PER_KEYWORD_SEGMENT.clone()),
            "PercentKeywordSegment" => Some(PERCENT_KEYWORD_SEGMENT.clone()),
            "Percent_rankKeywordSegment" => Some(PERCENT_RANK_KEYWORD_SEGMENT.clone()),
            "Percentile_contKeywordSegment" => Some(PERCENTILE_CONT_KEYWORD_SEGMENT.clone()),
            "Percentile_discKeywordSegment" => Some(PERCENTILE_DISC_KEYWORD_SEGMENT.clone()),
            "PipeKeywordSegment" => Some(PIPE_KEYWORD_SEGMENT.clone()),
            "PipeSegment" => Some(PIPE_SEGMENT.clone()),
            "PlacingKeywordSegment" => Some(PLACING_KEYWORD_SEGMENT.clone()),
            "PlanKeywordSegment" => Some(PLAN_KEYWORD_SEGMENT.clone()),
            "PliKeywordSegment" => Some(PLI_KEYWORD_SEGMENT.clone()),
            "PlusKeywordSegment" => Some(PLUS_KEYWORD_SEGMENT.clone()),
            "PlusSegment" => Some(PLUS_SEGMENT.clone()),
            "PolicyKeywordSegment" => Some(POLICY_KEYWORD_SEGMENT.clone()),
            "PortionKeywordSegment" => Some(PORTION_KEYWORD_SEGMENT.clone()),
            "PositionKeywordSegment" => Some(POSITION_KEYWORD_SEGMENT.clone()),
            "Position_regexKeywordSegment" => Some(POSITION_REGEX_KEYWORD_SEGMENT.clone()),
            "PositiveSegment" => Some(POSITIVE_SEGMENT.clone()),
            "PostFunctionGrammar" => Some(POST_FUNCTION_GRAMMAR.clone()),
            "PostTableExpressionGrammar" => Some(POST_TABLE_EXPRESSION_GRAMMAR.clone()),
            "PostfixKeywordSegment" => Some(POSTFIX_KEYWORD_SEGMENT.clone()),
            "PowerKeywordSegment" => Some(POWER_KEYWORD_SEGMENT.clone()),
            "PreTableFunctionKeywordsGrammar" => Some(PRE_TABLE_FUNCTION_KEYWORDS_GRAMMAR.clone()),
            "PrecedesKeywordSegment" => Some(PRECEDES_KEYWORD_SEGMENT.clone()),
            "PrecedingKeywordSegment" => Some(PRECEDING_KEYWORD_SEGMENT.clone()),
            "PrecisionKeywordSegment" => Some(PRECISION_KEYWORD_SEGMENT.clone()),
            "PrefixKeywordSegment" => Some(PREFIX_KEYWORD_SEGMENT.clone()),
            "PreorderKeywordSegment" => Some(PREORDER_KEYWORD_SEGMENT.clone()),
            "PrepareKeywordSegment" => Some(PREPARE_KEYWORD_SEGMENT.clone()),
            "Prepare_fnKeywordSegment" => Some(PREPARE_FN_KEYWORD_SEGMENT.clone()),
            "PreparedKeywordSegment" => Some(PREPARED_KEYWORD_SEGMENT.clone()),
            "PreserveKeywordSegment" => Some(PRESERVE_KEYWORD_SEGMENT.clone()),
            "PrettyKeywordSegment" => Some(PRETTY_KEYWORD_SEGMENT.clone()),
            "PrimaryKeyGrammar" => Some(PRIMARY_KEY_GRAMMAR.clone()),
            "PrimaryKeywordSegment" => Some(PRIMARY_KEYWORD_SEGMENT.clone()),
            "PrimitiveTypeSegment" => Some(PRIMITIVE_TYPE_SEGMENT.clone()),
            "PrincipalsKeywordSegment" => Some(PRINCIPALS_KEYWORD_SEGMENT.clone()),
            "PrintKeywordSegment" => Some(PRINT_KEYWORD_SEGMENT.clone()),
            "PriorKeywordSegment" => Some(PRIOR_KEYWORD_SEGMENT.clone()),
            "PrivilegesKeywordSegment" => Some(PRIVILEGES_KEYWORD_SEGMENT.clone()),
            "ProcKeywordSegment" => Some(PROC_KEYWORD_SEGMENT.clone()),
            "ProceduralKeywordSegment" => Some(PROCEDURAL_KEYWORD_SEGMENT.clone()),
            "ProcedureKeywordSegment" => Some(PROCEDURE_KEYWORD_SEGMENT.clone()),
            "ProceduresKeywordSegment" => Some(PROCEDURES_KEYWORD_SEGMENT.clone()),
            "ProcessKeywordSegment" => Some(PROCESS_KEYWORD_SEGMENT.clone()),
            "ProcesslistKeywordSegment" => Some(PROCESSLIST_KEYWORD_SEGMENT.clone()),
            "ProducedKeywordSegment" => Some(PRODUCED_KEYWORD_SEGMENT.clone()),
            "PropertyGrammar" => Some(PROPERTY_GRAMMAR.clone()),
            "ProtectionKeywordSegment" => Some(PROTECTION_KEYWORD_SEGMENT.clone()),
            "PtfKeywordSegment" => Some(PTF_KEYWORD_SEGMENT.clone()),
            "PublicKeywordSegment" => Some(PUBLIC_KEYWORD_SEGMENT.clone()),
            "PurgeKeywordSegment" => Some(PURGE_KEYWORD_SEGMENT.clone()),
            "QualifiedNumericLiteralSegment" => Some(QUALIFIED_NUMERIC_LITERAL_SEGMENT.clone()),
            "QualifyKeywordSegment" => Some(QUALIFY_KEYWORD_SEGMENT.clone()),
            "QuarterKeywordSegment" => Some(QUARTER_KEYWORD_SEGMENT.clone()),
            "QuoteKeywordSegment" => Some(QUOTE_KEYWORD_SEGMENT.clone()),
            "QuotedIdentifierSegment" => Some(QUOTED_IDENTIFIER_SEGMENT.clone()),
            "QuotedLiteralSegment" => Some(QUOTED_LITERAL_SEGMENT.clone()),
            "Raid0KeywordSegment" => Some(RAID0_KEYWORD_SEGMENT.clone()),
            "RaiserrorKeywordSegment" => Some(RAISERROR_KEYWORD_SEGMENT.clone()),
            "RangeKeywordSegment" => Some(RANGE_KEYWORD_SEGMENT.clone()),
            "RankKeywordSegment" => Some(RANK_KEYWORD_SEGMENT.clone()),
            "RawEqualsSegment" => Some(RAW_EQUALS_SEGMENT.clone()),
            "RawGreaterThanSegment" => Some(RAW_GREATER_THAN_SEGMENT.clone()),
            "RawKeywordSegment" => Some(RAW_KEYWORD_SEGMENT.clone()),
            "RawLessThanSegment" => Some(RAW_LESS_THAN_SEGMENT.clone()),
            "RawNotSegment" => Some(RAW_NOT_SEGMENT.clone()),
            "RawSegment" => Some(RAW_SEGMENT.clone()),
            "RcfileKeywordSegment" => Some(RCFILE_KEYWORD_SEGMENT.clone()),
            "ReadKeywordSegment" => Some(READ_KEYWORD_SEGMENT.clone()),
            "ReadonlyKeywordSegment" => Some(READONLY_KEYWORD_SEGMENT.clone()),
            "ReadsKeywordSegment" => Some(READS_KEYWORD_SEGMENT.clone()),
            "ReadtextKeywordSegment" => Some(READTEXT_KEYWORD_SEGMENT.clone()),
            "RealKeywordSegment" => Some(REAL_KEYWORD_SEGMENT.clone()),
            "RebuildKeywordSegment" => Some(REBUILD_KEYWORD_SEGMENT.clone()),
            "RecheckKeywordSegment" => Some(RECHECK_KEYWORD_SEGMENT.clone()),
            "ReconfigureKeywordSegment" => Some(RECONFIGURE_KEYWORD_SEGMENT.clone()),
            "RecordreaderKeywordSegment" => Some(RECORDREADER_KEYWORD_SEGMENT.clone()),
            "RecordwriterKeywordSegment" => Some(RECORDWRITER_KEYWORD_SEGMENT.clone()),
            "RecoverKeywordSegment" => Some(RECOVER_KEYWORD_SEGMENT.clone()),
            "RecursiveKeywordSegment" => Some(RECURSIVE_KEYWORD_SEGMENT.clone()),
            "ReduceKeywordSegment" => Some(REDUCE_KEYWORD_SEGMENT.clone()),
            "RefKeywordSegment" => Some(REF_KEYWORD_SEGMENT.clone()),
            "ReferenceDefinitionGrammar" => Some(REFERENCE_DEFINITION_GRAMMAR.clone()),
            "ReferenceMatchGrammar" => Some(REFERENCE_MATCH_GRAMMAR.clone()),
            "Reference_usageKeywordSegment" => Some(REFERENCE_USAGE_KEYWORD_SEGMENT.clone()),
            "ReferencesKeywordSegment" => Some(REFERENCES_KEYWORD_SEGMENT.clone()),
            "ReferencingKeywordSegment" => Some(REFERENCING_KEYWORD_SEGMENT.clone()),
            "ReferentialActionGrammar" => Some(REFERENTIAL_ACTION_GRAMMAR.clone()),
            "RefreshKeywordSegment" => Some(REFRESH_KEYWORD_SEGMENT.clone()),
            "RegexpKeywordSegment" => Some(REGEXP_KEYWORD_SEGMENT.clone()),
            "Regr_avgxKeywordSegment" => Some(REGR_AVGX_KEYWORD_SEGMENT.clone()),
            "Regr_avgyKeywordSegment" => Some(REGR_AVGY_KEYWORD_SEGMENT.clone()),
            "Regr_countKeywordSegment" => Some(REGR_COUNT_KEYWORD_SEGMENT.clone()),
            "Regr_interceptKeywordSegment" => Some(REGR_INTERCEPT_KEYWORD_SEGMENT.clone()),
            "Regr_r2KeywordSegment" => Some(REGR_R2_KEYWORD_SEGMENT.clone()),
            "Regr_slopeKeywordSegment" => Some(REGR_SLOPE_KEYWORD_SEGMENT.clone()),
            "Regr_sxxKeywordSegment" => Some(REGR_SXX_KEYWORD_SEGMENT.clone()),
            "Regr_sxyKeywordSegment" => Some(REGR_SXY_KEYWORD_SEGMENT.clone()),
            "Regr_syyKeywordSegment" => Some(REGR_SYY_KEYWORD_SEGMENT.clone()),
            "ReindexKeywordSegment" => Some(REINDEX_KEYWORD_SEGMENT.clone()),
            "RelativeKeywordSegment" => Some(RELATIVE_KEYWORD_SEGMENT.clone()),
            "ReleaseKeywordSegment" => Some(RELEASE_KEYWORD_SEGMENT.clone()),
            "ReloadKeywordSegment" => Some(RELOAD_KEYWORD_SEGMENT.clone()),
            "RelyKeywordSegment" => Some(RELY_KEYWORD_SEGMENT.clone()),
            "RenameKeywordSegment" => Some(RENAME_KEYWORD_SEGMENT.clone()),
            "RepairKeywordSegment" => Some(REPAIR_KEYWORD_SEGMENT.clone()),
            "RepeatKeywordSegment" => Some(REPEAT_KEYWORD_SEGMENT.clone()),
            "RepeatableKeywordSegment" => Some(REPEATABLE_KEYWORD_SEGMENT.clone()),
            "ReplaceKeywordSegment" => Some(REPLACE_KEYWORD_SEGMENT.clone()),
            "ReplicationKeywordSegment" => Some(REPLICATION_KEYWORD_SEGMENT.clone()),
            "RequireKeywordSegment" => Some(REQUIRE_KEYWORD_SEGMENT.clone()),
            "ResetKeywordSegment" => Some(RESET_KEYWORD_SEGMENT.clone()),
            "ResignalKeywordSegment" => Some(RESIGNAL_KEYWORD_SEGMENT.clone()),
            "ResourceKeywordSegment" => Some(RESOURCE_KEYWORD_SEGMENT.clone()),
            "RespectKeywordSegment" => Some(RESPECT_KEYWORD_SEGMENT.clone()),
            "RestartKeywordSegment" => Some(RESTART_KEYWORD_SEGMENT.clone()),
            "RestoreKeywordSegment" => Some(RESTORE_KEYWORD_SEGMENT.clone()),
            "RestrictKeywordSegment" => Some(RESTRICT_KEYWORD_SEGMENT.clone()),
            "ResultKeywordSegment" => Some(RESULT_KEYWORD_SEGMENT.clone()),
            "ReturnKeywordSegment" => Some(RETURN_KEYWORD_SEGMENT.clone()),
            "Returned_cardinalityKeywordSegment" => Some(RETURNED_CARDINALITY_KEYWORD_SEGMENT.clone()),
            "Returned_lengthKeywordSegment" => Some(RETURNED_LENGTH_KEYWORD_SEGMENT.clone()),
            "Returned_octet_lengthKeywordSegment" => Some(RETURNED_OCTET_LENGTH_KEYWORD_SEGMENT.clone()),
            "Returned_sqlstateKeywordSegment" => Some(RETURNED_SQLSTATE_KEYWORD_SEGMENT.clone()),
            "ReturnsKeywordSegment" => Some(RETURNS_KEYWORD_SEGMENT.clone()),
            "RevokeKeywordSegment" => Some(REVOKE_KEYWORD_SEGMENT.clone()),
            "RewriteKeywordSegment" => Some(REWRITE_KEYWORD_SEGMENT.clone()),
            "RightKeywordSegment" => Some(RIGHT_KEYWORD_SEGMENT.clone()),
            "RlikeKeywordSegment" => Some(RLIKE_KEYWORD_SEGMENT.clone()),
            "RoleKeywordSegment" => Some(ROLE_KEYWORD_SEGMENT.clone()),
            "RoleReferenceSegment" => Some(ROLE_REFERENCE_SEGMENT.clone()),
            "RolesKeywordSegment" => Some(ROLES_KEYWORD_SEGMENT.clone()),
            "RollbackKeywordSegment" => Some(ROLLBACK_KEYWORD_SEGMENT.clone()),
            "RollupFunctionNameSegment" => Some(ROLLUP_FUNCTION_NAME_SEGMENT.clone()),
            "RollupKeywordSegment" => Some(ROLLUP_KEYWORD_SEGMENT.clone()),
            "RoutineKeywordSegment" => Some(ROUTINE_KEYWORD_SEGMENT.clone()),
            "Routine_catalogKeywordSegment" => Some(ROUTINE_CATALOG_KEYWORD_SEGMENT.clone()),
            "Routine_nameKeywordSegment" => Some(ROUTINE_NAME_KEYWORD_SEGMENT.clone()),
            "Routine_schemaKeywordSegment" => Some(ROUTINE_SCHEMA_KEYWORD_SEGMENT.clone()),
            "RoutinesKeywordSegment" => Some(ROUTINES_KEYWORD_SEGMENT.clone()),
            "RowFormatClauseSegment" => Some(ROW_FORMAT_CLAUSE_SEGMENT.clone()),
            "RowFunctionContentsSegment" => Some(ROW_FUNCTION_CONTENTS_SEGMENT.clone()),
            "RowKeywordSegment" => Some(ROW_KEYWORD_SEGMENT.clone()),
            "Row_countKeywordSegment" => Some(ROW_COUNT_KEYWORD_SEGMENT.clone()),
            "Row_numberKeywordSegment" => Some(ROW_NUMBER_KEYWORD_SEGMENT.clone()),
            "RowcountKeywordSegment" => Some(ROWCOUNT_KEYWORD_SEGMENT.clone()),
            "RowguidcolKeywordSegment" => Some(ROWGUIDCOL_KEYWORD_SEGMENT.clone()),
            "RowidKeywordSegment" => Some(ROWID_KEYWORD_SEGMENT.clone()),
            "RownumKeywordSegment" => Some(ROWNUM_KEYWORD_SEGMENT.clone()),
            "RowsKeywordSegment" => Some(ROWS_KEYWORD_SEGMENT.clone()),
            "RuleKeywordSegment" => Some(RULE_KEYWORD_SEGMENT.clone()),
            "RunningKeywordSegment" => Some(RUNNING_KEYWORD_SEGMENT.clone()),
            "RwstorageKeywordSegment" => Some(RWSTORAGE_KEYWORD_SEGMENT.clone()),
            "SamplingExpressionSegment" => Some(SAMPLING_EXPRESSION_SEGMENT.clone()),
            "SaveKeywordSegment" => Some(SAVE_KEYWORD_SEGMENT.clone()),
            "SavepointKeywordSegment" => Some(SAVEPOINT_KEYWORD_SEGMENT.clone()),
            "ScaleKeywordSegment" => Some(SCALE_KEYWORD_SEGMENT.clone()),
            "SchemaKeywordSegment" => Some(SCHEMA_KEYWORD_SEGMENT.clone()),
            "SchemaReferenceSegment" => Some(SCHEMA_REFERENCE_SEGMENT.clone()),
            "Schema_nameKeywordSegment" => Some(SCHEMA_NAME_KEYWORD_SEGMENT.clone()),
            "SchemasKeywordSegment" => Some(SCHEMAS_KEYWORD_SEGMENT.clone()),
            "ScopeKeywordSegment" => Some(SCOPE_KEYWORD_SEGMENT.clone()),
            "Scope_catalogKeywordSegment" => Some(SCOPE_CATALOG_KEYWORD_SEGMENT.clone()),
            "Scope_nameKeywordSegment" => Some(SCOPE_NAME_KEYWORD_SEGMENT.clone()),
            "Scope_schemaKeywordSegment" => Some(SCOPE_SCHEMA_KEYWORD_SEGMENT.clone()),
            "ScrollKeywordSegment" => Some(SCROLL_KEYWORD_SEGMENT.clone()),
            "SearchKeywordSegment" => Some(SEARCH_KEYWORD_SEGMENT.clone()),
            "SecondKeywordSegment" => Some(SECOND_KEYWORD_SEGMENT.clone()),
            "Second_microsecondKeywordSegment" => Some(SECOND_MICROSECOND_KEYWORD_SEGMENT.clone()),
            "SecondsKeywordSegment" => Some(SECONDS_KEYWORD_SEGMENT.clone()),
            "SectionKeywordSegment" => Some(SECTION_KEYWORD_SEGMENT.clone()),
            "SecurityKeywordSegment" => Some(SECURITY_KEYWORD_SEGMENT.clone()),
            "SeekKeywordSegment" => Some(SEEK_KEYWORD_SEGMENT.clone()),
            "SelectClauseElementSegment" => Some(SELECT_CLAUSE_ELEMENT_SEGMENT.clone()),
            "SelectClauseModifierSegment" => Some(SELECT_CLAUSE_MODIFIER_SEGMENT.clone()),
            "SelectClauseSegment" => Some(SELECT_CLAUSE_SEGMENT.clone()),
            "SelectClauseTerminatorGrammar" => Some(SELECT_CLAUSE_TERMINATOR_GRAMMAR.clone()),
            "SelectKeywordSegment" => Some(SELECT_KEYWORD_SEGMENT.clone()),
            "SelectStatementSegment" => Some(SELECT_STATEMENT_SEGMENT.clone()),
            "SelectableGrammar" => Some(SELECTABLE_GRAMMAR.clone()),
            "SelectivityKeywordSegment" => Some(SELECTIVITY_KEYWORD_SEGMENT.clone()),
            "SelfKeywordSegment" => Some(SELF_KEYWORD_SEGMENT.clone()),
            "SemiKeywordSegment" => Some(SEMI_KEYWORD_SEGMENT.clone()),
            "SemicolonSegment" => Some(SEMICOLON_SEGMENT.clone()),
            "SensitiveKeywordSegment" => Some(SENSITIVE_KEYWORD_SEGMENT.clone()),
            "SeparatorKeywordSegment" => Some(SEPARATOR_KEYWORD_SEGMENT.clone()),
            "SequenceKeywordSegment" => Some(SEQUENCE_KEYWORD_SEGMENT.clone()),
            "SequenceMaxValueGrammar" => Some(SEQUENCE_MAX_VALUE_GRAMMAR.clone()),
            "SequenceMinValueGrammar" => Some(SEQUENCE_MIN_VALUE_GRAMMAR.clone()),
            "SequenceReferenceSegment" => Some(SEQUENCE_REFERENCE_SEGMENT.clone()),
            "SequencefileKeywordSegment" => Some(SEQUENCEFILE_KEYWORD_SEGMENT.clone()),
            "SequencesKeywordSegment" => Some(SEQUENCES_KEYWORD_SEGMENT.clone()),
            "SerdeKeywordSegment" => Some(SERDE_KEYWORD_SEGMENT.clone()),
            "SerdePropertiesGrammar" => Some(SERDE_PROPERTIES_GRAMMAR.clone()),
            "SerdepropertiesKeywordSegment" => Some(SERDEPROPERTIES_KEYWORD_SEGMENT.clone()),
            "SerializableKeywordSegment" => Some(SERIALIZABLE_KEYWORD_SEGMENT.clone()),
            "Serialize_fnKeywordSegment" => Some(SERIALIZE_FN_KEYWORD_SEGMENT.clone()),
            "ServerKeywordSegment" => Some(SERVER_KEYWORD_SEGMENT.clone()),
            "Server_nameKeywordSegment" => Some(SERVER_NAME_KEYWORD_SEGMENT.clone()),
            "SessionKeywordSegment" => Some(SESSION_KEYWORD_SEGMENT.clone()),
            "Session_userKeywordSegment" => Some(SESSION_USER_KEYWORD_SEGMENT.clone()),
            "SetClauseListSegment" => Some(SET_CLAUSE_LIST_SEGMENT.clone()),
            "SetClauseSegment" => Some(SET_CLAUSE_SEGMENT.clone()),
            "SetExpressionSegment" => Some(SET_EXPRESSION_SEGMENT.clone()),
            "SetKeywordSegment" => Some(SET_KEYWORD_SEGMENT.clone()),
            "SetOperatorSegment" => Some(SET_OPERATOR_SEGMENT.clone()),
            "SetSchemaStatementSegment" => Some(SET_SCHEMA_STATEMENT_SEGMENT.clone()),
            "SetStatementSegment" => Some(SET_STATEMENT_SEGMENT.clone()),
            "SetofKeywordSegment" => Some(SETOF_KEYWORD_SEGMENT.clone()),
            "SetsKeywordSegment" => Some(SETS_KEYWORD_SEGMENT.clone()),
            "SetuserKeywordSegment" => Some(SETUSER_KEYWORD_SEGMENT.clone()),
            "ShareKeywordSegment" => Some(SHARE_KEYWORD_SEGMENT.clone()),
            "SharedKeywordSegment" => Some(SHARED_KEYWORD_SEGMENT.clone()),
            "SharesKeywordSegment" => Some(SHARES_KEYWORD_SEGMENT.clone()),
            "ShorthandCastSegment" => Some(SHORTHAND_CAST_SEGMENT.clone()),
            "ShowKeywordSegment" => Some(SHOW_KEYWORD_SEGMENT.clone()),
            "Show_databaseKeywordSegment" => Some(SHOW_DATABASE_KEYWORD_SEGMENT.clone()),
            "ShuffleKeywordSegment" => Some(SHUFFLE_KEYWORD_SEGMENT.clone()),
            "ShutdownKeywordSegment" => Some(SHUTDOWN_KEYWORD_SEGMENT.clone()),
            "SignalKeywordSegment" => Some(SIGNAL_KEYWORD_SEGMENT.clone()),
            "SignedSegmentGrammar" => Some(SIGNED_SEGMENT_GRAMMAR.clone()),
            "SimilarKeywordSegment" => Some(SIMILAR_KEYWORD_SEGMENT.clone()),
            "SimpleKeywordSegment" => Some(SIMPLE_KEYWORD_SEGMENT.clone()),
            "SingleIdentifierGrammar" => Some(SINGLE_IDENTIFIER_GRAMMAR.clone()),
            "SingleIdentifierListSegment" => Some(SINGLE_IDENTIFIER_LIST_SEGMENT.clone()),
            "SingleQuotedIdentifierSegment" => Some(SINGLE_QUOTED_IDENTIFIER_SEGMENT.clone()),
            "SizeKeywordSegment" => Some(SIZE_KEYWORD_SEGMENT.clone()),
            "SizedArrayTypeSegment" => Some(SIZED_ARRAY_TYPE_SEGMENT.clone()),
            "SkewedByClauseSegment" => Some(SKEWED_BY_CLAUSE_SEGMENT.clone()),
            "SkewedKeywordSegment" => Some(SKEWED_KEYWORD_SEGMENT.clone()),
            "SkipKeywordSegment" => Some(SKIP_KEYWORD_SEGMENT.clone()),
            "SlashSegment" => Some(SLASH_SEGMENT.clone()),
            "SliceSegment" => Some(SLICE_SEGMENT.clone()),
            "SmallintKeywordSegment" => Some(SMALLINT_KEYWORD_SEGMENT.clone()),
            "SnapshotKeywordSegment" => Some(SNAPSHOT_KEYWORD_SEGMENT.clone()),
            "SomeKeywordSegment" => Some(SOME_KEYWORD_SEGMENT.clone()),
            "SonameKeywordSegment" => Some(SONAME_KEYWORD_SEGMENT.clone()),
            "SortByClauseSegment" => Some(SORT_BY_CLAUSE_SEGMENT.clone()),
            "SortKeywordSegment" => Some(SORT_KEYWORD_SEGMENT.clone()),
            "SortedKeywordSegment" => Some(SORTED_KEYWORD_SEGMENT.clone()),
            "SourceKeywordSegment" => Some(SOURCE_KEYWORD_SEGMENT.clone()),
            "SpaceKeywordSegment" => Some(SPACE_KEYWORD_SEGMENT.clone()),
            "SpatialKeywordSegment" => Some(SPATIAL_KEYWORD_SEGMENT.clone()),
            "SpecKeywordSegment" => Some(SPEC_KEYWORD_SEGMENT.clone()),
            "SpecificKeywordSegment" => Some(SPECIFIC_KEYWORD_SEGMENT.clone()),
            "Specific_nameKeywordSegment" => Some(SPECIFIC_NAME_KEYWORD_SEGMENT.clone()),
            "SpecifictypeKeywordSegment" => Some(SPECIFICTYPE_KEYWORD_SEGMENT.clone()),
            "SqlKeywordSegment" => Some(SQL_KEYWORD_SEGMENT.clone()),
            "Sql_big_resultKeywordSegment" => Some(SQL_BIG_RESULT_KEYWORD_SEGMENT.clone()),
            "Sql_big_selectsKeywordSegment" => Some(SQL_BIG_SELECTS_KEYWORD_SEGMENT.clone()),
            "Sql_big_tablesKeywordSegment" => Some(SQL_BIG_TABLES_KEYWORD_SEGMENT.clone()),
            "Sql_calc_found_rowsKeywordSegment" => Some(SQL_CALC_FOUND_ROWS_KEYWORD_SEGMENT.clone()),
            "Sql_log_offKeywordSegment" => Some(SQL_LOG_OFF_KEYWORD_SEGMENT.clone()),
            "Sql_log_updateKeywordSegment" => Some(SQL_LOG_UPDATE_KEYWORD_SEGMENT.clone()),
            "Sql_low_priority_updatesKeywordSegment" => Some(SQL_LOW_PRIORITY_UPDATES_KEYWORD_SEGMENT.clone()),
            "Sql_select_limitKeywordSegment" => Some(SQL_SELECT_LIMIT_KEYWORD_SEGMENT.clone()),
            "Sql_small_resultKeywordSegment" => Some(SQL_SMALL_RESULT_KEYWORD_SEGMENT.clone()),
            "Sql_warningsKeywordSegment" => Some(SQL_WARNINGS_KEYWORD_SEGMENT.clone()),
            "SqlcaKeywordSegment" => Some(SQLCA_KEYWORD_SEGMENT.clone()),
            "SqlcodeKeywordSegment" => Some(SQLCODE_KEYWORD_SEGMENT.clone()),
            "SqlerrorKeywordSegment" => Some(SQLERROR_KEYWORD_SEGMENT.clone()),
            "SqlexceptionKeywordSegment" => Some(SQLEXCEPTION_KEYWORD_SEGMENT.clone()),
            "SqlstateKeywordSegment" => Some(SQLSTATE_KEYWORD_SEGMENT.clone()),
            "SqlwarningKeywordSegment" => Some(SQLWARNING_KEYWORD_SEGMENT.clone()),
            "SqrtKeywordSegment" => Some(SQRT_KEYWORD_SEGMENT.clone()),
            "SslKeywordSegment" => Some(SSL_KEYWORD_SEGMENT.clone()),
            "StableKeywordSegment" => Some(STABLE_KEYWORD_SEGMENT.clone()),
            "StageKeywordSegment" => Some(STAGE_KEYWORD_SEGMENT.clone()),
            "StagesKeywordSegment" => Some(STAGES_KEYWORD_SEGMENT.clone()),
            "StarSegment" => Some(STAR_SEGMENT.clone()),
            "StartAngleBracketSegment" => Some(START_ANGLE_BRACKET_SEGMENT.clone()),
            "StartBracketSegment" => Some(START_BRACKET_SEGMENT.clone()),
            "StartCurlyBracketSegment" => Some(START_CURLY_BRACKET_SEGMENT.clone()),
            "StartKeywordSegment" => Some(START_KEYWORD_SEGMENT.clone()),
            "StartSquareBracketSegment" => Some(START_SQUARE_BRACKET_SEGMENT.clone()),
            "StartingKeywordSegment" => Some(STARTING_KEYWORD_SEGMENT.clone()),
            "StartsKeywordSegment" => Some(STARTS_KEYWORD_SEGMENT.clone()),
            "StateKeywordSegment" => Some(STATE_KEYWORD_SEGMENT.clone()),
            "StatementKeywordSegment" => Some(STATEMENT_KEYWORD_SEGMENT.clone()),
            "StatementSegment" => Some(STATEMENT_SEGMENT.clone()),
            "StaticKeywordSegment" => Some(STATIC_KEYWORD_SEGMENT.clone()),
            "StatisticsKeywordSegment" => Some(STATISTICS_KEYWORD_SEGMENT.clone()),
            "StatsKeywordSegment" => Some(STATS_KEYWORD_SEGMENT.clone()),
            "Stddev_popKeywordSegment" => Some(STDDEV_POP_KEYWORD_SEGMENT.clone()),
            "Stddev_sampKeywordSegment" => Some(STDDEV_SAMP_KEYWORD_SEGMENT.clone()),
            "StdinKeywordSegment" => Some(STDIN_KEYWORD_SEGMENT.clone()),
            "StdoutKeywordSegment" => Some(STDOUT_KEYWORD_SEGMENT.clone()),
            "StorageFormatGrammar" => Some(STORAGE_FORMAT_GRAMMAR.clone()),
            "StorageKeywordSegment" => Some(STORAGE_KEYWORD_SEGMENT.clone()),
            "Storagehandler_uriKeywordSegment" => Some(STORAGEHANDLER_URI_KEYWORD_SEGMENT.clone()),
            "StoredAsGrammar" => Some(STORED_AS_GRAMMAR.clone()),
            "StoredByGrammar" => Some(STORED_BY_GRAMMAR.clone()),
            "StoredKeywordSegment" => Some(STORED_KEYWORD_SEGMENT.clone()),
            "Straight_joinKeywordSegment" => Some(STRAIGHT_JOIN_KEYWORD_SEGMENT.clone()),
            "StreamKeywordSegment" => Some(STREAM_KEYWORD_SEGMENT.clone()),
            "StreamsKeywordSegment" => Some(STREAMS_KEYWORD_SEGMENT.clone()),
            "StreamtableKeywordSegment" => Some(STREAMTABLE_KEYWORD_SEGMENT.clone()),
            "StrictKeywordSegment" => Some(STRICT_KEYWORD_SEGMENT.clone()),
            "StringBinaryOperatorGrammar" => Some(STRING_BINARY_OPERATOR_GRAMMAR.clone()),
            "StringKeywordSegment" => Some(STRING_KEYWORD_SEGMENT.clone()),
            "StructKeywordSegment" => Some(STRUCT_KEYWORD_SEGMENT.clone()),
            "StructLiteralSegment" => Some(STRUCT_LITERAL_SEGMENT.clone()),
            "StructTypeSchemaSegment" => Some(STRUCT_TYPE_SCHEMA_SEGMENT.clone()),
            "StructTypeSegment" => Some(STRUCT_TYPE_SEGMENT.clone()),
            "StructureKeywordSegment" => Some(STRUCTURE_KEYWORD_SEGMENT.clone()),
            "StyleKeywordSegment" => Some(STYLE_KEYWORD_SEGMENT.clone()),
            "Subclass_originKeywordSegment" => Some(SUBCLASS_ORIGIN_KEYWORD_SEGMENT.clone()),
            "SublistKeywordSegment" => Some(SUBLIST_KEYWORD_SEGMENT.clone()),
            "SubmultisetKeywordSegment" => Some(SUBMULTISET_KEYWORD_SEGMENT.clone()),
            "SubsetKeywordSegment" => Some(SUBSET_KEYWORD_SEGMENT.clone()),
            "SubstringKeywordSegment" => Some(SUBSTRING_KEYWORD_SEGMENT.clone()),
            "Substring_regexKeywordSegment" => Some(SUBSTRING_REGEX_KEYWORD_SEGMENT.clone()),
            "SucceedsKeywordSegment" => Some(SUCCEEDS_KEYWORD_SEGMENT.clone()),
            "SuccessfulKeywordSegment" => Some(SUCCESSFUL_KEYWORD_SEGMENT.clone()),
            "SumKeywordSegment" => Some(SUM_KEYWORD_SEGMENT.clone()),
            "SummaryKeywordSegment" => Some(SUMMARY_KEYWORD_SEGMENT.clone()),
            "SuperuserKeywordSegment" => Some(SUPERUSER_KEYWORD_SEGMENT.clone()),
            "SymbolKeywordSegment" => Some(SYMBOL_KEYWORD_SEGMENT.clone()),
            "SymbolSegment" => Some(SYMBOL_SEGMENT.clone()),
            "SymmetricKeywordSegment" => Some(SYMMETRIC_KEYWORD_SEGMENT.clone()),
            "SyncKeywordSegment" => Some(SYNC_KEYWORD_SEGMENT.clone()),
            "SynonymKeywordSegment" => Some(SYNONYM_KEYWORD_SEGMENT.clone()),
            "SysdateKeywordSegment" => Some(SYSDATE_KEYWORD_SEGMENT.clone()),
            "SysidKeywordSegment" => Some(SYSID_KEYWORD_SEGMENT.clone()),
            "SystemKeywordSegment" => Some(SYSTEM_KEYWORD_SEGMENT.clone()),
            "System_timeKeywordSegment" => Some(SYSTEM_TIME_KEYWORD_SEGMENT.clone()),
            "System_userKeywordSegment" => Some(SYSTEM_USER_KEYWORD_SEGMENT.clone()),
            "System_versionKeywordSegment" => Some(SYSTEM_VERSION_KEYWORD_SEGMENT.clone()),
            "TableConstraintSegment" => Some(TABLE_CONSTRAINT_SEGMENT.clone()),
            "TableEndClauseSegment" => Some(TABLE_END_CLAUSE_SEGMENT.clone()),
            "TableExpressionSegment" => Some(TABLE_EXPRESSION_SEGMENT.clone()),
            "TableKeywordSegment" => Some(TABLE_KEYWORD_SEGMENT.clone()),
            "TablePropertiesGrammar" => Some(TABLE_PROPERTIES_GRAMMAR.clone()),
            "TableReferenceSegment" => Some(TABLE_REFERENCE_SEGMENT.clone()),
            "Table_nameKeywordSegment" => Some(TABLE_NAME_KEYWORD_SEGMENT.clone()),
            "TablesKeywordSegment" => Some(TABLES_KEYWORD_SEGMENT.clone()),
            "TablesampleKeywordSegment" => Some(TABLESAMPLE_KEYWORD_SEGMENT.clone()),
            "TablespaceKeywordSegment" => Some(TABLESPACE_KEYWORD_SEGMENT.clone()),
            "TablespaceReferenceSegment" => Some(TABLESPACE_REFERENCE_SEGMENT.clone()),
            "TagReferenceSegment" => Some(TAG_REFERENCE_SEGMENT.clone()),
            "Tail_Recurse_Expression_A_Grammar" => Some(TAIL_RECURSE_EXPRESSION_A_GRAMMAR.clone()),
            "Tail_Recurse_Expression_B_Grammar" => Some(TAIL_RECURSE_EXPRESSION_B_GRAMMAR.clone()),
            "TaskKeywordSegment" => Some(TASK_KEYWORD_SEGMENT.clone()),
            "TasksKeywordSegment" => Some(TASKS_KEYWORD_SEGMENT.clone()),
            "TblpropertiesKeywordSegment" => Some(TBLPROPERTIES_KEYWORD_SEGMENT.clone()),
            "TempKeywordSegment" => Some(TEMP_KEYWORD_SEGMENT.clone()),
            "TemplateKeywordSegment" => Some(TEMPLATE_KEYWORD_SEGMENT.clone()),
            "TemporalQuerySegment" => Some(TEMPORAL_QUERY_SEGMENT.clone()),
            "TemporaryGrammar" => Some(TEMPORARY_GRAMMAR.clone()),
            "TemporaryKeywordSegment" => Some(TEMPORARY_KEYWORD_SEGMENT.clone()),
            "TemporaryTransientGrammar" => Some(TEMPORARY_TRANSIENT_GRAMMAR.clone()),
            "TerminateKeywordSegment" => Some(TERMINATE_KEYWORD_SEGMENT.clone()),
            "TerminatedByGrammar" => Some(TERMINATED_BY_GRAMMAR.clone()),
            "TerminatedKeywordSegment" => Some(TERMINATED_KEYWORD_SEGMENT.clone()),
            "TextKeywordSegment" => Some(TEXT_KEYWORD_SEGMENT.clone()),
            "TextfileKeywordSegment" => Some(TEXTFILE_KEYWORD_SEGMENT.clone()),
            "TextsizeKeywordSegment" => Some(TEXTSIZE_KEYWORD_SEGMENT.clone()),
            "ThanKeywordSegment" => Some(THAN_KEYWORD_SEGMENT.clone()),
            "ThenKeywordSegment" => Some(THEN_KEYWORD_SEGMENT.clone()),
            "TiesKeywordSegment" => Some(TIES_KEYWORD_SEGMENT.clone()),
            "TildeSegment" => Some(TILDE_SEGMENT.clone()),
            "TimeKeywordSegment" => Some(TIME_KEYWORD_SEGMENT.clone()),
            "TimeWithTZGrammar" => Some(TIME_WITH_T_Z_GRAMMAR.clone()),
            "TimeZoneGrammar" => Some(TIME_ZONE_GRAMMAR.clone()),
            "TimestampKeywordSegment" => Some(TIMESTAMP_KEYWORD_SEGMENT.clone()),
            "TimestamptzKeywordSegment" => Some(TIMESTAMPTZ_KEYWORD_SEGMENT.clone()),
            "Timezone_hourKeywordSegment" => Some(TIMEZONE_HOUR_KEYWORD_SEGMENT.clone()),
            "Timezone_minuteKeywordSegment" => Some(TIMEZONE_MINUTE_KEYWORD_SEGMENT.clone()),
            "TinyblobKeywordSegment" => Some(TINYBLOB_KEYWORD_SEGMENT.clone()),
            "TinyintKeywordSegment" => Some(TINYINT_KEYWORD_SEGMENT.clone()),
            "TinytextKeywordSegment" => Some(TINYTEXT_KEYWORD_SEGMENT.clone()),
            "ToKeywordSegment" => Some(TO_KEYWORD_SEGMENT.clone()),
            "ToastKeywordSegment" => Some(TOAST_KEYWORD_SEGMENT.clone()),
            "TopKeywordSegment" => Some(TOP_KEYWORD_SEGMENT.clone()),
            "Top_level_countKeywordSegment" => Some(TOP_LEVEL_COUNT_KEYWORD_SEGMENT.clone()),
            "TouchKeywordSegment" => Some(TOUCH_KEYWORD_SEGMENT.clone()),
            "TrailingKeywordSegment" => Some(TRAILING_KEYWORD_SEGMENT.clone()),
            "TranKeywordSegment" => Some(TRAN_KEYWORD_SEGMENT.clone()),
            "TransactionKeywordSegment" => Some(TRANSACTION_KEYWORD_SEGMENT.clone()),
            "TransactionStatementSegment" => Some(TRANSACTION_STATEMENT_SEGMENT.clone()),
            "Transaction_activeKeywordSegment" => Some(TRANSACTION_ACTIVE_KEYWORD_SEGMENT.clone()),
            "TransactionsKeywordSegment" => Some(TRANSACTIONS_KEYWORD_SEGMENT.clone()),
            "Transactions_committedKeywordSegment" => Some(TRANSACTIONS_COMMITTED_KEYWORD_SEGMENT.clone()),
            "Transactions_rolled_backKeywordSegment" => Some(TRANSACTIONS_ROLLED_BACK_KEYWORD_SEGMENT.clone()),
            "TransformKeywordSegment" => Some(TRANSFORM_KEYWORD_SEGMENT.clone()),
            "TransformsKeywordSegment" => Some(TRANSFORMS_KEYWORD_SEGMENT.clone()),
            "TransientKeywordSegment" => Some(TRANSIENT_KEYWORD_SEGMENT.clone()),
            "TranslateKeywordSegment" => Some(TRANSLATE_KEYWORD_SEGMENT.clone()),
            "Translate_regexKeywordSegment" => Some(TRANSLATE_REGEX_KEYWORD_SEGMENT.clone()),
            "TranslationKeywordSegment" => Some(TRANSLATION_KEYWORD_SEGMENT.clone()),
            "TreatKeywordSegment" => Some(TREAT_KEYWORD_SEGMENT.clone()),
            "TriggerKeywordSegment" => Some(TRIGGER_KEYWORD_SEGMENT.clone()),
            "TriggerReferenceSegment" => Some(TRIGGER_REFERENCE_SEGMENT.clone()),
            "Trigger_catalogKeywordSegment" => Some(TRIGGER_CATALOG_KEYWORD_SEGMENT.clone()),
            "Trigger_nameKeywordSegment" => Some(TRIGGER_NAME_KEYWORD_SEGMENT.clone()),
            "Trigger_schemaKeywordSegment" => Some(TRIGGER_SCHEMA_KEYWORD_SEGMENT.clone()),
            "TrimKeywordSegment" => Some(TRIM_KEYWORD_SEGMENT.clone()),
            "TrimParametersGrammar" => Some(TRIM_PARAMETERS_GRAMMAR.clone()),
            "Trim_arrayKeywordSegment" => Some(TRIM_ARRAY_KEYWORD_SEGMENT.clone()),
            "TrueKeywordSegment" => Some(TRUE_KEYWORD_SEGMENT.clone()),
            "TrueSegment" => Some(TRUE_SEGMENT.clone()),
            "TruncateKeywordSegment" => Some(TRUNCATE_KEYWORD_SEGMENT.clone()),
            "TruncateStatementSegment" => Some(TRUNCATE_STATEMENT_SEGMENT.clone()),
            "TrustedKeywordSegment" => Some(TRUSTED_KEYWORD_SEGMENT.clone()),
            "TsequalKeywordSegment" => Some(TSEQUAL_KEYWORD_SEGMENT.clone()),
            "TupleSegment" => Some(TUPLE_SEGMENT.clone()),
            "TypeKeywordSegment" => Some(TYPE_KEYWORD_SEGMENT.clone()),
            "TypedArrayLiteralSegment" => Some(TYPED_ARRAY_LITERAL_SEGMENT.clone()),
            "TypedStructLiteralSegment" => Some(TYPED_STRUCT_LITERAL_SEGMENT.clone()),
            "UescapeKeywordSegment" => Some(UESCAPE_KEYWORD_SEGMENT.clone()),
            "UidKeywordSegment" => Some(UID_KEYWORD_SEGMENT.clone()),
            "UnarchiveKeywordSegment" => Some(UNARCHIVE_KEYWORD_SEGMENT.clone()),
            "UnboundedKeywordSegment" => Some(UNBOUNDED_KEYWORD_SEGMENT.clone()),
            "UncachedKeywordSegment" => Some(UNCACHED_KEYWORD_SEGMENT.clone()),
            "UncommittedKeywordSegment" => Some(UNCOMMITTED_KEYWORD_SEGMENT.clone()),
            "UnconditionalCrossJoinKeywordsGrammar" => Some(UNCONDITIONAL_CROSS_JOIN_KEYWORDS_GRAMMAR.clone()),
            "UnconditionalJoinKeywordsGrammar" => Some(UNCONDITIONAL_JOIN_KEYWORDS_GRAMMAR.clone()),
            "UnderKeywordSegment" => Some(UNDER_KEYWORD_SEGMENT.clone()),
            "UndoKeywordSegment" => Some(UNDO_KEYWORD_SEGMENT.clone()),
            "UnencryptedKeywordSegment" => Some(UNENCRYPTED_KEYWORD_SEGMENT.clone()),
            "UnionGrammar" => Some(UNION_GRAMMAR.clone()),
            "UnionKeywordSegment" => Some(UNION_KEYWORD_SEGMENT.clone()),
            "UniontypeKeywordSegment" => Some(UNIONTYPE_KEYWORD_SEGMENT.clone()),
            "UniqueKeyGrammar" => Some(UNIQUE_KEY_GRAMMAR.clone()),
            "UniqueKeywordSegment" => Some(UNIQUE_KEYWORD_SEGMENT.clone()),
            "UniquejoinKeywordSegment" => Some(UNIQUEJOIN_KEYWORD_SEGMENT.clone()),
            "UnknownKeywordSegment" => Some(UNKNOWN_KEYWORD_SEGMENT.clone()),
            "UnknownLiteralSegment" => Some(UNKNOWN_LITERAL_SEGMENT.clone()),
            "UnlistenKeywordSegment" => Some(UNLISTEN_KEYWORD_SEGMENT.clone()),
            "UnlockKeywordSegment" => Some(UNLOCK_KEYWORD_SEGMENT.clone()),
            "UnnamedKeywordSegment" => Some(UNNAMED_KEYWORD_SEGMENT.clone()),
            "UnnestKeywordSegment" => Some(UNNEST_KEYWORD_SEGMENT.clone()),
            "UnorderedSelectStatementSegment" => Some(UNORDERED_SELECT_STATEMENT_SEGMENT.clone()),
            "UnorderedSetExpressionSegment" => Some(UNORDERED_SET_EXPRESSION_SEGMENT.clone()),
            "UnsetKeywordSegment" => Some(UNSET_KEYWORD_SEGMENT.clone()),
            "UnsignedKeywordSegment" => Some(UNSIGNED_KEYWORD_SEGMENT.clone()),
            "UntilKeywordSegment" => Some(UNTIL_KEYWORD_SEGMENT.clone()),
            "UpdateKeywordSegment" => Some(UPDATE_KEYWORD_SEGMENT.clone()),
            "UpdateStatementSegment" => Some(UPDATE_STATEMENT_SEGMENT.clone()),
            "Update_fnKeywordSegment" => Some(UPDATE_FN_KEYWORD_SEGMENT.clone()),
            "UpdatetextKeywordSegment" => Some(UPDATETEXT_KEYWORD_SEGMENT.clone()),
            "UpperKeywordSegment" => Some(UPPER_KEYWORD_SEGMENT.clone()),
            "UpsertKeywordSegment" => Some(UPSERT_KEYWORD_SEGMENT.clone()),
            "UriKeywordSegment" => Some(URI_KEYWORD_SEGMENT.clone()),
            "UsageKeywordSegment" => Some(USAGE_KEYWORD_SEGMENT.clone()),
            "UseKeywordSegment" => Some(USE_KEYWORD_SEGMENT.clone()),
            "UseStatementSegment" => Some(USE_STATEMENT_SEGMENT.clone()),
            "Use_any_roleKeywordSegment" => Some(USE_ANY_ROLE_KEYWORD_SEGMENT.clone()),
            "UserKeywordSegment" => Some(USER_KEYWORD_SEGMENT.clone()),
            "User_defined_fnKeywordSegment" => Some(USER_DEFINED_FN_KEYWORD_SEGMENT.clone()),
            "User_defined_type_catalogKeywordSegment" => Some(USER_DEFINED_TYPE_CATALOG_KEYWORD_SEGMENT.clone()),
            "User_defined_type_codeKeywordSegment" => Some(USER_DEFINED_TYPE_CODE_KEYWORD_SEGMENT.clone()),
            "User_defined_type_nameKeywordSegment" => Some(USER_DEFINED_TYPE_NAME_KEYWORD_SEGMENT.clone()),
            "User_defined_type_schemaKeywordSegment" => Some(USER_DEFINED_TYPE_SCHEMA_KEYWORD_SEGMENT.clone()),
            "UsersKeywordSegment" => Some(USERS_KEYWORD_SEGMENT.clone()),
            "UsingKeywordSegment" => Some(USING_KEYWORD_SEGMENT.clone()),
            "UtcKeywordSegment" => Some(UTC_KEYWORD_SEGMENT.clone()),
            "Utc_dateKeywordSegment" => Some(UTC_DATE_KEYWORD_SEGMENT.clone()),
            "Utc_timeKeywordSegment" => Some(UTC_TIME_KEYWORD_SEGMENT.clone()),
            "Utc_timestampKeywordSegment" => Some(UTC_TIMESTAMP_KEYWORD_SEGMENT.clone()),
            "Utc_tmestampKeywordSegment" => Some(UTC_TMESTAMP_KEYWORD_SEGMENT.clone()),
            "UtctimestampKeywordSegment" => Some(UTCTIMESTAMP_KEYWORD_SEGMENT.clone()),
            "VacuumKeywordSegment" => Some(VACUUM_KEYWORD_SEGMENT.clone()),
            "ValidKeywordSegment" => Some(VALID_KEYWORD_SEGMENT.clone()),
            "ValidateKeywordSegment" => Some(VALIDATE_KEYWORD_SEGMENT.clone()),
            "ValidatorKeywordSegment" => Some(VALIDATOR_KEYWORD_SEGMENT.clone()),
            "ValueKeywordSegment" => Some(VALUE_KEYWORD_SEGMENT.clone()),
            "Value_ofKeywordSegment" => Some(VALUE_OF_KEYWORD_SEGMENT.clone()),
            "Value_typeKeywordSegment" => Some(VALUE_TYPE_KEYWORD_SEGMENT.clone()),
            "ValuesClauseSegment" => Some(VALUES_CLAUSE_SEGMENT.clone()),
            "ValuesKeywordSegment" => Some(VALUES_KEYWORD_SEGMENT.clone()),
            "Var_popKeywordSegment" => Some(VAR_POP_KEYWORD_SEGMENT.clone()),
            "Var_sampKeywordSegment" => Some(VAR_SAMP_KEYWORD_SEGMENT.clone()),
            "VarbinaryKeywordSegment" => Some(VARBINARY_KEYWORD_SEGMENT.clone()),
            "Varchar2KeywordSegment" => Some(VARCHAR2_KEYWORD_SEGMENT.clone()),
            "VarcharKeywordSegment" => Some(VARCHAR_KEYWORD_SEGMENT.clone()),
            "VarcharacterKeywordSegment" => Some(VARCHARACTER_KEYWORD_SEGMENT.clone()),
            "VariableKeywordSegment" => Some(VARIABLE_KEYWORD_SEGMENT.clone()),
            "VariablesKeywordSegment" => Some(VARIABLES_KEYWORD_SEGMENT.clone()),
            "VaryingKeywordSegment" => Some(VARYING_KEYWORD_SEGMENT.clone()),
            "VectorizationKeywordSegment" => Some(VECTORIZATION_KEYWORD_SEGMENT.clone()),
            "VerboseKeywordSegment" => Some(VERBOSE_KEYWORD_SEGMENT.clone()),
            "VersionKeywordSegment" => Some(VERSION_KEYWORD_SEGMENT.clone()),
            "VersioningKeywordSegment" => Some(VERSIONING_KEYWORD_SEGMENT.clone()),
            "ViewKeywordSegment" => Some(VIEW_KEYWORD_SEGMENT.clone()),
            "ViewsKeywordSegment" => Some(VIEWS_KEYWORD_SEGMENT.clone()),
            "VolatileKeywordSegment" => Some(VOLATILE_KEYWORD_SEGMENT.clone()),
            "WaitforKeywordSegment" => Some(WAITFOR_KEYWORD_SEGMENT.clone()),
            "WarehouseKeywordSegment" => Some(WAREHOUSE_KEYWORD_SEGMENT.clone()),
            "WarehousesKeywordSegment" => Some(WAREHOUSES_KEYWORD_SEGMENT.clone()),
            "WeekKeywordSegment" => Some(WEEK_KEYWORD_SEGMENT.clone()),
            "WeekdayKeywordSegment" => Some(WEEKDAY_KEYWORD_SEGMENT.clone()),
            "WeeksKeywordSegment" => Some(WEEKS_KEYWORD_SEGMENT.clone()),
            "WhenClauseSegment" => Some(WHEN_CLAUSE_SEGMENT.clone()),
            "WhenKeywordSegment" => Some(WHEN_KEYWORD_SEGMENT.clone()),
            "WheneverKeywordSegment" => Some(WHENEVER_KEYWORD_SEGMENT.clone()),
            "WhereClauseSegment" => Some(WHERE_CLAUSE_SEGMENT.clone()),
            "WhereClauseTerminatorGrammar" => Some(WHERE_CLAUSE_TERMINATOR_GRAMMAR.clone()),
            "WhereKeywordSegment" => Some(WHERE_KEYWORD_SEGMENT.clone()),
            "WhileKeywordSegment" => Some(WHILE_KEYWORD_SEGMENT.clone()),
            "WhitespaceSegment" => Some(WHITESPACE_SEGMENT.clone()),
            "Width_bucketKeywordSegment" => Some(WIDTH_BUCKET_KEYWORD_SEGMENT.clone()),
            "WildcardExpressionSegment" => Some(WILDCARD_EXPRESSION_SEGMENT.clone()),
            "WildcardIdentifierSegment" => Some(WILDCARD_IDENTIFIER_SEGMENT.clone()),
            "WindowKeywordSegment" => Some(WINDOW_KEYWORD_SEGMENT.clone()),
            "WindowSpecificationSegment" => Some(WINDOW_SPECIFICATION_SEGMENT.clone()),
            "WithCompoundNonSelectStatementSegment" => Some(WITH_COMPOUND_NON_SELECT_STATEMENT_SEGMENT.clone()),
            "WithCompoundStatementSegment" => Some(WITH_COMPOUND_STATEMENT_SEGMENT.clone()),
            "WithDataClauseSegment" => Some(WITH_DATA_CLAUSE_SEGMENT.clone()),
            "WithFillSegment" => Some(WITH_FILL_SEGMENT.clone()),
            "WithKeywordSegment" => Some(WITH_KEYWORD_SEGMENT.clone()),
            "WithNoSchemaBindingClauseSegment" => Some(WITH_NO_SCHEMA_BINDING_CLAUSE_SEGMENT.clone()),
            "WithinKeywordSegment" => Some(WITHIN_KEYWORD_SEGMENT.clone()),
            "WithoutKeywordSegment" => Some(WITHOUT_KEYWORD_SEGMENT.clone()),
            "WordSegment" => Some(WORD_SEGMENT.clone()),
            "WorkKeywordSegment" => Some(WORK_KEYWORD_SEGMENT.clone()),
            "WrapperKeywordSegment" => Some(WRAPPER_KEYWORD_SEGMENT.clone()),
            "WriteKeywordSegment" => Some(WRITE_KEYWORD_SEGMENT.clone()),
            "WritetextKeywordSegment" => Some(WRITETEXT_KEYWORD_SEGMENT.clone()),
            "X509KeywordSegment" => Some(X509_KEYWORD_SEGMENT.clone()),
            "XmlKeywordSegment" => Some(XML_KEYWORD_SEGMENT.clone()),
            "XorKeywordSegment" => Some(XOR_KEYWORD_SEGMENT.clone()),
            "YamlKeywordSegment" => Some(YAML_KEYWORD_SEGMENT.clone()),
            "YearKeywordSegment" => Some(YEAR_KEYWORD_SEGMENT.clone()),
            "Year_monthKeywordSegment" => Some(YEAR_MONTH_KEYWORD_SEGMENT.clone()),
            "YearsKeywordSegment" => Some(YEARS_KEYWORD_SEGMENT.clone()),
            "ZerofillKeywordSegment" => Some(ZEROFILL_KEYWORD_SEGMENT.clone()),
            "ZoneKeywordSegment" => Some(ZONE_KEYWORD_SEGMENT.clone()),
            "ZorderKeywordSegment" => Some(ZORDER_KEYWORD_SEGMENT.clone()),
            _ => None,
    }
}

pub fn get_impala_segment_type(name: &str) -> Option<&'static str> {
    match name {
            "AccessStatementSegment" => Some("access_statement"),
            "AggregateOrderByClause" => Some("aggregate_order_by"),
            "AliasExpressionSegment" => Some("alias_expression"),
            "AlterDatabaseStatementSegment" => Some("alter_database_statement"),
            "AlterSequenceOptionsSegment" => Some("alter_sequence_options_segment"),
            "AlterSequenceStatementSegment" => Some("alter_sequence_statement"),
            "AlterTableStatementSegment" => Some("alter_table_statement"),
            "AlterViewStatementSegment" => Some("alter_view_statement"),
            "ArrayAccessorSegment" => Some("array_accessor"),
            "ArrayExpressionSegment" => Some("array_expression"),
            "ArrayLiteralSegment" => Some("array_literal"),
            "ArrayTypeSegment" => Some("array_type"),
            "AsAliasOperatorSegment" => Some("alias_operator"),
            "BaseFileSegment" => Some("file"),
            "BaseSegment" => Some("base"),
            "BinaryOperatorSegment" => Some("binary_operator"),
            "BitwiseAndSegment" => Some("binary_operator"),
            "BitwiseLShiftSegment" => Some("binary_operator"),
            "BitwiseOrSegment" => Some("binary_operator"),
            "BitwiseRShiftSegment" => Some("binary_operator"),
            "BracketedArguments" => Some("bracketed_arguments"),
            "BracketedSegment" => Some("bracketed"),
            "CTEColumnList" => Some("cte_column_list"),
            "CTEDefinitionSegment" => Some("common_table_expression"),
            "CaseExpressionSegment" => Some("case_expression"),
            "ClusterByClauseSegment" => Some("clusterby_clause"),
            "CodeSegment" => Some("raw"),
            "CollationReferenceSegment" => Some("collation_reference"),
            "ColumnConstraintSegment" => Some("column_constraint_segment"),
            "ColumnDefinitionSegment" => Some("column_definition"),
            "ColumnReferenceSegment" => Some("column_reference"),
            "ColumnsExpressionFunctionContentsSegment" => Some("columns_expression"),
            "ColumnsExpressionFunctionNameSegment" => Some("function_name"),
            "CommentClauseSegment" => Some("comment_clause"),
            "CommentSegment" => Some("comment"),
            "ComparisonOperatorSegment" => Some("comparison_operator"),
            "CompositeBinaryOperatorSegment" => Some("binary_operator"),
            "CompositeComparisonOperatorSegment" => Some("comparison_operator"),
            "ComputeStatsStatementSegment" => Some("compute_stats_statement"),
            "ConcatSegment" => Some("binary_operator"),
            "CreateCastStatementSegment" => Some("create_cast_statement"),
            "CreateDatabaseStatementSegment" => Some("create_database_statement"),
            "CreateFunctionStatementSegment" => Some("create_function_statement"),
            "CreateIndexStatementSegment" => Some("create_index_statement"),
            "CreateModelStatementSegment" => Some("create_model_statement"),
            "CreateRoleStatementSegment" => Some("create_role_statement"),
            "CreateSchemaStatementSegment" => Some("create_schema_statement"),
            "CreateSequenceOptionsSegment" => Some("create_sequence_options_segment"),
            "CreateSequenceStatementSegment" => Some("create_sequence_statement"),
            "CreateTableAsSelectStatementSegment" => Some("create_table_as_select_statement"),
            "CreateTableStatementSegment" => Some("create_table_statement"),
            "CreateTriggerStatementSegment" => Some("create_trigger"),
            "CreateUserStatementSegment" => Some("create_user_statement"),
            "CreateViewStatementSegment" => Some("create_view_statement"),
            "CubeFunctionNameSegment" => Some("function_name"),
            "CubeRollupClauseSegment" => Some("cube_rollup_clause"),
            "DatabaseReferenceSegment" => Some("database_reference"),
            "DatatypeSegment" => Some("data_type"),
            "DatePartFunctionNameSegment" => Some("function_name"),
            "DateTimeFunctionContentsSegment" => Some("function_contents"),
            "Dedent" => Some("dedent"),
            "DeleteStatementSegment" => Some("delete_statement"),
            "DescribeStatementSegment" => Some("describe_statement"),
            "DistributeByClauseSegment" => Some("distributeby_clause"),
            "DropCastStatementSegment" => Some("drop_cast_statement"),
            "DropDatabaseStatementSegment" => Some("drop_database_statement"),
            "DropFunctionStatementSegment" => Some("drop_function_statement"),
            "DropIndexStatementSegment" => Some("drop_index_statement"),
            "DropModelStatementSegment" => Some("drop_MODELstatement"),
            "DropRoleStatementSegment" => Some("drop_role_statement"),
            "DropSchemaStatementSegment" => Some("drop_schema_statement"),
            "DropSequenceStatementSegment" => Some("drop_sequence_statement"),
            "DropTableStatementSegment" => Some("drop_table_statement"),
            "DropTriggerStatementSegment" => Some("drop_trigger"),
            "DropTypeStatementSegment" => Some("drop_type_statement"),
            "DropUserStatementSegment" => Some("drop_user_statement"),
            "DropViewStatementSegment" => Some("drop_view_statement"),
            "ElseClauseSegment" => Some("else_clause"),
            "EmptyStructLiteralBracketsSegment" => Some("struct_literal"),
            "EmptyStructLiteralSegment" => Some("typed_struct_literal"),
            "EqualsSegment" => Some("comparison_operator"),
            "ExplainStatementSegment" => Some("explain_statement"),
            "ExpressionSegment" => Some("expression"),
            "ExtensionReferenceSegment" => Some("extension_reference"),
            "FetchClauseSegment" => Some("fetch_clause"),
            "FileSegment" => Some("file"),
            "FrameClauseSegment" => Some("frame_clause"),
            "FromClauseSegment" => Some("from_clause"),
            "FromExpressionElementSegment" => Some("from_expression_element"),
            "FromExpressionSegment" => Some("from_expression"),
            "FunctionContentsSegment" => Some("function_contents"),
            "FunctionDefinitionGrammar" => Some("function_definition"),
            "FunctionNameSegment" => Some("function_name"),
            "FunctionParameterListGrammar" => Some("function_parameter_list"),
            "FunctionSegment" => Some("function"),
            "GreaterThanOrEqualToSegment" => Some("comparison_operator"),
            "GreaterThanSegment" => Some("comparison_operator"),
            "GroupByClauseSegment" => Some("groupby_clause"),
            "GroupingExpressionList" => Some("grouping_expression_list"),
            "GroupingSetsClauseSegment" => Some("grouping_sets_clause"),
            "HavingClauseSegment" => Some("having_clause"),
            "IdentifierSegment" => Some("identifier"),
            "ImplicitIndent" => Some("indent"),
            "Indent" => Some("indent"),
            "IndexColumnDefinitionSegment" => Some("index_column_definition"),
            "IndexReferenceSegment" => Some("index_reference"),
            "InsertStatementSegment" => Some("insert_statement"),
            "IntervalExpressionSegment" => Some("interval_expression"),
            "JoinClauseSegment" => Some("join_clause"),
            "JoinOnConditionSegment" => Some("join_on_condition"),
            "KeywordSegment" => Some("keyword"),
            "LateralViewClauseSegment" => Some("lateral_view_clause"),
            "LessThanOrEqualToSegment" => Some("comparison_operator"),
            "LessThanSegment" => Some("comparison_operator"),
            "LimitClauseSegment" => Some("limit_clause"),
            "LiteralKeywordSegment" => Some("literal"),
            "LiteralSegment" => Some("literal"),
            "LocalAliasSegment" => Some("local_alias_segment"),
            "MLTableExpressionSegment" => Some("ml_table_expression"),
            "MapTypeSegment" => Some("map_type"),
            "MatchConditionSegment" => Some("match_condition"),
            "MergeDeleteClauseSegment" => Some("merge_delete_clause"),
            "MergeInsertClauseSegment" => Some("merge_insert_clause"),
            "MergeMatchSegment" => Some("merge_match"),
            "MergeMatchedClauseSegment" => Some("merge_when_matched_clause"),
            "MergeNotMatchedClauseSegment" => Some("merge_when_not_matched_clause"),
            "MergeStatementSegment" => Some("merge_statement"),
            "MergeUpdateClauseSegment" => Some("merge_update_clause"),
            "MsckRepairTableStatementSegment" => Some("msck_repair_table_statement"),
            "MsckTableStatementSegment" => Some("msck_table_statement"),
            "NamedWindowExpressionSegment" => Some("named_window_expression"),
            "NamedWindowSegment" => Some("named_window"),
            "NewlineSegment" => Some("newline"),
            "NotEqualToSegment" => Some("comparison_operator"),
            "ObjectLiteralElementSegment" => Some("object_literal_element"),
            "ObjectLiteralSegment" => Some("object_literal"),
            "ObjectReferenceSegment" => Some("object_reference"),
            "OffsetClauseSegment" => Some("offset_clause"),
            "OrderByClauseSegment" => Some("orderby_clause"),
            "OverClauseSegment" => Some("over_clause"),
            "OverlapsClauseSegment" => Some("overlaps_clause"),
            "PartitionClauseSegment" => Some("partitionby_clause"),
            "PathSegment" => Some("path_segment"),
            "PrimitiveTypeSegment" => Some("primitive_type"),
            "QualifiedNumericLiteralSegment" => Some("numeric_literal"),
            "RawSegment" => Some("raw"),
            "RoleReferenceSegment" => Some("role_reference"),
            "RollupFunctionNameSegment" => Some("function_name"),
            "RowFormatClauseSegment" => Some("row_format_clause"),
            "RowFunctionContentsSegment" => Some("function_contents"),
            "SamplingExpressionSegment" => Some("sample_expression"),
            "SchemaReferenceSegment" => Some("schema_reference"),
            "SelectClauseElementSegment" => Some("select_clause_element"),
            "SelectClauseModifierSegment" => Some("select_clause_modifier"),
            "SelectClauseSegment" => Some("select_clause"),
            "SelectStatementSegment" => Some("select_statement"),
            "SequenceReferenceSegment" => Some("sequence_reference"),
            "SetClauseListSegment" => Some("set_clause_list"),
            "SetClauseSegment" => Some("set_clause"),
            "SetExpressionSegment" => Some("set_expression"),
            "SetOperatorSegment" => Some("set_operator"),
            "SetSchemaStatementSegment" => Some("set_schema_statement"),
            "SetStatementSegment" => Some("set_statement"),
            "ShorthandCastSegment" => Some("cast_expression"),
            "SingleIdentifierListSegment" => Some("identifier_list"),
            "SizedArrayTypeSegment" => Some("sized_array_type"),
            "SkewedByClauseSegment" => Some("skewed_by_clause"),
            "SortByClauseSegment" => Some("sortby_clause"),
            "StatementSegment" => Some("statement"),
            "StructLiteralSegment" => Some("struct_literal"),
            "StructTypeSchemaSegment" => Some("struct_type_schema"),
            "StructTypeSegment" => Some("struct_type"),
            "SymbolSegment" => Some("symbol"),
            "TableConstraintSegment" => Some("table_constraint"),
            "TableEndClauseSegment" => Some("table_end_clause_segment"),
            "TableExpressionSegment" => Some("table_expression"),
            "TableReferenceSegment" => Some("table_reference"),
            "TablespaceReferenceSegment" => Some("tablespace_reference"),
            "TagReferenceSegment" => Some("tag_reference"),
            "TemporalQuerySegment" => Some("temporal_query"),
            "TimeZoneGrammar" => Some("time_zone_grammar"),
            "TransactionStatementSegment" => Some("transaction_statement"),
            "TriggerReferenceSegment" => Some("trigger_reference"),
            "TruncateStatementSegment" => Some("truncate_table"),
            "TupleSegment" => Some("tuple"),
            "TypedArrayLiteralSegment" => Some("typed_array_literal"),
            "TypedStructLiteralSegment" => Some("typed_struct_literal"),
            "UnorderedSelectStatementSegment" => Some("select_statement"),
            "UnorderedSetExpressionSegment" => Some("set_expression"),
            "UpdateStatementSegment" => Some("update_statement"),
            "UseStatementSegment" => Some("use_statement"),
            "ValuesClauseSegment" => Some("values_clause"),
            "WhenClauseSegment" => Some("when_clause"),
            "WhereClauseSegment" => Some("where_clause"),
            "WhitespaceSegment" => Some("whitespace"),
            "WildcardExpressionSegment" => Some("wildcard_expression"),
            "WildcardIdentifierSegment" => Some("wildcard_identifier"),
            "WindowSpecificationSegment" => Some("window_specification"),
            "WithCompoundNonSelectStatementSegment" => Some("with_compound_statement"),
            "WithCompoundStatementSegment" => Some("with_compound_statement"),
            "WithDataClauseSegment" => Some("with_data_clause"),
            "WithFillSegment" => Some("with_fill"),
            "WithNoSchemaBindingClauseSegment" => Some("with_no_schema_binding_clause"),
            "WordSegment" => Some("word"),
            _ => None,
    }
}

pub fn get_impala_root_grammar() -> Arc<Grammar> {
    get_impala_segment_grammar(
        "FileSegment"
    ).expect("Root grammar missing.")
}
