/* This is a generated file! */
use once_cell::sync::Lazy;
use uuid::Uuid;
use crate::matcher::{LexMatcher, extract_nested_block_comment};
use crate::token::Token;
use crate::regex::RegexModeGroup;
use crate::dialect::Dialect;

pub static REDSHIFT_KEYWORDS: Lazy<Vec<String>> = Lazy::new(|| { vec![
    "AES128".to_string(),
    "AES256".to_string(),
    "ALL".to_string(),
    "ALLOWOVERWRITE".to_string(),
    "ANALYSE".to_string(),
    "ANALYZE".to_string(),
    "AND".to_string(),
    "ANY".to_string(),
    "APPEND".to_string(),
    "ARRAY".to_string(),
    "AS".to_string(),
    "ASC".to_string(),
    "AUTHORIZATION".to_string(),
    "AZ64".to_string(),
    "BETWEEN".to_string(),
    "BINARY".to_string(),
    "BLANKSASNULL".to_string(),
    "BOTH".to_string(),
    "BYTEDICT".to_string(),
    "CASE".to_string(),
    "CAST".to_string(),
    "CHECK".to_string(),
    "COLLATE".to_string(),
    "COLUMN".to_string(),
    "COMPROWS".to_string(),
    "COMPUPDATE".to_string(),
    "CONSTRAINT".to_string(),
    "CREATE".to_string(),
    "CREDENTIALS".to_string(),
    "CROSS".to_string(),
    "CURRENT_DATE".to_string(),
    "CURRENT_TIME".to_string(),
    "CURRENT_TIMESTAMP".to_string(),
    "CURRENT_USER".to_string(),
    "CURRENT_USER_ID".to_string(),
    "DATETIME".to_string(),
    "DEFAULT".to_string(),
    "DEFERRABLE".to_string(),
    "DEFRAG".to_string(),
    "DELIMITERS".to_string(),
    "DELTA".to_string(),
    "DELTA32K".to_string(),
    "DESC".to_string(),
    "DISABLE".to_string(),
    "DISTINCT".to_string(),
    "DO".to_string(),
    "ELSE".to_string(),
    "EMPTYASNULL".to_string(),
    "ENABLE".to_string(),
    "ENCRYPT".to_string(),
    "ENCRYPTION".to_string(),
    "END".to_string(),
    "EXCEPT".to_string(),
    "EXPLICIT_IDS".to_string(),
    "FALSE".to_string(),
    "FILLRECORD".to_string(),
    "FOR".to_string(),
    "FOREIGN".to_string(),
    "FREEZE".to_string(),
    "FROM".to_string(),
    "FULL".to_string(),
    "GLOBALDICT256".to_string(),
    "GLOBALDICT64K".to_string(),
    "GRANT".to_string(),
    "GROUP".to_string(),
    "HAVING".to_string(),
    "IDENTITY".to_string(),
    "IGNORE".to_string(),
    "IGNOREBLANKLINES".to_string(),
    "IGNOREHEADER".to_string(),
    "ILIKE".to_string(),
    "IN".to_string(),
    "INITIALLY".to_string(),
    "INNER".to_string(),
    "INTERSECT".to_string(),
    "INTO".to_string(),
    "IS".to_string(),
    "ISNULL".to_string(),
    "JOIN".to_string(),
    "LEADING".to_string(),
    "LEFT".to_string(),
    "LIKE".to_string(),
    "LIMIT".to_string(),
    "LOCALTIME".to_string(),
    "LOCALTIMESTAMP".to_string(),
    "LUN".to_string(),
    "LUNS".to_string(),
    "LZO".to_string(),
    "MINUS".to_string(),
    "MOSTLY16".to_string(),
    "MOSTLY32".to_string(),
    "MOSTLY8".to_string(),
    "NATURAL".to_string(),
    "NEW".to_string(),
    "NOT".to_string(),
    "NOTNULL".to_string(),
    "NULL".to_string(),
    "NULLS".to_string(),
    "OFF".to_string(),
    "OFFSET".to_string(),
    "OID".to_string(),
    "OLD".to_string(),
    "ON".to_string(),
    "ONLY".to_string(),
    "OPEN".to_string(),
    "OR".to_string(),
    "ORDER".to_string(),
    "OUTER".to_string(),
    "OVERLAPS".to_string(),
    "PARALLEL".to_string(),
    "PARTITION".to_string(),
    "PERCENT".to_string(),
    "PERMISSIONS".to_string(),
    "PIVOT".to_string(),
    "PLACING".to_string(),
    "PRIMARY".to_string(),
    "RAW".to_string(),
    "READRATIO".to_string(),
    "RECOVER".to_string(),
    "REFERENCES".to_string(),
    "REJECTLOG".to_string(),
    "RESORT".to_string(),
    "RESPECT".to_string(),
    "RESTORE".to_string(),
    "RIGHT".to_string(),
    "RUNLENGTH".to_string(),
    "SELECT".to_string(),
    "SESSION_USER".to_string(),
    "SIMILAR".to_string(),
    "SNAPSHOT".to_string(),
    "SOME".to_string(),
    "SYSDATE".to_string(),
    "SYSTEM".to_string(),
    "TABLE".to_string(),
    "TAG".to_string(),
    "TDES".to_string(),
    "TEXT255".to_string(),
    "TEXT32K".to_string(),
    "THEN".to_string(),
    "TIMESTAMP".to_string(),
    "TO".to_string(),
    "TOP".to_string(),
    "TRAILING".to_string(),
    "TRUE".to_string(),
    "TRUNCATECOLUMNS".to_string(),
    "UNION".to_string(),
    "UNIQUE".to_string(),
    "UNNEST".to_string(),
    "UNPIVOT".to_string(),
    "USER".to_string(),
    "USING".to_string(),
    "VERBOSE".to_string(),
    "WHEN".to_string(),
    "WHERE".to_string(),
    "WITH".to_string(),
    "WITHIN".to_string(),
    "WITHOUT".to_string(),
]});

pub static REDSHIFT_LEXERS: Lazy<Vec<LexMatcher>> = Lazy::new(|| { vec![

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "whitespace",
        r#"[^\S\r\n]+"#,
        Token::whitespace_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "inline_comment",
        r#"(--)[^\n]*"#,
        Token::comment_token,
        None,
        None,
        Some(vec![String::from("-"), String::from("-")]),
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |input| input.starts_with(['#','-','/']),
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "block_comment",
        r#"/\*(?>[^*/]+|\*(?!\/)|/[^*])*(?>(?R)(?>[^*/]+|\*(?!\/)|/[^*])*)*\*/"#,
        Token::comment_token,
        Some(Box::new(
    LexMatcher::regex_subdivider(
        Dialect::Redshift,
        "newline",
        r#"\r\n|\n"#,
        Token::newline_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ))),
        Some(Box::new(
    LexMatcher::regex_subdivider(
        Dialect::Redshift,
        "whitespace",
        r#"[^\S\r\n]+"#,
        Token::whitespace_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ))),
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        Some(extract_nested_block_comment),
        |input| input.starts_with("/"),
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "single_quote",
        r#"'([^']|'')*'"#,
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        Some((r#"'((?:[^']|'')*)'"#.to_string(), RegexModeGroup::Index(1))),
        Some((r#"''"#.to_string(), r#"'"#.to_string())),
        None,
        None,
        |input| match input.as_bytes() {
        [b'\'', ..] => true,                     // Single quote case
        [b'R' | b'r', b'\'', ..] => true,        // r' or R'
        [b'B' | b'b', b'\'', ..] => true,        // b' or B'
        [b'R' | b'r', b'B' | b'b', b'\'', ..] => true, // rb', RB', etc.
        [b'B' | b'b', b'R' | b'r', b'\'', ..] => true, // br', Br', etc.
        _ => false,
    },
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "double_quote",
        r#""([^"]|"")*""#,
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        Some((r#""((?:[^"]|"")*)""#.to_string(), RegexModeGroup::Index(1))),
        Some((r#""""#.to_string(), r#"""#.to_string())),
        None,
        None,
        |input| match input.as_bytes() {
        [b'"', ..] => true,                     // Just a double quote
        [b'R' | b'r', b'"', ..] => true,        // r" or R"
        [b'B' | b'b', b'"', ..] => true,        // b" or B"
        [b'R' | b'r', b'B' | b'b', b'"', ..] => true, // rb", RB", etc.
        [b'B' | b'b', b'R' | b'r', b'"', ..] => true, // br", Br", etc.
        _ => false,
    },
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "back_quote",
        r#"`(?:[^`\\]|\\.)*`"#,
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        Some((r#"`((?:[^`\\]|\\.)*)`"#.to_string(), RegexModeGroup::Index(1))),
        Some((r#"\\`"#.to_string(), r#"`"#.to_string())),
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "dollar_quote",
        r#"\$(\w*)\$(.*?)\$\1\$"#,
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        Some((r#"\$(\w*)\$(.*?)\$\1\$"#.to_string(), RegexModeGroup::Index(2))),
        None,
        None,
        None,
        |input| input.starts_with("$"),
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "numeric_literal",
        r#"(?>\d+\.\d+|\d+\.(?![\.\w])|\.\d+|\d+)(\.?[eE][+-]?\d+)?((?<=\.)|(?=\b))"#,
        Token::literal_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |input| input.starts_with(['x','X','.','0','1','2','3','4','5','6','7','8','9']),
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "obevo_annotation",
        r#"////\s*(CHANGE|BODY|METADATA)[^\n]*"#,
        Token::comment_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "glob_operator",
        "~~~",
        Token::comparison_operator_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "unicode_single_quote",
        r#"(?si)U&'([^']|'')*'(\s*UESCAPE\s*'[^0-9A-Fa-f'+\-\s)]')?"#,
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "escaped_single_quote",
        r#"(?si)E(('')+?(?!')|'.*?((?<!\\)(?:\\\\)*(?<!')(?:'')*|(?<!\\)(?:\\\\)*\\(?<!')(?:'')*')'(?!'))"#,
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |input| input.starts_with(['E', 'e']),
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "unicode_double_quote",
        r#"(?si)U&".+?"(\s*UESCAPE\s*\'[^0-9A-Fa-f\'+\-\s)]\')?"#,
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "json_operator",
        r#"->>?|#>>?|@[>@?]|<@|\?[|&]?|#-"#,
        Token::symbol_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "pg_trgm_operator",
        r#"<<<->|<->>>|<->>|<<->(?!>)|<<%|%>>|<%|%>"#,
        Token::symbol_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "pgvector_operator",
        r#"<->|<#>|<=>|<\+>"#,
        Token::symbol_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "postgis_operator",
        r#"\&\&\&|\&<\||<<\||@|\|\&>|\|>>|\~=|<\->|\|=\||<\#>|<<\->>|<<\#>>"#,
        Token::symbol_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "at",
        "@",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "bit_string_literal",
        r#"[bBxX]'[0-9a-fA-F]*'"#,
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "full_text_search_operator",
        "!!",
        Token::symbol_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "like_operator",
        r#"!?~~?\*?"#,
        Token::comparison_operator_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "newline",
        r#"\r\n|\n"#,
        Token::newline_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "casting_operator",
        "::",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "right_arrow",
        "=>",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "walrus_operator",
        ":=",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "equals",
        "=",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "greater_than",
        ">",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "less_than",
        "<",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "not",
        "!",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "dot",
        ".",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "comma",
        ",",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "plus",
        "+",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "minus",
        "-",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "divide",
        "/",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "percent",
        "%",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "question",
        "?",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "ampersand",
        "&",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "vertical_bar",
        "|",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "caret",
        "^",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "star",
        "*",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "start_bracket",
        "(",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "end_bracket",
        ")",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "start_square_bracket",
        "[",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "end_square_bracket",
        "]",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "start_curly_bracket",
        "{",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "end_curly_bracket",
        "}",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "colon",
        ":",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::string_lexer(
        Dialect::Redshift,
        "semicolon",
        ";",
        Token::code_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "meta_command",
        r#"\\(?!gset|gexec)([^\\\r\n])+((\\\\)|(?=\n)|(?=\r\n))?"#,
        Token::comment_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |input| input.starts_with(['\\']),
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "dollar_numeric_literal",
        r#"\$\d+"#,
        Token::literal_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "meta_command_query_buffer",
        r#"\\([^\\\r\n])+((\\g(set|exec))|(?=\n)|(?=\r\n))?"#,
        Token::symbol_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |input| input.starts_with(['\\']),
        None,
    ),

    LexMatcher::regex_lexer(
        Dialect::Redshift,
        "word",
        r#"#?[0-9a-zA-Z_]+[0-9a-zA-Z_$]*"#,
        Token::word_token,
        None,
        None,
        None,
        None,
        Uuid::new_v4().to_string(),
        None,
        None,
        None,
        None,
        |_| true,
        None,
    ),
]});
